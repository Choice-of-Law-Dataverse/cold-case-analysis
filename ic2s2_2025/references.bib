
@inproceedings{vaswani_attention_2017,
	address = {California},
	title = {Attention is {All} {You} {Need}},
	url = {https://arxiv.org/pdf/1706.03762.pdf},
	urldate = {2023-11-02},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year = {2017},
	file = {Full Text PDF:C\:\\Users\\WeigoldS\\Zotero\\storage\\TVEH7CVH\\Vaswani et al. - 2017 - Attention is All You Need.pdf:application/pdf},
}

@misc{rafailov_direct_2023,
	title = {Direct {Preference} {Optimization}: {Your} {Language} {Model} is {Secretly} a {Reward} {Model}},
	shorttitle = {Direct {Preference} {Optimization}},
	url = {http://arxiv.org/abs/2305.18290},
	abstract = {While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper we introduce a new parameterization of the reward model in RLHF that enables extraction of the corresponding optimal policy in closed form, allowing us to solve the standard RLHF problem with only a simple classification loss. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant, and computationally lightweight, eliminating the need for sampling from the LM during fine-tuning or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of generations, and matches or improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.},
	language = {en},
	urldate = {2024-02-21},
	publisher = {arXiv},
	author = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D. and Finn, Chelsea},
	month = dec,
	year = {2023},
	note = {arXiv:2305.18290 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, OS},
	file = {2023.emnlp-main.740.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\3M5MFI5A\\2023.emnlp-main.740.pdf:application/pdf;Rafailov et al. - 2023 - Direct Preference Optimization Your Language Mode.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\7BLR4ESR\\Rafailov et al. - 2023 - Direct Preference Optimization Your Language Mode.pdf:application/pdf},
}

@article{noauthor_large_nodate,
	title = {Large language models and generative {AI}},
	language = {en},
	file = {Large language models and generative AI.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\RW6UCU22\\Large language models and generative AI.pdf:application/pdf},
}

@techreport{openai_gpt-4_nodate,
	title = {{GPT}-4 {Technical} {Report}},
	author = {OpenAI},
	annote = {„key challenge of the project, developing deep learning infrastructure and optimization methods that behave predictably across a wide range of scales“ (OpenAI, p. 1)

Das ist ja ein spannendes Zitat.
},
	file = {gpt-4.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\IU7VGG5Y\\gpt-4.pdf:application/pdf;gpt4-report-graph.JPG:C\:\\Users\\WeigoldS\\Zotero\\storage\\7YFA5UWT\\gpt4-report-graph.JPG:image/jpeg},
}

@article{bhupatiraju_mapping_2024,
	title = {Mapping the {Geometry} of {Law} {Using} {Natural} {Language} {Processing}},
	volume = {1},
	copyright = {https://creativecommons.org/licenses/by-nc/4.0},
	issn = {2004-8556},
	url = {https://publicera.kb.se/ejels/article/view/18073},
	doi = {10.62355/ejels.18073},
	abstract = {Judicial documents and judgments are a rich source of information about legal cases, litigants, and judicial decision-makers. Natural language processing (NLP) based approaches have recently received much attention for their ability to decipher implicit information from text. NLP researchers have successfully developed data-driven representations of text using dense vectors that encode the relations between those objects. In this study, we explore the application of the Doc2Vec model to legal language to understand judicial reasoning and identify implicit patterns in judgments and judges. In an application to federal appellate courts, we show that these vectors encode information that distinguishes courts in time and legal topics. We use Doc2Vec document embeddings to study the patterns and train a classifier model to predict cases with a high chance of being appealed at the Supreme Court of the United States (SCOTUS). There are no existing benchmarks, and we present the first results at this task at scale. Furthermore, we analyze generic writing/judgment patterns of prominent judges using deep learning-based autoencoder models. Overall, we observe that Doc2Vec document embeddings capture important legal information and are helpful in downstream tasks.},
	language = {en},
	number = {1},
	urldate = {2024-06-08},
	journal = {European Journal of Empirical Legal Studies},
	author = {Bhupatiraju, Sandeep and Chen, Daniel and Venkataramanan, Kannan},
	month = may,
	year = {2024},
	pages = {49--68},
	file = {Bhupatiraju et al. - 2024 - Mapping the Geometry of Law Using Natural Language.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LZ3G9UH8\\Bhupatiraju et al. - 2024 - Mapping the Geometry of Law Using Natural Language.pdf:application/pdf},
}

@article{blum_foundations_2018,
	title = {Foundations of {Data} {Science}},
	language = {en},
	author = {Blum, Avrim and Hopcroft, John and Kannan, Ravindran},
	year = {2018},
	file = {Blum et al. - Foundations of Data Science.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\XW492PIX\\Blum et al. - Foundations of Data Science.pdf:application/pdf},
}

@article{lin_practitioners_nodate,
	title = {Practitioner's {Guide} to {Data} {Science}},
	language = {en},
	author = {Lin, Hui and Li, Ming},
	file = {Lin und Li - Practitioner's Guide to Data Science.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\VEZD23R4\\Lin und Li - Practitioner's Guide to Data Science.pdf:application/pdf},
}

@article{rocklov_data_2021,
	title = {Data {Science} and {Machine} {Learning}: {Mathematical} and {Statistical} {Methods}},
	volume = {49},
	copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
	issn = {0300-5771, 1464-3685},
	shorttitle = {Data {Science} and {Machine} {Learning}},
	url = {https://academic.oup.com/ije/article/49/6/2096/5864489},
	doi = {10.1093/ije/dyaa111},
	language = {en},
	number = {6},
	urldate = {2024-05-27},
	journal = {International Journal of Epidemiology},
	author = {Rocklöv, Joacim and Gayle, Albert A},
	month = jan,
	year = {2021},
	pages = {2096--2096},
	file = {Rocklöv und Gayle - 2021 - Data Science and Machine Learning Mathematical an.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\7TT4U3II\\Rocklöv und Gayle - 2021 - Data Science and Machine Learning Mathematical an.pdf:application/pdf},
}

@article{grimmer_new_nodate,
	title = {A {New} {Framework} for {Machine} {Learning} and the {Social} {Sciences}},
	language = {en},
	author = {Grimmer, Justin and Roberts, Margaret E and Stewart, Brandon M},
	file = {Grimmer et al. - A New Framework for Machine Learning and the Socia.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\TGXXMCHF\\Grimmer et al. - A New Framework for Machine Learning and the Socia.pdf:application/pdf},
}

@book{paas_foundation_2023,
	address = {Cham},
	series = {Artificial {Intelligence}: {Foundations}, {Theory}, and {Algorithms}},
	title = {Foundation {Models} for {Natural} {Language} {Processing}: {Pre}-trained {Language} {Models} {Integrating} {Media}},
	copyright = {https://creativecommons.org/licenses/by/4.0},
	isbn = {978-3-031-23189-6 978-3-031-23190-2},
	shorttitle = {Foundation {Models} for {Natural} {Language} {Processing}},
	url = {https://link.springer.com/10.1007/978-3-031-23190-2},
	language = {en},
	urldate = {2024-05-19},
	publisher = {Springer International Publishing},
	author = {Paaß, Gerhard and Giesselbach, Sven},
	year = {2023},
	doi = {10.1007/978-3-031-23190-2},
	file = {Paaß und Giesselbach - 2023 - Foundation Models for Natural Language Processing.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\U82GEWW6\\Paaß und Giesselbach - 2023 - Foundation Models for Natural Language Processing.pdf:application/pdf},
}

@book{richter_statistisches_2019,
	address = {Berlin, Heidelberg},
	title = {Statistisches und maschinelles {Lernen}: {Gängige} {Verfahren} im Überblick},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-662-59353-0 978-3-662-59354-7},
	shorttitle = {Statistisches und maschinelles {Lernen}},
	url = {http://link.springer.com/10.1007/978-3-662-59354-7},
	language = {de},
	urldate = {2024-05-19},
	publisher = {Springer Berlin Heidelberg},
	author = {Richter, Stefan},
	year = {2019},
	doi = {10.1007/978-3-662-59354-7},
	file = {Richter - 2019 - Statistisches und maschinelles Lernen Gängige Ver.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LZZDLAHH\\Richter - 2019 - Statistisches und maschinelles Lernen Gängige Ver.pdf:application/pdf},
}

@misc{wei_chain--thought_2023,
	title = {Chain-of-{Thought} {Prompting} {Elicits} {Reasoning} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2201.11903},
	abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—signiﬁcantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufﬁciently large language models via a simple method called chain-ofthought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even ﬁnetuned GPT-3 with a veriﬁer.},
	language = {en},
	urldate = {2024-05-19},
	publisher = {arXiv},
	author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
	month = jan,
	year = {2023},
	note = {arXiv:2201.11903 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\M2CJEKLL\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:application/pdf},
}

@article{ribeiro_de_faria_automatic_2024,
	title = {Automatic information extraction from {Employment} {Tribunal} judgements using large language models},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4776160},
	doi = {10.2139/ssrn.4776160},
	abstract = {Court transcripts and judgments are rich repositories of legal knowledge, detailing the intricacies of cases and the rationale behind judicial decisions. The extraction of key information from these documents provides a concise overview of a case, crucial for both legal experts and the public. With the advent of large language models (LLMs), automatic information extraction has become increasingly feasible and efficient. This paper presents a comprehensive study on the application of GPT-4, a large language model, for automatic information extraction from UK Employment Tribunal (UKET) cases. We meticulously evaluated GPT-4’s performance in extracting critical information with a manual verification process to ensure the accuracy and relevance of the extracted data. Our research is structured around two primary extraction tasks: the first involves a general extraction of eight key aspects that hold significance for both legal specialists and the general public, including the facts of the case, the claims made, references to legal statutes, references to precedents, general case outcomes and corresponding labels, detailed order and remedies and reasons for the decision. The second task is more focused, aimed at analysing three of those extracted features, namely facts, claims and outcomes, in order to facilitate the development of a tool capable of predicting the outcome of employment law disputes. Through our analysis, we demonstrate that LLMs like GPT-4 can obtain high accuracy in legal information extraction, highlighting the potential of LLMs in revolutionising the way legal information is processed and utilised, offering significant implications for legal research and practice.},
	language = {en},
	urldate = {2024-05-19},
	journal = {SSRN Electronic Journal},
	author = {Ribeiro De Faria, Joana and Xie, Huiyuan and Steffek, Felix},
	year = {2024},
	keywords = {SW, Information Extraction, OS, Information Extraction - Employment Tribunal Desicions Example},
	annote = {SW NOTES


prompt could be interesting/useful for us


other than that, they use a very basic setup


},
	file = {2023.emnlp-main.740.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\PZAFR9BE\\2023.emnlp-main.740.pdf:application/pdf;Ribeiro De Faria et al. - 2024 - Automatic information extraction from Employment T.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\L7LYLE3J\\Ribeiro De Faria et al. - 2024 - Automatic information extraction from Employment T.pdf:application/pdf},
}

@article{nielsen_ai-_nodate,
	title = {{AI}- {First} {New} {UI} {Paradigm} in 60 {Years}},
	abstract = {AI is introducing the third user-interface paradigm in computing history, shi!ing to a new interaction mechanism where users tell the computer what they want, not how to do it — thus reversing the locus of control.},
	language = {en},
	author = {Nielsen, Jakob},
	file = {Nielsen - AI- First New UI Paradigm in 60 Years.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\N4ZF6NFJ\\Nielsen - AI- First New UI Paradigm in 60 Years.pdf:application/pdf},
}

@book{zhang_machine_2020,
	title = {Machine {Learning} and {Visual} {Perception}},
	isbn = {978-3-11-059556-7},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110595567/html},
	language = {de},
	urldate = {2024-05-19},
	publisher = {De Gruyter},
	author = {Zhang, Baochang and Li, Ce and Lin, Nana},
	month = may,
	year = {2020},
	doi = {10.1515/9783110595567},
	file = {Zhang et al. - 2020 - Machine Learning and Visual Perception.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\FL9YPXBW\\Zhang et al. - 2020 - Machine Learning and Visual Perception.pdf:application/pdf},
}

@article{power_grokking_nodate,
	title = {{GROKKING}: {GENERALIZATION} {BEYOND} {OVERFIT}- {TING} {ON} {SMALL} {ALGORITHMIC} {DATASETS}},
	abstract = {In this paper we propose to study generalization of neural networks on small algorithmically generated datasets. In this setting, questions about data efﬁciency, memorization, generalization, and speed of learning can be studied in great detail. In some situations we show that neural networks learn through a process of “grokking” a pattern in the data, improving generalization performance from random chance level to perfect generalization, and that this improvement in generalization can happen well past the point of overﬁtting. We also study generalization as a function of dataset size and ﬁnd that smaller datasets require increasing amounts of optimization for generalization. We argue that these datasets provide a fertile ground for studying a poorly understood aspect of deep learning: generalization of overparametrized neural networks beyond memorization of the ﬁnite training dataset.},
	language = {en},
	author = {Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
	keywords = {OpenAI - Mathematical Reasoning},
	file = {Power et al. - GROKKING GENERALIZATION BEYOND OVERFIT- TING ON S.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\GD6T58L8\\Power et al. - GROKKING GENERALIZATION BEYOND OVERFIT- TING ON S.pdf:application/pdf},
}

@article{bosse_maschinelles_nodate,
	title = {Maschinelles {Lernen} und {Datenanalyse} in der {Soziologie}},
	language = {de},
	author = {Bosse, PD Stefan},
	keywords = {Sociology - Machine Learning},
	file = {Bosse - Maschinelles Lernen und Datenanalyse in der Soziol.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\Q748Y8AQ\\Bosse - Maschinelles Lernen und Datenanalyse in der Soziol.pdf:application/pdf},
}

@article{leible_zwischen_2024,
	title = {Zwischen {Forschung} und {Praxis}: {Fähigkeiten} und {Limitationen} generativer {KI} sowie ihre wachsende {Bedeutung} in der {Zukunft}},
	volume = {61},
	issn = {1436-3011, 2198-2775},
	shorttitle = {Zwischen {Forschung} und {Praxis}},
	url = {https://link.springer.com/10.1365/s40702-024-01050-x},
	doi = {10.1365/s40702-024-01050-x},
	abstract = {The dynamic development and increasing popularity of generative artiﬁcial intelligence (genAI), especially through the spread and use of ChatGPT, has shown the enormous potential of this technology to fundamentally transform professions and industries. The decision regarding using genAI and identifying promising application scenarios pose considerable challenges in view of a rapidly growing and increasingly complex market. Given these circumstances, this article aims to present an overview of the capabilities and limitations of genAI. A systematic literature review was used to identify a variety of application scenarios and evaluate them in terms of the outcomes of genAI deployment, providing a snapshot of current capabilities and limitations. In addition, a survey was conducted among 40 participants to record usage habits and experiences in dealing with genAI and to validate the ﬁndings from the literature. The insights gained should support practitioners in navigating the ﬁeld of genAI and provide decision-making support by enabling them to classify the identiﬁed capabilities and limitations in the context of their own application scenarios. Furthermore, the results provide points of reference for the methodical investigation of genAI application scenarios as well as starting points for in-depth scientiﬁc research by researchers. By linking theoretical analysis and a practical survey, the article offers a comprehensive insight into the current state of genAI.},
	language = {de},
	number = {2},
	urldate = {2024-05-16},
	journal = {HMD Praxis der Wirtschaftsinformatik},
	author = {Leible, Stephan and Gücük, Gian-Luca and Simic, Dejan and Von Brackel-Schmidt, Constantin and Lewandowski, Tom},
	month = apr,
	year = {2024},
	keywords = {Information Systems - AI Research, Information Systems - Generative AI},
	pages = {344--370},
	file = {Leible et al. - 2024 - Zwischen Forschung und Praxis Fähigkeiten und Lim.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\9NHWW9FD\\Leible et al. - 2024 - Zwischen Forschung und Praxis Fähigkeiten und Lim.pdf:application/pdf},
}

@article{kahlert_mehr_nodate,
	title = {Mehr {Methoden} mixen, mehr {Experimente} wagen: {Mit} sozialwissenschaftlicher {Methodologie} den {Herausforderungen} der {KI}-{Forschung} begegnen},
	language = {de},
	author = {Kahlert, Peter and Tatari, Maryam and Kahlert, Suzette and Passoth, Dr Jan-Hendrik and Viadrina, Europa-Universität},
	keywords = {Social Science - AI Research},
	file = {Kahlert et al. - Mehr Methoden mixen, mehr Experimente wagen Mit s.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\GJUBWCRF\\Kahlert et al. - Mehr Methoden mixen, mehr Experimente wagen Mit s.pdf:application/pdf},
}

@article{burtell_surprising_nodate,
	title = {The {Surprising} {Power} of {Next} {Word} {Prediction}: {Large} {Language} {Models} {Explained}, {Part}},
	language = {en},
	author = {Burtell, Matthew and Toner, Helen},
	keywords = {LLMs explaned},
	file = {Burtell und Toner - The Surprising Power of Next Word Prediction Larg.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ZUMYUSAQ\\Burtell und Toner - The Surprising Power of Next Word Prediction Larg.pdf:application/pdf},
}

@article{schwartz-croft_effects_2024,
	title = {Effects of {ROSS} {Intelligence} and {NDAS}, highlighting the need for {AI} regulation},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4727662},
	doi = {10.2139/ssrn.4727662},
	language = {en},
	urldate = {2024-06-24},
	journal = {SSRN Electronic Journal},
	author = {Schwartz-croft, Lucian},
	year = {2024},
	keywords = {Use of LLms in legal practice},
	file = {Schwartz-croft - 2024 - Effects of ROSS Intelligence and NDAS, highlightin.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ZJJ82Y4A\\Schwartz-croft - 2024 - Effects of ROSS Intelligence and NDAS, highlightin.pdf:application/pdf},
}

@article{choi_ai_2023,
	title = {{AI} {Assistance} in {Legal} {Analysis}: {An} {Empirical} {Study}},
	issn = {1556-5068},
	shorttitle = {{AI} {Assistance} in {Legal} {Analysis}},
	url = {https://www.ssrn.com/abstract=4539836},
	doi = {10.2139/ssrn.4539836},
	language = {en},
	urldate = {2024-06-24},
	journal = {SSRN Electronic Journal},
	author = {Choi, Jonathan H. and Schwarcz, Daniel B.},
	year = {2023},
	keywords = {AI assistance - legal analysis},
	file = {Choi und Schwarcz - 2023 - AI Assistance in Legal Analysis An Empirical Stud.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\TMJV7JBI\\Choi und Schwarcz - 2023 - AI Assistance in Legal Analysis An Empirical Stud.pdf:application/pdf},
}

@article{farquhar_detecting_2024,
	title = {Detecting hallucinations in large language models using semantic entropy},
	volume = {630},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-024-07421-0},
	doi = {10.1038/s41586-024-07421-0},
	abstract = {Abstract
            
              Large language model (LLM) systems, such as ChatGPT
              1
              or Gemini
              2
              , can show impressive reasoning and question-answering capabilities but often ‘hallucinate’ false outputs and unsubstantiated answers
              3,4
              . Answering unreliably or without the necessary information prevents adoption in diverse fields, with problems including fabrication of legal precedents
              5
              or untrue facts in news articles
              6
              and even posing a risk to human life in medical domains such as radiology
              7
              . Encouraging truthfulness through supervision or reinforcement has been only partially successful
              8
              . Researchers need a general method for detecting hallucinations in LLMs that works even with new and unseen questions to which humans might not know the answer. Here we develop new methods grounded in statistics, proposing entropy-based uncertainty estimators for LLMs to detect a subset of hallucinations—confabulations—which are arbitrary and incorrect generations. Our method addresses the fact that one idea can be expressed in many ways by computing uncertainty at the level of meaning rather than specific sequences of words. Our method works across datasets and tasks without a priori knowledge of the task, requires no task-specific data and robustly generalizes to new tasks not seen before. By detecting when a prompt is likely to produce a confabulation, our method helps users understand when they must take extra care with LLMs and opens up new possibilities for using LLMs that are otherwise prevented by their unreliability.},
	language = {en},
	number = {8017},
	urldate = {2024-06-24},
	journal = {Nature},
	author = {Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
	month = jun,
	year = {2024},
	keywords = {Detecting LLM halluzination},
	pages = {625--630},
	file = {Farquhar et al. - 2024 - Detecting hallucinations in large language models .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\UICQ9YKM\\Farquhar et al. - 2024 - Detecting hallucinations in large language models .pdf:application/pdf},
}

@article{polak_extracting_2024,
	title = {Extracting accurate materials data from research papers with conversational language models and prompt engineering},
	volume = {15},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-024-45914-8},
	doi = {10.1038/s41467-024-45914-8},
	abstract = {Abstract
            There has been a growing effort to replace manual extraction of data from research papers with automated data extraction based on natural language processing, language models, and recently, large language models (LLMs). Although these methods enable efficient extraction of data from large sets of research papers, they require a significant amount of up-front effort, expertise, and coding. In this work, we propose the  method that can fully automate very accurate data extraction with minimal initial effort and background, using an advanced conversational LLM.  consists of a set of engineered prompts applied to a conversational LLM that both identify sentences with data, extract that data, and assure the data’s correctness through a series of follow-up questions. These follow-up questions largely overcome known issues with LLMs providing factually inaccurate responses.  can be applied with any conversational LLMs and yields very high quality data extraction. In tests on materials data, we find precision and recall both close to 90\% from the best conversational LLMs, like GPT-4. We demonstrate that the exceptional performance is enabled by the information retention in a conversational model combined with purposeful redundancy and introducing uncertainty through follow-up prompts. These results suggest that approaches similar to , due to their simplicity, transferability, and accuracy are likely to become powerful tools for data extraction in the near future. Finally, databases for critical cooling rates of metallic glasses and yield strengths of high entropy alloys are developed using .},
	language = {en},
	number = {1},
	urldate = {2024-06-24},
	journal = {Nature Communications},
	author = {Polak, Maciej P. and Morgan, Dane},
	month = feb,
	year = {2024},
	keywords = {Data extraction using LLM},
	pages = {1569},
	file = {Polak und Morgan - 2024 - Extracting accurate materials data from research p.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\UMI8WIG7\\Polak und Morgan - 2024 - Extracting accurate materials data from research p.pdf:application/pdf},
}

@article{haponik_rag_nodate,
	title = {{RAG} vs {Fine}-{Tuning}: {A} {Comparative} {Analysis} of {LLM} {Learning} {Techniques}},
	language = {en},
	author = {Haponik, Artur},
	keywords = {Blog - LLM learning technics},
	file = {Haponik - RAG vs Fine-Tuning A Comparative Analysis of LLM .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\9XG4RPUI\\Haponik - RAG vs Fine-Tuning A Comparative Analysis of LLM .pdf:application/pdf},
}

@incollection{engstrom_natural_2023,
	edition = {1},
	title = {Natural {Language} {Processing} in {Legal} {Tech}},
	isbn = {978-1-00-925530-1 978-1-00-925535-6 978-1-00-925534-9},
	url = {https://www.cambridge.org/core/product/identifier/9781009255301%23CN-bp-3/type/book_part},
	language = {en},
	urldate = {2024-06-24},
	booktitle = {Legal {Tech} and the {Future} of {Civil} {Justice}},
	publisher = {Cambridge University Press},
	author = {Frankenreiter, Jens and Nyarko, Julian},
	editor = {Engstrom, David Freeman},
	month = feb,
	year = {2023},
	doi = {10.1017/9781009255301.005},
	keywords = {Natural Language Processing - Legal Tech, OS, NLP - Legal Tech in General},
	pages = {70--90},
	file = {Frankenreiter und Nyarko - 2023 - Natural Language Processing in Legal Tech.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ATMTM992\\Frankenreiter und Nyarko - 2023 - Natural Language Processing in Legal Tech.pdf:application/pdf},
}

@article{noauthor_llm_nodate,
	title = {{LLM} {Training}- {How} {It} {Works} and 4 {Key} {Considerations}},
	language = {en},
	keywords = {Blog - LLM Training},
	file = {LLM Training- How It Works and 4 Key Consideration.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\VWZ84WZH\\LLM Training- How It Works and 4 Key Consideration.pdf:application/pdf},
}

@article{noauthor_einsatzmoglichkeiten_nodate,
	title = {Einsatzmöglichkeiten von {Large} {Language} {Models} in der {Justiz}},
	language = {de},
	keywords = {Blog LLM in Justiz},
	file = {Einsatzmöglichkeiten von Large Language Models in .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\BNC6I2KM\\Einsatzmöglichkeiten von Large Language Models in .pdf:application/pdf},
}

@article{agastya_decoding_nodate,
	title = {Decoding {LLM} {Performance}: {A} {Guide} to {Evaluating} {LLM} {Applications}},
	language = {en},
	author = {Agastya, Amogh},
	keywords = {Blog - LLM Evaluation},
	file = {Agastya - Decoding LLM Performance A Guide to Evaluating LL.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\TCRG9R9C\\Agastya - Decoding LLM Performance A Guide to Evaluating LL.pdf:application/pdf},
}

@article{noauthor_creating_nodate,
	title = {Creating an {OpenAI} {API} {Key} {\textbar} {Codecademy}},
	language = {en},
	keywords = {OpenAI - API-Key generation},
	file = {Creating an OpenAI API Key  Codecademy.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\KQK6DVF9\\Creating an OpenAI API Key  Codecademy.pdf:application/pdf},
}

@article{surden_chatgpt_nodate,
	title = {{ChatGPT}, {Large} {Language} {Models}, and {Law}},
	volume = {92},
	language = {en},
	journal = {FORDHAM LAW REVIEW},
	author = {Surden, Harry},
	keywords = {Legal Tech - AI and Law},
	file = {Surden - ChatGPT, Large Language Models, and Law.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\VYHZVLSX\\Surden - ChatGPT, Large Language Models, and Law.pdf:application/pdf},
}

@article{noauthor_building_nodate,
	title = {Building {Domain}-{Specific} {LLMs}- {Examples} and {Techniques}},
	language = {en},
	keywords = {Blog - Domain specific knowledge},
	file = {Building Domain-Specific LLMs- Examples and Techni.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\S5GLGMKN\\Building Domain-Specific LLMs- Examples and Techni.pdf:application/pdf},
}

@article{beatman_azure_nodate,
	title = {Azure {OpenAI} {Service}: {Transforming} legal practices with generative {AI} solutions},
	language = {en},
	author = {Beatman, Andy},
	keywords = {OpenAI - Azure Service for legal solutions},
	file = {Beatman - Azure OpenAI Service Transforming legal practices.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\54CTXAI8\\Beatman - Azure OpenAI Service Transforming legal practices.pdf:application/pdf},
}

@article{dimitriadis_artificial_2024,
	title = {Artificial fine-tuning tasks for yes/no question answering},
	volume = {30},
	issn = {1351-3249, 1469-8110},
	url = {https://www.cambridge.org/core/product/identifier/S1351324922000286/type/journal_article},
	doi = {10.1017/S1351324922000286},
	abstract = {Current research in yes/no question answering (QA) focuses on transfer learning techniques and transformer-based models. Models trained on large corpora are ﬁne-tuned on tasks similar to yes/no QA, and then the captured knowledge is transferred for solving the yes/no QA task. Most previous studies use existing similar tasks, such as natural language inference or extractive QA, for the ﬁne-tuning step. This paper follows a different perspective, hypothesizing that an artiﬁcial yes/no task can transfer useful knowledge for improving the performance of yes/no QA. We introduce three such tasks for this purpose, by adapting three corresponding existing tasks: candidate answer validation, sentiment classiﬁcation, and lexical simpliﬁcation. Furthermore, we experimented with three different variations of the BERT model (BERT base, RoBERTa, and ALBERT). The results show that our hypothesis holds true for all artiﬁcial tasks, despite the small size of the corresponding datasets that are used for the ﬁne-tuning process, the differences between these tasks, the decisions that we made to adapt the original ones, and the tasks’ simplicity. This gives an alternative perspective on how to deal with the yes/no QA problem, that is more creative, and at the same time more ﬂexible, as it can exploit multiple other existing tasks and corresponding datasets to improve yes/no QA models.},
	language = {en},
	number = {1},
	urldate = {2024-06-24},
	journal = {Natural Language Engineering},
	author = {Dimitriadis, Dimitris and Tsoumakas, Grigorios},
	month = jan,
	year = {2024},
	keywords = {Natural Language Engineering - Q\&A Models},
	pages = {73--95},
	file = {Dimitriadis und Tsoumakas - 2024 - Artificial fine-tuning tasks for yesno question a.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\S3MU4CWP\\Dimitriadis und Tsoumakas - 2024 - Artificial fine-tuning tasks for yesno question a.pdf:application/pdf},
}

@article{ali_this_nodate,
	title = {This guide walks you through the basics of the {ChatGPT} {API}, demonstrating its potential in natural language processing and {AI}- driven communication.},
	language = {en},
	author = {Ali, Moez},
	keywords = {Blog - Basics ChatGPT API},
	file = {Ali - This guide walks you through the basics of the Cha.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\MZJ34KLT\\Ali - This guide walks you through the basics of the Cha.pdf:application/pdf},
}

@inproceedings{kim_evallm_2024,
	address = {Honolulu HI USA},
	title = {{EvalLM}: {Interactive} {Evaluation} of {Large} {Language} {Model} {Prompts} on {User}-{Defined} {Criteria}},
	isbn = {9798400703300},
	shorttitle = {{EvalLM}},
	url = {https://dl.acm.org/doi/10.1145/3613904.3642216},
	doi = {10.1145/3613904.3642216},
	language = {en},
	urldate = {2024-06-24},
	booktitle = {Proceedings of the {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kim, Tae Soo and Lee, Yoonjoo and Shin, Jamin and Kim, Young-Ho and Kim, Juho},
	month = may,
	year = {2024},
	keywords = {Computer Science - LLM Evaluation},
	pages = {1--21},
	file = {Kim et al. - 2024 - EvalLM Interactive Evaluation of Large Language M.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\KWPRW2KV\\Kim et al. - 2024 - EvalLM Interactive Evaluation of Large Language M.pdf:application/pdf},
}

@article{wein_digitale_2020,
	title = {Digitale {Dokumente} und {Soziologie} der digitalen {Analyse}: {Zur} {Repräsentation} entfernter {Gebrauchsweisen}},
	volume = {21},
	copyright = {https://creativecommons.org/licenses/by-sa/4.0/deed.de},
	issn = {21962138, 21962146},
	shorttitle = {Digitale {Dokumente} und {Soziologie} der digitalen {Analyse}},
	url = {https://www.budrich-journals.de/index.php/zqf/article/view/35544},
	doi = {10.3224/zqf.v21i1.02},
	abstract = {The following article operates on two levels: Firstly, it illustrates the ways social research can manage ‘Big Data’. This is not achieved by competing with the kind of data analysis practiced within the field of IT, but rather by scrutinizing the analysis itself, its documents, and the knowledge incorporated therein. Taking a web analysis report as an example, the article shows just how the sociological analysis takes place in practice. It further outlines first results of this insight. Secondly, turning from specific empirical cases towards the abstract, it tries to find an answer to the methodological challenges Sociology faces in light of far advanced digitalization. Empirical social research is confronted with a fast-growing number of digital documents. The article seeks to systemize practical knowledge on how qualitative social research deals with, among others, records, papers, and images. Four dimensions of documents are specified: On the one hand, those that are crucial in ‘classical’ document analysis - besides its use this includes its textual performativity - and, on the other hand, those that have stayed rather implicit in sociological research up until now, and were mainly noted outside of the discourse of document analysis: graphical-visual performativity and materiality.},
	language = {de},
	number = {1-2020},
	urldate = {2024-06-24},
	journal = {Zeitschrift für Qualitative Forschung},
	author = {Wein, Vanessa},
	month = jul,
	year = {2020},
	keywords = {Sociology - Big Data},
	pages = {13--35},
	file = {Wein - 2020 - Digitale Dokumente und Soziologie der digitalen An.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\UHD78FGV\\Wein - 2020 - Digitale Dokumente und Soziologie der digitalen An.pdf:application/pdf},
}

@misc{iourovitski_grade_2024,
	title = {Grade {Score}: {Quantifying} {LLM} {Performance} in {Option} {Selection}},
	shorttitle = {Grade {Score}},
	url = {http://arxiv.org/abs/2406.12043},
	abstract = {This study introduces the "Grade Score", a novel metric designed to evaluate the consistency and fairness of Large Language Models (LLMs) when used as multiple-choice judges with respect to order bias and choice consistency. The Grade Score combines Entropy, which measures order bias, and Mode Frequency, which assesses choice stability, offering insights into LLMs' reliability and impartiality. The study explores techniques such as prompt engineering and option sampling strategies to optimize the Grade Score, demonstrating their effectiveness in enhancing LLMs' performance. Results showcase varying performances among LLMs with respect to prompts and highlight the positive impact of including irrelevant options. The study also identifies an emergent behavior in instruction-following models, where they adapt to instructions targeting specific biases, demonstrating their adaptability. The Grade Score facilitates comparisons between LLMs and encourages ongoing research towards optimizing their decision-making processes, with potential implications for improving their reliability and fairness in various applications. All code is available on GitHub https://github.com/IoDmitri/GradeLab},
	language = {en},
	urldate = {2024-06-24},
	publisher = {arXiv},
	author = {Iourovitski, Dmitri},
	month = jun,
	year = {2024},
	note = {arXiv:2406.12043 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Quantifiyng LLM performance},
	file = {Iourovitski - 2024 - Grade Score Quantifying LLM Performance in Option.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\WLCPL5Q6\\Iourovitski - 2024 - Grade Score Quantifying LLM Performance in Option.pdf:application/pdf},
}

@misc{rao_quallm_2024,
	title = {{QuaLLM}: {An} {LLM}-based {Framework} to {Extract} {Quantitative} {Insights} from {Online} {Forums}},
	shorttitle = {{QuaLLM}},
	url = {http://arxiv.org/abs/2405.05345},
	abstract = {Online discussion forums provide crucial data to understand the concerns of a wide range of real-world communities. However, the typical qualitative and quantitative methods used to analyze those data, such as thematic analysis and topic modeling, are infeasible to scale or require significant human effort to translate outputs to human readable forms. This study introduces QuaLLM, a novel LLM-based framework to analyze and extract quantitative insights from text data on online forums. The framework consists of a novel prompting methodology and evaluation strategy. We applied this framework to analyze over one million comments from two Reddit’s rideshare worker communities, marking the largest study of its type. We uncover significant worker concerns regarding AI and algorithmic platform decisions, responding to regulatory calls about worker insights. In short, our work sets a new precedent for AIassisted quantitative data analysis to surface concerns from online forums.},
	language = {en},
	urldate = {2024-06-24},
	publisher = {arXiv},
	author = {Rao, Varun Nagaraj and Agarwal, Eesha and Dalal, Samantha and Calacci, Dan and Monroy-Hernández, Andrés},
	month = may,
	year = {2024},
	note = {arXiv:2405.05345 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	annote = {Comment: Accepted to CHI LLM as Research Tools Workshop (2024)},
	file = {Rao et al. - 2024 - QuaLLM An LLM-based Framework to Extract Quantita.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\WSQH6LME\\Rao et al. - 2024 - QuaLLM An LLM-based Framework to Extract Quantita.pdf:application/pdf},
}

@article{tikhonov_post_nodate,
	title = {Post {Turing}: {Mapping} the landscape of {LLM} {Evaluation}},
	abstract = {In the rapidly evolving landscape of Large Language Models (LLMs), introduction of welldefined and standardized evaluation methodologies remains a crucial challenge. This paper traces the historical trajectory of LLM evaluations, from the foundational questions posed by Alan Turing to the modern era of AI research. We categorize the evolution of LLMs into distinct periods, each characterized by its unique benchmarks and evaluation criteria. As LLMs increasingly mimic human-like behaviors, traditional evaluation proxies, such as the Turing test, have become less reliable. We emphasize the pressing need for a unified evaluation system, given the broader societal implications of these models. Through an analysis of common evaluation methodologies, we advocate for a qualitative shift in assessment approaches, underscoring the importance of standardization and objective criteria. This work serves as a call for the AI community to collaboratively address the challenges of LLM evaluation, ensuring their reliability, fairness, and societal benefit.},
	language = {en},
	author = {Tikhonov, Alexey and Yamshchikov, Ivan P},
	keywords = {LLM Evaluation Mapping Landscape},
	file = {2309.11325.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\9389RYNV\\2309.11325.pdf:application/pdf;Tikhonov und Yamshchikov - Post Turing Mapping the landscape of LLM Evaluati.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\6M7S3J4M\\Tikhonov und Yamshchikov - Post Turing Mapping the landscape of LLM Evaluati.pdf:application/pdf},
}

@article{von_lucke_wie_2020,
	title = {Wie {Ansätze} künstlicher {Intelligenz} die öffentliche {Verwaltung} und die {Justiz} verändern könnten},
	issn = {1664-848X},
	url = {https://jusletter-it.weblaw.ch/issues/2020/fses/14_s_245_272_von_luc_5102164864.html},
	doi = {10.38023/fafb2543-2746-4061-b898-5ee71c91cef8},
	abstract = {Künstliche Intelligenz (KI) bietet das Potenzial, Staat, Verwaltung, Justiz und Gesellschaft in hohem Maße disruptiv zu verändern. Bereits heute sind zahlreiche KI‐Anwendungen Bestandteil von alltäglichen Produkten und Dienstleistungen. Doch wie können diese auch durch den öffentlichen Sektor systematisch genutzt werden? Welche Folgen sind damit für die Organisation von Staat und Verwaltung sowie die Gesellschaft verbunden? Zahlreiche offene Fragen bedürfen gesellschaftlicher Diskussionen rund um entscheidungsunterstützende Systeme und autonome Entscheidungen.},
	language = {de},
	number = {fses},
	urldate = {2024-06-24},
	journal = {Jusletter-IT},
	author = {Von Lucke, Jörn and Etscheid, Jan},
	year = {2020},
	keywords = {Legal Tech - AI use cases},
	file = {Von Lucke und Etscheid - 2020 - Wie Ansätze künstlicher Intelligenz die öffentlich.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\VZE9JI8J\\Von Lucke und Etscheid - 2020 - Wie Ansätze künstlicher Intelligenz die öffentlich.pdf:application/pdf},
}

@inproceedings{wu_precedent-enhanced_2023,
	address = {Singapore},
	title = {Precedent-{Enhanced} {Legal} {Judgment} {Prediction} with {LLM} and {Domain}-{Model} {Collaboration}},
	url = {https://aclanthology.org/2023.emnlp-main.740},
	doi = {10.18653/v1/2023.emnlp-main.740},
	language = {en},
	urldate = {2024-06-24},
	booktitle = {Proceedings of the 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Wu, Yiquan and Zhou, Siying and Liu, Yifei and Lu, Weiming and Liu, Xiaozhong and Zhang, Yating and Sun, Changlong and Wu, Fei and Kuang, Kun},
	year = {2023},
	keywords = {Computational Lingustics - Legal AI},
	pages = {12060--12075},
	file = {Wu et al. - 2023 - Precedent-Enhanced Legal Judgment Prediction with .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ZDF27BFZ\\Wu et al. - 2023 - Precedent-Enhanced Legal Judgment Prediction with .pdf:application/pdf},
}

@article{noauthor_7_nodate,
	title = {7 {Ways} to {Evaluate} and {Monitor} {LLMs}},
	language = {en},
	keywords = {LLM Evaluation},
	file = {7 Ways to Evaluate and Monitor LLMs.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\Q7PXEZ69\\7 Ways to Evaluate and Monitor LLMs.pdf:application/pdf},
}

@misc{fu_gptscore_2023,
	title = {{GPTScore}: {Evaluate} as {You} {Desire}},
	shorttitle = {{GPTScore}},
	url = {http://arxiv.org/abs/2302.04166},
	abstract = {Generative Artificial Intelligence (AI) has enabled the development of sophisticated models that are capable of producing high-caliber text, images, and other outputs through the utilization of large pre-trained models. Nevertheless, assessing the quality of the generation is an even more arduous task than the generation itself, and this issue has not been given adequate consideration recently. This paper proposes a novel evaluation framework, GPTScore, which utilizes the emergent abilities (e.g., zero-shot instruction) of generative pre-trained models to score generated texts. There are 19 pre-trained models explored in this paper, ranging in size from 80M (e.g., FLAN-T5-small) to 175B (e.g., GPT3). Experimental results on four text generation tasks, 22 evaluation aspects, and corresponding 37 datasets demonstrate that this approach can effectively allow us to achieve what one desires to evaluate for texts simply by natural language instructions. This nature helps us overcome several long-standing challenges in text evaluation--how to achieve customized, multi-faceted evaluation without the need for annotated samples. We make our code publicly available at https://github.com/jinlanfu/GPTScore.},
	language = {en},
	urldate = {2024-06-24},
	publisher = {arXiv},
	author = {Fu, Jinlan and Ng, See-Kiong and Jiang, Zhengbao and Liu, Pengfei},
	month = feb,
	year = {2023},
	note = {arXiv:2302.04166 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Fu et al. - 2023 - GPTScore Evaluate as You Desire.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\588MW3EY\\Fu et al. - 2023 - GPTScore Evaluate as You Desire.pdf:application/pdf},
}

@misc{liu_g-eval_2023,
	title = {G-{Eval}: {NLG} {Evaluation} using {GPT}-4 with {Better} {Human} {Alignment}},
	shorttitle = {G-{Eval}},
	url = {http://arxiv.org/abs/2303.16634},
	abstract = {The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the benefit of being applicable to new tasks that lack human references. However, these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present G-Eval, a framework of using large language models with chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of NLG outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that G-Eval with GPT-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperforming all previous methods by a large margin. We also propose preliminary analysis on the behavior of LLM-based evaluators, and highlight the potential issue of LLM-based evaluators having a bias towards the LLM-generated texts. The code is at https://github.com/nlpyang/geval},
	language = {en},
	urldate = {2024-06-24},
	publisher = {arXiv},
	author = {Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
	month = may,
	year = {2023},
	note = {arXiv:2303.16634 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Liu et al. - 2023 - G-Eval NLG Evaluation using GPT-4 with Better Hum.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ZXRDKLQ4\\Liu et al. - 2023 - G-Eval NLG Evaluation using GPT-4 with Better Hum.pdf:application/pdf},
}

@misc{kim_prometheus_2024,
	title = {Prometheus: {Inducing} {Fine}-grained {Evaluation} {Capability} in {Language} {Models}},
	shorttitle = {Prometheus},
	url = {http://arxiv.org/abs/2310.08491},
	abstract = {Recently, using a powerful proprietary Large Language Model (LLM) (e.g., GPT4) as an evaluator for long-form responses has become the de facto standard. However, for practitioners with large-scale evaluation tasks and custom criteria in consideration (e.g., child-readability), using proprietary LLMs as an evaluator is unreliable due to the closed-source nature, uncontrolled versioning, and prohibitive costs. In this work, we propose PROMETHEUS, a fully open-source LLM that is on par with GPT-4’s evaluation capabilities when the appropriate reference materials (reference answer, score rubric) are accompanied. We first construct the FEEDBACK COLLECTION, a new dataset that consists of 1K fine-grained score rubrics, 20K instructions, and 100K responses and language feedback generated by GPT-4. Using the FEEDBACK COLLECTION, we train PROMETHEUS, a 13B evaluator LLM that can assess any given long-form text based on customized score rubric provided by the user. Experimental results show that PROMETHEUS scores a Pearson correlation of 0.897 with human evaluators when evaluating with 45 customized score rubrics, which is on par with GPT-4 (0.882), and greatly outperforms ChatGPT (0.392). Furthermore, measuring correlation with GPT-4 with 1222 customized score rubrics across four benchmarks (MT Bench, Vicuna Bench, Feedback Bench, Flask Eval) shows similar trends, bolstering PROMETHEUS’s capability as an evaluator LLM. Lastly, PROMETHEUS achieves the highest accuracy on two human preference benchmarks (HHH Alignment \& MT Bench Human Judgment) compared to open-sourced reward models explicitly trained on human preference datasets, highlighting its potential as an universal reward model. We open-source our code, dataset, and model 1.},
	language = {en},
	urldate = {2024-06-24},
	publisher = {arXiv},
	author = {Kim, Seungone and Shin, Jamin and Cho, Yejin and Jang, Joel and Longpre, Shayne and Lee, Hwaran and Yun, Sangdoo and Shin, Seongjin and Kim, Sungdong and Thorne, James and Seo, Minjoon},
	month = mar,
	year = {2024},
	note = {arXiv:2310.08491 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: ICLR 2024},
	file = {Kim et al. - 2024 - Prometheus Inducing Fine-grained Evaluation Capab.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\3KDJHIAQ\\Kim et al. - 2024 - Prometheus Inducing Fine-grained Evaluation Capab.pdf:application/pdf},
}

@misc{tang_not_2024,
	title = {Not {All} {Metrics} {Are} {Guilty}: {Improving} {NLG} {Evaluation} by {Diversifying} {References}},
	shorttitle = {Not {All} {Metrics} {Are} {Guilty}},
	url = {http://arxiv.org/abs/2305.15067},
	abstract = {Most research about natural language generation (NLG) relies on evaluation benchmarks with limited references for a sample, which may result in poor correlations with human judgements. The underlying reason is that one semantic meaning can actually be expressed in different forms, and the evaluation with a single or few references may not accurately reflect the quality of the model’s hypotheses. To address this issue, this paper presents a simple and effective method, named Div-Ref, to enhance existing evaluation benchmarks by enriching the number of references. We leverage large language models (LLMs) to diversify the expression of a single reference into multiple high-quality ones to cover the semantic space of the reference sentence as much as possible. We conduct comprehensive experiments to empirically demonstrate that diversifying the expression of reference can significantly enhance the correlation between automatic evaluation and human evaluation. This idea is compatible with recent LLM-based evaluation which can similarly derive advantages from incorporating multiple references. We strongly encourage future generation benchmarks to include more references, even if they are generated by LLMs, which is once for all. We release all the code and data at https://github.com/RUCAIBox/Div-Ref to facilitate research.},
	language = {en},
	urldate = {2024-06-24},
	publisher = {arXiv},
	author = {Tang, Tianyi and Lu, Hongyuan and Jiang, Yuchen Eleanor and Huang, Haoyang and Zhang, Dongdong and Zhao, Wayne Xin and Kocmi, Tom and Wei, Furu},
	month = may,
	year = {2024},
	note = {arXiv:2305.15067 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted by NAACL 2024},
	file = {Tang et al. - 2024 - Not All Metrics Are Guilty Improving NLG Evaluati.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\CKZV569Q\\Tang et al. - 2024 - Not All Metrics Are Guilty Improving NLG Evaluati.pdf:application/pdf},
}

@article{grimmer_text_2013,
	title = {Text as {Data}: {The} {Promise} and {Pitfalls} of {Automatic} {Content} {Analysis} {Methods} for {Political} {Texts}},
	volume = {21},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Text as {Data}},
	url = {https://www.cambridge.org/core/product/identifier/S1047198700013401/type/journal_article},
	doi = {10.1093/pan/mps028},
	abstract = {Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods—they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.},
	language = {en},
	number = {3},
	urldate = {2024-08-03},
	journal = {Political Analysis},
	author = {Grimmer, Justin and Stewart, Brandon M.},
	year = {2013},
	pages = {267--297},
	file = {Grimmer und Stewart - 2013 - Text as Data The Promise and Pitfalls of Automati.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\F6WS3MNL\\Grimmer und Stewart - 2013 - Text as Data The Promise and Pitfalls of Automati.pdf:application/pdf},
}

@article{magesh_hallucination-free_nodate,
	title = {Hallucination-{Free}? {Assessing} the {Reliability} of {Leading} {AI} {Legal} {Research} {Tools}},
	language = {en},
	author = {Magesh, Varun and Suzgun, Mirac and Surani, Faiz and Manning, Christopher D and Dahl, Matthew and Ho, Daniel E},
	keywords = {OS, LLM - Hallucination Detection in leading AI Legal Research Tools},
	file = {Magesh et al. - Hallucination-Free Assessing the Reliability of L.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\588WH4J6\\Magesh et al. - Hallucination-Free Assessing the Reliability of L.pdf:application/pdf},
}

@article{sargeant_topic_2024,
	title = {Topic {Modelling} {Case} {Law} {Using} a {Large} {Language} {Model} and a {New} {Taxonomy} for {UK} {Law}: {AI} {Insights} into {Summary} {Judgment}},
	issn = {1556-5068},
	shorttitle = {Topic {Modelling} {Case} {Law} {Using} a {Large} {Language} {Model} and a {New} {Taxonomy} for {UK} {Law}},
	url = {https://www.ssrn.com/abstract=4836558},
	doi = {10.2139/ssrn.4836558},
	abstract = {This paper addresses a critical gap in legal analytics by developing and applying a novel taxonomy for topic modelling summary judgment cases in the United Kingdom. Using a curated dataset of summary judgment cases, we use the Large Language Model Claude 3 Opus to explore functional topics and trends. We find that Claude 3 Opus correctly classified the topic with an accuracy of 87.10\%. The analysis reveals distinct patterns in the application of summary judgments across various legal domains. As case law in the United Kingdom is not originally labelled with keywords or a topic filtering option, the findings not only refine our understanding of the thematic underpinnings of summary judgments but also illustrate the potential of combining traditional and AI-driven approaches in legal classification. Therefore, this paper provides a new and general taxonomy for UK law. The implications of this work serve as a foundation for further research and policy discussions in the field of judicial administration and computational legal research methodologies.},
	language = {en},
	urldate = {2024-07-25},
	journal = {SSRN Electronic Journal},
	author = {Sargeant, Holli and Izzidien, Ahmed and Steffek, Felix},
	year = {2024},
	file = {Sargeant et al. - 2024 - Topic Modelling Case Law Using a Large Language Mo.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\93J679I4\\Sargeant et al. - 2024 - Topic Modelling Case Law Using a Large Language Mo.pdf:application/pdf},
}

@misc{xu_large_2024,
	title = {Large {Language} {Models} for {Generative} {Information} {Extraction}: {A} {Survey}},
	shorttitle = {Large {Language} {Models} for {Generative} {Information} {Extraction}},
	url = {http://arxiv.org/abs/2312.17617},
	abstract = {Abstract Information extraction (IE) aims to extract structural knowledge from plain natural language texts. Recently, generative Large Language Models (LLMs) have demonstrated remarkable capabilities in text understanding and generation. As a result, numerous works have been proposed to integrate LLMs for IE tasks based on a generative paradigm. To conduct a comprehensive systematic review and exploration of LLM efforts for IE tasks, in this study, we survey the most recent advancements in this field. We first present an extensive overview by categorizing these works in terms of various IE subtasks and techniques, and then we empirically analyze the most advanced methods and discover the emerging trend of IE tasks with LLMs. Based on a thorough review conducted, we identify several insights in technique and promising research directions that deserve further exploration in future studies. We maintain a public repository and consistently update related resources 1.},
	language = {en},
	urldate = {2024-10-22},
	publisher = {arXiv},
	author = {Xu, Derong and Chen, Wei and Peng, Wenjun and Zhang, Chao and Xu, Tong and Zhao, Xiangyu and Wu, Xian and Zheng, Yefeng and Wang, Yang and Chen, Enhong},
	month = jun,
	year = {2024},
	note = {arXiv:2312.17617 [cs]},
	keywords = {Computer Science - Computation and Language, SW, Information Extraction},
	annote = {Comment: v2: Updated 100+ new papers, 5 technical categories},
	file = {Xu et al. - 2024 - Large Language Models for Generative Information E.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\P8X5M5Z4\\Xu et al. - 2024 - Large Language Models for Generative Information E.pdf:application/pdf},
}

@misc{yurtsev_kor_nodate,
	type = {Github {Pages}},
	title = {Kor 2.0.0},
	url = {https://eyurtsev.github.io/kor/tutorial.html},
	author = {Yurtsev, Eugene},
	keywords = {SW, Information Extraction},
	annote = {Potentially promising approach for information extraction
},
}

@misc{schulhoff_prompt_2024,
	title = {The {Prompt} {Report}: {A} {Systematic} {Survey} of {Prompting} {Techniques}},
	shorttitle = {The {Prompt} {Report}},
	url = {http://arxiv.org/abs/2406.06608},
	abstract = {Generative Artificial Intelligence (GenAI) systems are being increasingly deployed across all parts of industry and research settings. Developers and end users interact with these systems through the use of prompting or prompt engineering. While prompting is a widespread and highly researched concept, there exists conflicting terminology and a poor ontological understanding of what constitutes a prompt due to the area’s nascency. This paper establishes a structured understanding of prompts, by assembling a taxonomy of prompting techniques and analyzing their use. We present a comprehensive vocabulary of 33 vocabulary terms, a taxonomy of 58 text-only prompting techniques, and 40 techniques for other modalities. We further present a meta-analysis of the entire literature on natural language prefix-prompting.},
	language = {en},
	urldate = {2024-10-22},
	publisher = {arXiv},
	author = {Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and Dulepet, Pranav Sandeep and Vidyadhara, Saurav and Ki, Dayeon and Agrawal, Sweta and Pham, Chau and Kroiz, Gerson and Li, Feileen and Tao, Hudson and Srivastava, Ashay and Costa, Hevander Da and Gupta, Saloni and Rogers, Megan L. and Goncearenco, Inna and Sarli, Giuseppe and Galynker, Igor and Peskoff, Denis and Carpuat, Marine and White, Jules and Anadkat, Shyamal and Hoyle, Alexander and Resnik, Philip},
	month = jul,
	year = {2024},
	note = {arXiv:2406.06608 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, SW, Prompting},
	annote = {Interesting overview for what techniques exist (kind of like a dictionary)
},
	file = {Schulhoff et al. - 2024 - The Prompt Report A Systematic Survey of Promptin.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\F65D88RD\\Schulhoff et al. - 2024 - The Prompt Report A Systematic Survey of Promptin.pdf:application/pdf},
}

@incollection{sileno_information_2023,
	title = {Information {Extraction} from {Lengthy} {Legal} {Contracts}: {Leveraging} {Query}-{Based} {Summarization} and {GPT}-3.5},
	copyright = {https://creativecommons.org/licenses/by-nc/4.0/},
	isbn = {978-1-64368-472-7 978-1-64368-473-4},
	shorttitle = {Information {Extraction} from {Lengthy} {Legal} {Contracts}},
	url = {https://ebooks.iospress.nl/doi/10.3233/FAIA230963},
	abstract = {In the legal domain, extracting information from contracts poses significant challenges, primarily due to the scarcity of annotated data. In such situations, leveraging large language models (LLMs), such as the Generative Pretrained Transformer (GPT) models, offers a promising solution. However, the inherent token limitations of these models can be a bottleneck for processing lengthy legal contracts. This paper presents an unsupervised two-step approach to address these challenges. First, we propose a query-based summarization model that extracts sentences pertinent to predefined queries, concisely representing lengthy contracts. This summarization ensures that the core information remains intact while simultaneously addressing the token limitation issue. Subsequently, the generated summary is fed to GPT-3.5 for precise information extraction. Our approach effectively overcomes the challenges of token limitations and zero resources, enabling efficient and scalable information extraction from legal contracts. We compare our results with those obtained from supervised models that have been finetuned on domain-specific annotated data. Experimental results demonstrate the remarkable effectiveness of our approach, as it achieves state-of-the-art performance without the need for domain-specific training data.},
	language = {en},
	urldate = {2024-10-22},
	booktitle = {Frontiers in {Artificial} {Intelligence} and {Applications}},
	publisher = {IOS Press},
	author = {Zin, May Myo and Nguyen, Ha Thanh and Satoh, Ken and Sugawara, Saku and Nishino, Fumihito},
	editor = {Sileno, Giovanni and Spanakis, Jerry and Van Dijck, Gijs},
	month = dec,
	year = {2023},
	doi = {10.3233/FAIA230963},
	keywords = {SW, Information Extraction},
	annote = {Super interesting approach, work through this in even greater detail (SW)
},
	file = {Zin et al. - 2023 - Information Extraction from Lengthy Legal Contract.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\B2EMJBQM\\Zin et al. - 2023 - Information Extraction from Lengthy Legal Contract.pdf:application/pdf},
}

@article{dagdelen_structured_2024,
	title = {Structured information extraction from scientific text with large language models},
	volume = {15},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-024-45563-x},
	doi = {10.1038/s41467-024-45563-x},
	abstract = {Abstract
            Extracting structured knowledge from scientific text remains a challenging task for machine learning models. Here, we present a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models (GPT-3, Llama-2) can be fine-tuned to extract useful records of complex scientific knowledge. We test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks, and general composition/phase/morphology/application information extraction. Records are extracted from single sentences or entire paragraphs, and the output can be returned as simple English sentences or a more structured format such as a list of JSON objects. This approach represents a simple, accessible, and highly flexible route to obtaining large databases of structured specialized scientific knowledge extracted from research papers.},
	language = {en},
	number = {1},
	urldate = {2024-10-22},
	journal = {Nature Communications},
	author = {Dagdelen, John and Dunn, Alexander and Lee, Sanghoon and Walker, Nicholas and Rosen, Andrew S. and Ceder, Gerbrand and Persson, Kristin A. and Jain, Anubhav},
	month = feb,
	year = {2024},
	keywords = {SW, Information Extraction, OS, Information Extraction - Scientific Texts},
	pages = {1418},
	annote = {Here they specifically use Finetuning for Information Extraction tasks.
},
	file = {Dagdelen et al. - 2024 - Structured information extraction from scientific .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\7GPXGU2C\\Dagdelen et al. - 2024 - Structured information extraction from scientific .pdf:application/pdf},
}

@article{izzidien_llm_2024,
	title = {{LLM} vs. {Lawyers}: {Identifying} a {Subset} of {Summary} {Judgments} in a {Large} {UK} {Case} {Law} {Dataset}},
	issn = {1556-5068},
	shorttitle = {{LLM} vs. {Lawyers}},
	url = {https://www.ssrn.com/abstract=4746305},
	doi = {10.2139/ssrn.4746305},
	abstract = {To undertake computational research of the law, efficiently identifying datasets of court decisions that relate to a specific legal issue is a crucial yet challenging endeavour. This study addresses the gap in the literature working with large legal corpora about how to isolate cases, in our case summary judgments, from a large corpus of UK court decisions. We introduce a comparative analysis of two computational methods: (1) a traditional natural language processing-based approach leveraging expert-generated keywords and logical operators and (2) an innovative application of the Claude 2 large language model to classify cases based on content-specific prompts. We use the Cambridge Law Corpus of 356,011 UK court decisions and determine that the large language model achieves a weighted F1 score of 0.94 versus 0.78 for keywords. Despite iterative refinement, the search logic based on keywords fails to capture nuances in legal language. We identify and extract 3,102 summary judgment cases, enabling us to map their distribution across various UK courts over a temporal span. The paper marks a pioneering step in employing advanced natural language processing to tackle core legal research tasks, demonstrating how these technologies can bridge systemic gaps and enhance the accessibility of legal information. We share the extracted dataset metrics to support further research on summary judgments.},
	language = {en},
	urldate = {2024-10-24},
	journal = {SSRN Electronic Journal},
	author = {Izzidien, Ahmed and Sargeant, Holli and Steffek, Felix},
	year = {2024},
	keywords = {LLM Evaluation, SW},
	file = {Izzidien et al. - 2024 - LLM vs. Lawyers Identifying a Subset of Summary J.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\B6QJ9Z7Z\\Izzidien et al. - 2024 - LLM vs. Lawyers Identifying a Subset of Summary J.pdf:application/pdf},
}

@article{pereira_inacia_2024,
	title = {{INACIA}: {Integrating} {Large} {Language} {Models} in {Brazilian} {Audit} {Courts}: {Opportunities} and {Challenges}},
	issn = {2691-199X, 2639-0175},
	shorttitle = {{INACIA}},
	url = {https://dl.acm.org/doi/10.1145/3652951},
	doi = {10.1145/3652951},
	abstract = {This paper introduces INACIA (
              In
              strução
              A
              ssistida
              c
              om
              I
              nteligência
              A
              rtificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case analysis, including basic information extraction, admissibility examination,
              Periculum in mora
              and
              Fumus boni iuris
              analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA’s potential in extracting relevant information from case documents, evaluating its legal plausibility, and formulating propositions for judicial decision-making. Utilizing a validation dataset alongside LLMs, our evaluation methodology presents a novel approach to assessing system performance, correlating highly with human judgment. These results underscore INACIA’s potential in complex legal task handling while also acknowledging the current limitations. This study discusses possible improvements and the broader implications of applying AI in legal contexts, suggesting that INACIA represents a significant step towards integrating AI in legal systems globally, albeit with cautious optimism grounded in the empirical findings.},
	language = {en},
	urldate = {2024-10-24},
	journal = {Digital Government: Research and Practice},
	author = {Pereira, Jayr and Assumpcao, Andre and Trecenti, Julio and Airosa, Luiz and Lente, Caio and Cléto, Jhonatan and Dobins, Guilherme and Nogueira, Rodrigo and Mitchell, Luis and Lotufo, Roberto},
	month = mar,
	year = {2024},
	keywords = {LLM Evaluation, SW, Information Extraction},
	pages = {3652951},
	annote = {See page 9 for a great prompt example
},
	annote = {Their approach looks “somewhat” similar to ours. Can we use their approach to evaluation for our endeavor?
},
	file = {Pereira et al. - 2024 - INACIA Integrating Large Language Models in Brazi.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\25IACIFV\\Pereira et al. - 2024 - INACIA Integrating Large Language Models in Brazi.pdf:application/pdf},
}

@misc{trozze_large_2024,
	title = {Large {Language} {Models} in {Cryptocurrency} {Securities} {Cases}: {Can} a {GPT} {Model} {Meaningfully} {Assist} {Lawyers}?},
	shorttitle = {Large {Language} {Models} in {Cryptocurrency} {Securities} {Cases}},
	url = {http://arxiv.org/abs/2308.06032},
	abstract = {Large Language Models (LLMs) could be a useful tool for lawyers. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying GPT-3.5's legal reasoning and ChatGPT's legal drafting capabilities. We examine whether a) GPT-3.5 can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to ChatGPT. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by ChatGPT and lawyers. GPT-3.5's legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely missed additional, correct violations). ChatGPT performed better at legal drafting, and jurors' decisions were not statistically significantly associated with the author of the document upon which they based their decisions. Because GPT-3.5 cannot satisfactorily conduct legal reasoning tasks, it would be unlikely to be able to help lawyers in a meaningful way at this stage. However, ChatGPT's drafting skills (though, perhaps, still inferior to lawyers) could assist lawyers in providing legal services. Our research is the first to systematically study an LLM's legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.},
	language = {en},
	urldate = {2024-10-24},
	publisher = {arXiv},
	author = {Trozze, Arianna and Davies, Toby and Kleinberg, Bennett},
	month = feb,
	year = {2024},
	note = {arXiv:2308.06032 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, LLM Evaluation, SW},
	annote = {How did they come up with their score?
--{\textgreater} my conclusion: not too reliable
},
	file = {Trozze et al. - 2024 - Large Language Models in Cryptocurrency Securities.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\6SYZGG9U\\Trozze et al. - 2024 - Large Language Models in Cryptocurrency Securities.pdf:application/pdf},
}

@misc{chu_better_2024,
	title = {A {Better} {LLM} {Evaluator} for {Text} {Generation}: {The} {Impact} of {Prompt} {Output} {Sequencing} and {Optimization}},
	shorttitle = {A {Better} {LLM} {Evaluator} for {Text} {Generation}},
	url = {http://arxiv.org/abs/2406.09972},
	doi = {10.11517/pjsai.JSAI2024.0_2G5GS604},
	abstract = {This research investigates prompt designs of evaluating generated texts using large language models (LLMs). While LLMs are increasingly used for scoring various inputs, creating effective prompts for open-ended text evaluation remains challenging due to model sensitivity and subjectivity in evaluation of text generation. Our study experimented with different prompt structures, altering the sequence of output instructions and including explanatory reasons. We found that the order of presenting reasons and scores significantly influences LLMs' scoring, with a different level of rule understanding in the prompt. An additional optimization may enhance scoring alignment if sufficient data is available. This insight is crucial for improving the accuracy and consistency of LLM-based evaluations.},
	language = {en},
	urldate = {2024-10-24},
	author = {Chu, KuanChao and Chen, Yi-Pei and Nakayama, Hideki},
	year = {2024},
	note = {arXiv:2406.09972 [cs]},
	keywords = {Computer Science - Computation and Language, LLM Evaluation, SW},
	annote = {Comment: Presented in JSAI 2024. The first two authors contributed equally. arXiv admin note: substantial text overlap with arXiv:2406.02863},
	annote = {Interesting take on specific aspects to think about when using an LLM for output evaluation.

I still need to find out what exactly specific components mentioned here mean and how they could be implemented for our endeavor.
},
	file = {Chu et al. - 2024 - A Better LLM Evaluator for Text Generation The Im.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ADJGAP5F\\Chu et al. - 2024 - A Better LLM Evaluator for Text Generation The Im.pdf:application/pdf},
}

@misc{qin_is_2023,
	title = {Is {ChatGPT} a {General}-{Purpose} {Natural} {Language} {Processing} {Task} {Solver}?},
	url = {http://arxiv.org/abs/2302.06476},
	abstract = {Spurred by advancements in scale, large language models (LLMs) have demonstrated the ability to perform a variety of natural language processing (NLP) tasks zero-shot—i.e., without adaptation on downstream data. Recently, the debut of ChatGPT 1 has drawn a great deal of attention from the natural language processing (NLP) community due to the fact that it can generate high-quality responses to human input and self-correct previous mistakes based on subsequent conversations. However, it is not yet known whether ChatGPT can serve as a generalist model that can perform many NLP tasks zero-shot. In this work, we empirically analyze the zero-shot learning ability of ChatGPT by evaluating it on 20 popular NLP datasets covering 7 representative task categories. With extensive empirical studies, we demonstrate both the effectiveness and limitations of the current version of ChatGPT. We find that ChatGPT performs well on many tasks favoring reasoning capabilities (e.g., arithmetic reasoning) while it still faces challenges when solving specific tasks such as sequence tagging. We additionally provide in-depth analysis through qualitative case studies.},
	language = {en},
	urldate = {2024-09-14},
	publisher = {arXiv},
	author = {Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
	month = nov,
	year = {2023},
	note = {arXiv:2302.06476 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, LLM - GPT Ability of Zero Shot Learning, OS},
	file = {Qin et al. - 2023 - Is ChatGPT a General-Purpose Natural Language Proc.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\QUYUFTZA\\Qin et al. - 2023 - Is ChatGPT a General-Purpose Natural Language Proc.pdf:application/pdf},
}

@book{qamar_applied_2024,
	address = {Cham},
	title = {Applied {Text} {Mining}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-51916-1 978-3-031-51917-8},
	url = {https://link.springer.com/10.1007/978-3-031-51917-8},
	language = {en},
	urldate = {2024-07-29},
	publisher = {Springer Nature Switzerland},
	author = {Qamar, Usman and Raza, Muhammad Summair},
	year = {2024},
	doi = {10.1007/978-3-031-51917-8},
	keywords = {OS, Book - Applied Text Mining},
	file = {Qamar und Raza - 2024 - Applied Text Mining.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\JPQJWSFT\\Qamar und Raza - 2024 - Applied Text Mining.pdf:application/pdf},
}

@inproceedings{plank_problem_2022,
	address = {Abu Dhabi, United Arab Emirates},
	title = {The “{Problem}” of {Human} {Label} {Variation}: {On} {Ground} {Truth} in {Data}, {Modeling} and {Evaluation}},
	shorttitle = {The “{Problem}” of {Human} {Label} {Variation}},
	url = {https://aclanthology.org/2022.emnlp-main.731},
	doi = {10.18653/v1/2022.emnlp-main.731},
	abstract = {Human variation in labeling is often considered noise. Annotation projects for machine learning (ML) aim at minimizing human label variation, with the assumption to maximize data quality and in turn optimize and maximize machine learning metrics. However, this conventional practice assumes that there exists a ground truth, and neglects that there exists genuine human variation in labeling due to disagreement, subjectivity in annotation or multiple plausible answers. In this position paper, we argue that this big open problem of human label variation persists and critically needs more attention to move our field forward. This is because human label variation impacts all stages of the ML pipeline: data, modeling and evaluation. However, few works consider all of these dimensions jointly; and existing research is fragmented. We reconcile different previously proposed notions of human label variation, provide a repository of publicly-available datasets with un-aggregated labels, depict approaches proposed so far, identify gaps and suggest ways forward. As datasets are becoming increasingly available, we hope that this synthesized view on the “problem” will lead to an open discussion on possible strategies to devise fundamentally new directions.},
	language = {en},
	urldate = {2024-09-07},
	booktitle = {Proceedings of the 2022 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Plank, Barbara},
	year = {2022},
	keywords = {OS, LLM - Human Label Variation},
	pages = {10671--10682},
	file = {Plank - 2022 - The “Problem” of Human Label Variation On Ground .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\CNLFEXQ6\\Plank - 2022 - The “Problem” of Human Label Variation On Ground .pdf:application/pdf},
}

@book{phoenix_prompt_2024,
	address = {Beijing Boston},
	edition = {First edition},
	title = {Prompt engineering for generative {AI}: future-proof inputs for reliable {AI} outputs at scale},
	isbn = {978-1-09-815343-4},
	shorttitle = {Prompt engineering for generative {AI}},
	abstract = {Large language models (LLMs) and diffusion models such as ChatGPT and Stable Diffusion have unprecedented potential. Because they have been trained on all the public text and images on the internet, they can make useful contributions to a wide variety of tasks. And with the barrier to entry greatly reduced today, practically any developer can harness LLMs and diffusion models to tackle problems previously unsuitable for automation. With this book, you'll gain a solid foundation in generative AI, including how to apply these models in practice. When first integrating LLMs and diffusion models into their workflows, most developers struggle to coax reliable enough results from them to use in automated systems. Authors James Phoenix and Mike Taylor show you how a set of principles called prompt engineering can enable you to work effectively with AI. --},
	language = {en},
	publisher = {O'Reilly},
	author = {Phoenix, James and Taylor, Mike},
	year = {2024},
	keywords = {OS, Book - Prompt Engeneering for Generative AI},
	file = {Phoenix und Taylor - 2024 - Prompt engineering for generative AI future-proof.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\8FE9PGF9\\Phoenix und Taylor - 2024 - Prompt engineering for generative AI future-proof.pdf:application/pdf},
}

@article{ozdemir_quick_nodate,
	title = {Quick {Start} {Guide} to {Large} {Language} {Models}, {Second} {Edition}},
	language = {en},
	author = {Ozdemir, Sinan},
	keywords = {OS, Book - LLMs - Quick Start Guide},
	file = {Ozdemir - Quick Start Guide to Large Language Models, Second.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ISMUMDVB\\Ozdemir - Quick Start Guide to Large Language Models, Second.pdf:application/pdf},
}

@article{ostling_cambridge_2023,
	title = {The {Cambridge} {Law} {Corpus}: {A} {Dataset} for {Legal} {AI} {Research}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {The {Cambridge} {Law} {Corpus}},
	url = {https://arxiv.org/abs/2309.12269},
	doi = {10.48550/ARXIV.2309.12269},
	abstract = {We introduce the Cambridge Law Corpus (CLC), a dataset for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.},
	language = {en},
	urldate = {2024-09-10},
	author = {Östling, Andreas and Sargeant, Holli and Xie, Huiyuan and Bull, Ludwig and Terenin, Alexander and Jonsson, Leif and Magnusson, Måns and Steffek, Felix},
	year = {2023},
	note = {Publisher: arXiv
Version Number: 4},
	keywords = {OS, Applications (stat.AP), Computation and Language (cs.CL), Computers and Society (cs.CY), FOS: Computer and information sciences, Legal Data - Bias},
	file = {Östling et al. - 2023 - The Cambridge Law Corpus A Dataset for Legal AI R.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\KWTF58TZ\\Östling et al. - 2023 - The Cambridge Law Corpus A Dataset for Legal AI R.pdf:application/pdf},
}

@book{nugues_python_2024,
	address = {Cham},
	series = {Cognitive {Technologies}},
	title = {Python for {Natural} {Language} {Processing}: {Programming} with {NumPy}, scikit-learn, {Keras}, and {PyTorch}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-57548-8 978-3-031-57549-5},
	shorttitle = {Python for {Natural} {Language} {Processing}},
	url = {https://link.springer.com/10.1007/978-3-031-57549-5},
	language = {en},
	urldate = {2024-08-03},
	publisher = {Springer Nature Switzerland},
	author = {Nugues, Pierre M.},
	year = {2024},
	doi = {10.1007/978-3-031-57549-5},
	keywords = {Book - NLP - Python},
	file = {Nugues - 2024 - Python for Natural Language Processing Programmin.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\PSJ4B7E5\\Nugues - 2024 - Python for Natural Language Processing Programmin.pdf:application/pdf},
}

@article{naik_enhancing_2024,
	title = {Enhancing {Semantic} {Searching} of {Legal} {Documents} {Through} {LSTM}-{Based} {Named} {Entity} {Recognition} and {Semantic} {Classification}},
	issn = {0952-8059, 1572-8722},
	url = {https://link.springer.com/10.1007/s11196-024-10157-9},
	doi = {10.1007/s11196-024-10157-9},
	abstract = {In natural language processing (NLP), named entity recognition (NER) and semantic classification are essential tasks. NER is a fundamental task, that identify named entities in text such as people, organizations, and locations. In Legal domain, NER is particularly important due to the variety of named entities that appear in legal documents and are important for legal analysis whereas Semantic classification is the process of giving each sentence in a text a semantic label, such as ”fact,””arguments,” or”judgement”. Both NER and Semantic classi- fication are critical component of many NLP applications such as Knowledge base construction and semantic search. Semantic searching of legal documents is a powerful technique that can be used to quickly find the information that you need. By combining NER and semantic classification, one can identify the key elements of a legal document and search for documents that are related to a particular topic or contain a particular type of information. This paper proposes a novel approach to NER and Semantic classification in legal domain using Long short-term memory (LSTM) model. The proposed approach is evaluated on a corpus of legal text and the result of this study suggest that LSTM models are a promising approach for NER and Semantic classification in legal domain and can be used to improve the performance of semantic searching of legal documents.},
	language = {en},
	urldate = {2024-08-06},
	journal = {International Journal for the Semiotics of Law - Revue internationale de Sémiotique juridique},
	author = {Naik, Varsha and K, Rajeswari and Patel, Purvang},
	month = apr,
	year = {2024},
	keywords = {OS, LLM - Enhancing Semantic Searching with LSTM-NER},
	file = {Naik et al. - 2024 - Enhancing Semantic Searching of Legal Documents Th.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\27FK66AX\\Naik et al. - 2024 - Enhancing Semantic Searching of Legal Documents Th.pdf:application/pdf},
}

@book{nagy_regex_2018,
	address = {Berkeley, CA},
	title = {Regex {Quick} {Syntax} {Reference}: {Understanding} and {Using} {Regular} {Expressions}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-1-4842-3875-2 978-1-4842-3876-9},
	shorttitle = {Regex {Quick} {Syntax} {Reference}},
	url = {http://link.springer.com/10.1007/978-1-4842-3876-9},
	language = {en},
	urldate = {2024-08-03},
	publisher = {Apress},
	author = {Nagy, Zsolt},
	year = {2018},
	doi = {10.1007/978-1-4842-3876-9},
	keywords = {OS, Book - RegEx - Quick Syntax Reference},
	file = {Nagy - 2018 - Regex Quick Syntax Reference Understanding and Us.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\FE9MVBS7\\Nagy - 2018 - Regex Quick Syntax Reference Understanding and Us.pdf:application/pdf},
}

@book{monkman_data_2024,
	address = {Boca Raton},
	edition = {1},
	title = {The {Data} {Preparation} {Journey}: {Finding} {Your} {Way} with {R}},
	isbn = {978-1-00-325825-4},
	shorttitle = {The {Data} {Preparation} {Journey}},
	url = {https://www.taylorfrancis.com/books/9781003258254},
	language = {en},
	urldate = {2024-08-03},
	publisher = {Chapman and Hall/CRC},
	author = {Monkman, Martin Hugh},
	month = may,
	year = {2024},
	doi = {10.1201/9781003258254},
	keywords = {OS, Data Preparation - With R},
	file = {Monkman - 2024 - The Data Preparation Journey Finding Your Way wit.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\HPBKH9UL\\Monkman - 2024 - The Data Preparation Journey Finding Your Way wit.pdf:application/pdf},
}

@book{mitkov_oxford_2014,
	edition = {2},
	title = {The {Oxford} {Handbook} of {Computational} {Linguistics} 2nd edition},
	isbn = {978-0-19-957369-1 978-0-19-174964-3},
	url = {https://academic.oup.com/edited-volume/42643},
	abstract = {This handbook is currently in development, with individual articles publishing online in advance of print publication. At this time, we cannot add information about unpublished articles in this handbook, however the table of contents will continue to grow as additional articles pass through the review process and are added to the site. Please note that the online publication date for this handbook is the date that the first article in the title was published online. For more information, please read the site FAQs.},
	language = {en},
	urldate = {2024-09-17},
	publisher = {Oxford University Press},
	editor = {Mitkov, Ruslan},
	month = apr,
	year = {2014},
	doi = {10.1093/oxfordhb/9780199573691.001.0001},
	keywords = {OS, Book - Computational Lingustics - Fundamentals},
	file = {Mitkov - 2014 - The Oxford Handbook of Computational Linguistics 2.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\KL8QLAGI\\Mitkov - 2014 - The Oxford Handbook of Computational Linguistics 2.pdf:application/pdf},
}

@book{mitchell_web_2024,
	address = {Beijing Boston Farnham Sebastopol Tokyo},
	edition = {Third Edition},
	title = {Web {Scraping} with {Python}: {Data} {Extraction} from the {Modern} {Web}},
	isbn = {978-1-09-814535-4},
	shorttitle = {Web {Scraping} with {Python}},
	abstract = {This thoroughly updated third edition not only introduces you to web scraping but also serves as a comprehensive guide to scraping almost every type of data from the modern web},
	language = {en},
	publisher = {O'Reilly},
	author = {Mitchell, Ryan},
	year = {2024},
	keywords = {OS, Book - Web Scraping - Python},
	file = {Mitchell - 2024 - Web Scraping with Python Data Extraction from the.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\P4WWJ47Y\\Mitchell - 2024 - Web Scraping with Python Data Extraction from the.pdf:application/pdf},
}

@article{mielke_korpuslinguistik_2021,
	title = {Korpuslinguistik in der {Rechtswissenschaft}. {Eine} webbasierte {Analyseplattform} für {EuGH}-{Entscheidungen}},
	issn = {1664-848X},
	url = {https://jusletter-it.weblaw.ch/issues/2021/27-Mai-2021/03_legaltech_03.docx_d38a0791f4.html},
	doi = {10.38023/9b2a8ae5-fcc9-4df4-a599-3d2a59868ba5},
	language = {de},
	number = {27-Mai-2021},
	urldate = {2024-08-24},
	journal = {Jusletter-IT},
	author = {Mielke, Bettina and Wolff, Christian},
	year = {2021},
	keywords = {OS, Korpuslingustik in der Rechtswissenschaft - Beispiel EuGH Entscheide},
	file = {Mielke und Wolff - 2021 - Korpuslinguistik in der Rechtswissenschaft. Eine w.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\SLM2CDU4\\Mielke und Wolff - 2021 - Korpuslinguistik in der Rechtswissenschaft. Eine w.pdf:application/pdf},
}

@book{mertz_regular_2023,
	address = {Shelter Island, NY},
	edition = {First edition},
	title = {Regular expression puzzles and {AI} coding assistants: 24 puzzles solved by the author, with and without assistance from {Copilot}, {ChatGPT} and more},
	isbn = {978-1-63343-781-4},
	shorttitle = {Regular expression puzzles and {AI} coding assistants},
	abstract = {Learn how AI-assisted coding using ChatGPT and GitHub Copilot can dramatically increase your productivity (and fun) writing regular expressions and other programs. Regular Expression Puzzles and AI Coding Assistants is the story of two competitors. On one side is David Mertz, an expert programmer and the author of the Web's most popular Regex tutorial. On the other are the AI powerhouse coding assistants, GitHub Copilot and OpenAI ChatGPT. Here's how the contest works: David invents 24 Regex problems he calls puzzles and shows you how to tackle each one. When he's done, he has Copilot and ChatGPT work the same puzzles. What they produce intrigues him. Which side is likelier to get it right? Which will write simple and elegant code? Which makes smarter use of lesser known Regex library features? Read the book to find out. David also offers AI best practices, showing how smart prompts return better results. By the end, you'll be a master at solving your own Regex puzzles, whether you use AI or not},
	language = {en},
	publisher = {Manning Publications},
	author = {Mertz, David},
	year = {2023},
	note = {OCLC: 1373623486},
	keywords = {OS, Book - RegEx Puzzles},
	file = {Mertz - 2023 - Regular expression puzzles and AI coding assistant.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\7ZTDWCBX\\Mertz - 2023 - Regular expression puzzles and AI coding assistant.pdf:application/pdf},
}

@book{mertz_cleaning_2021,
	address = {S.l.},
	title = {Cleaning data for effective data science: doing the other 80\% of the work with {Python}, {R}, and command-line tools},
	isbn = {978-1-80107-440-7},
	shorttitle = {Cleaning data for effective data science},
	abstract = {A comprehensive guide for data scientists to master effective data cleaning tools and techniques Key Features Master data cleaning techniques in a language-agnostic manner Learn from intriguing hands-on examples from numerous domains, such as biology, weather data, demographics, physics, time series, and image processing Work with detailed, commented, well-tested code samples in Python and R Book Description It is something of a truism in data science, data analysis, or machine learning that most of the effort needed to achieve your actual purpose lies in cleaning your data. Written in David's signature friendly and humorous style, this book discusses in detail the essential steps performed in every production data science or data analysis pipeline and prepares you for data visualization and modeling results. The book dives into the practical application of tools and techniques needed for data ingestion, anomaly detection, value imputation, and feature engineering. It also offers long-form exercises at the end of each chapter to practice the skills acquired. You will begin by looking at data ingestion of data formats such as JSON, CSV, SQL RDBMSes, HDF5, NoSQL databases, files in image formats, and binary serialized data structures. Further, the book provides numerous example data sets and data files, which are available for download and independent exploration. Moving on from formats, you will impute missing values, detect unreliable data and statistical anomalies, and generate synthetic features that are necessary for successful data analysis and visualization goals. By the end of this book, you will have acquired a firm understanding of the data cleaning process necessary to perform real-world data science and machine learning tasks. What you will learn How to think carefully about your data and ask the right questions Identify problem data pertaining to individual data points Detect problem data in the systematic "shape" of the data Remediate data integrity and hygiene problems Prepare data for analytic and machine learning tasks Impute values into missing or unreliable data Generate synthetic features that are more amenable to data science, data analysis, or visualization goals. Who this book is for This book is designed to benefit software developers, data scientists, aspiring data scientists, and students who are interested in data analysis or scientific computing. Basic familiarity with statistics, general concepts in machine learning,..},
	language = {en},
	publisher = {Packt Publishing Limited},
	author = {Mertz, David},
	year = {2021},
	note = {OCLC: 1244742334},
	keywords = {OS, Book - Data Science - Data Cleaning},
	file = {Mertz - 2021 - Cleaning data for effective data science doing th.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\RXNS4Q32\\Mertz - 2021 - Cleaning data for effective data science doing th.pdf:application/pdf},
}

@misc{mcintosh_inadequacies_2024,
	title = {Inadequacies of {Large} {Language} {Model} {Benchmarks} in the {Era} of {Generative} {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2402.09880},
	abstract = {The rapid rise in popularity of Large Language Models (LLMs) with emerging capabilities has spurred public curiosity to evaluate and compare different LLMs, leading many researchers to propose their LLM benchmarks. Noticing preliminary inadequacies in those benchmarks, we embarked on a study to critically assess 23 state-of-the-art LLM benchmarks, using our novel uniﬁed evaluation framework through the lenses of people, process, and technology, under the pillars of functionality and security. Our research uncovered signiﬁcant limitations, including biases, difﬁculties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment. Our discussions emphasized the urgent need for standardized methodologies, regulatory certainties, and ethical guidelines in light of Artiﬁcial Intelligence (AI) advancements, including advocating for an evolution from static benchmarks to dynamic behavioral proﬁling to accurately capture LLMs’ complex behaviors and potential risks. Our study highlighted the necessity for a paradigm shift in LLM evaluation methodologies, underlining the importance of collaborative efforts for the development of universally accepted benchmarks and the enhancement of AI systems’ integration into society.},
	language = {en},
	urldate = {2024-09-10},
	publisher = {arXiv},
	author = {McIntosh, Timothy R. and Susnjak, Teo and Liu, Tong and Watters, Paul and Halgamuge, Malka N.},
	month = feb,
	year = {2024},
	note = {arXiv:2402.09880 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, OS, LLM - Benchmarking Critics},
	file = {McIntosh et al. - 2024 - Inadequacies of Large Language Model Benchmarks in.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\XGZ98EGA\\McIntosh et al. - 2024 - Inadequacies of Large Language Model Benchmarks in.pdf:application/pdf},
}

@book{martinetz_quick_2020,
	address = {Wiesbaden},
	series = {Quick {Guide}},
	title = {Quick {Guide} {Legal} {Tech}: {Schritt} für {Schritt} zur digitalen {Kanzlei} und {Rechtsabteilung}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-658-28552-4 978-3-658-28553-1},
	shorttitle = {Quick {Guide} {Legal} {Tech}},
	url = {http://link.springer.com/10.1007/978-3-658-28553-1},
	language = {de},
	urldate = {2024-07-13},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Martinetz, Sophie and Maringele, Sarah},
	year = {2020},
	doi = {10.1007/978-3-658-28553-1},
	keywords = {OS, Book - Legal Tech Overview},
	file = {Martinetz und Maringele - 2020 - Quick Guide Legal Tech Schritt für Schritt zur di.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\L37JK2VP\\Martinetz und Maringele - 2020 - Quick Guide Legal Tech Schritt für Schritt zur di.pdf:application/pdf},
}

@misc{martin_better_2024,
	title = {Better {Call} {GPT}, {Comparing} {Large} {Language} {Models} {Against} {Lawyers}},
	url = {http://arxiv.org/abs/2401.16212},
	abstract = {This paper presents a groundbreaking comparison between Large Language Models and traditional legal contract reviewers, Junior Lawyers and Legal Process Outsourcers. We dissect whether LLMs can outperform humans in accuracy, speed, and cost efficiency during contract review. Our empirical analysis benchmarks LLMs against a ground truth set by Senior Lawyers, uncovering that advanced models match or exceed human accuracy in determining legal issues. In speed, LLMs complete reviews in mere seconds, eclipsing the hours required by their human counterparts. Cost wise, LLMs operate at a fraction of the price, offering a staggering 99.97 percent reduction in cost over traditional methods. These results are not just statistics, they signal a seismic shift in legal practice. LLMs stand poised to disrupt the legal industry, enhancing accessibility and efficiency of legal services. Our research asserts that the era of LLM dominance in legal contract review is upon us, challenging the status quo and calling for a reimagined future of legal workflows.},
	language = {en},
	urldate = {2024-08-04},
	publisher = {arXiv},
	author = {Martin, Lauren and Whitehouse, Nick and Yiu, Stephanie and Catterson, Lizzie and Perera, Rivindu},
	year = {2024},
	note = {arXiv:2401.16212 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, OS, LLM - Determining and locating legal issues in contracts},
	annote = {Comment: 16 pages},
	file = {Martin et al. - 2024 - Better Call GPT, Comparing Large Language Models A.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LI6YW33D\\Martin et al. - 2024 - Better Call GPT, Comparing Large Language Models A.pdf:application/pdf},
}

@misc{ma_leveraging_2024,
	title = {Leveraging {Large} {Language} {Models} for {Relevance} {Judgments} in {Legal} {Case} {Retrieval}},
	url = {http://arxiv.org/abs/2403.18405},
	abstract = {Collecting relevant judgments for legal case retrieval is a challenging and time-consuming task. Accurately judging the relevance between two legal cases requires a considerable effort to read the lengthy text and a high level of domain expertise to extract Legal Facts and make juridical judgments. With the advent of advanced large language models, some recent studies have suggested that it is promising to use LLMs for relevance judgment. Nonetheless, the method of employing a general large language model for reliable relevance judgments in legal case retrieval is yet to be thoroughly explored. To fill this research gap, we devise a novel few-shot workflow tailored to the relevant judgment of legal cases. The proposed workflow breaks down the annotation process into a series of stages, imitating the process employed by human annotators and enabling a flexible integration of expert reasoning to enhance the accuracy of relevance judgments. By comparing the relevance judgments of LLMs and human experts, we empirically show that we can obtain reliable relevance judgments with the proposed workflow. Furthermore, we demonstrate the capacity to augment existing legal case retrieval models through the synthesis of data generated by the large language model.},
	language = {en},
	urldate = {2024-08-04},
	publisher = {arXiv},
	author = {Ma, Shengjie and Chen, Chong and Chu, Qi and Mao, Jiaxin},
	month = mar,
	year = {2024},
	note = {arXiv:2403.18405 [cs]},
	keywords = {Computer Science - Artificial Intelligence, OS, Computer Science - Information Retrieval, LLM - Legal Case Retrieval},
	file = {Ma et al. - 2024 - Leveraging Large Language Models for Relevance Jud.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\PDLCSCBA\\Ma et al. - 2024 - Leveraging Large Language Models for Relevance Jud.pdf:application/pdf},
}

@book{lee_natural_2024,
	address = {Singapore},
	title = {Natural {Language} {Processing}: {A} {Textbook} with {Python} {Implementation}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-981-9919-98-7 978-981-9919-99-4},
	shorttitle = {Natural {Language} {Processing}},
	url = {https://link.springer.com/10.1007/978-981-99-1999-4},
	language = {en},
	urldate = {2024-08-03},
	publisher = {Springer Nature Singapore},
	author = {Lee, Raymond S. T.},
	year = {2024},
	doi = {10.1007/978-981-99-1999-4},
	keywords = {OS, Book - NLP - Python},
	file = {Lee - 2024 - Natural Language Processing A Textbook with Pytho.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\D3M9TE9E\\Lee - 2024 - Natural Language Processing A Textbook with Pytho.pdf:application/pdf},
}

@misc{lee_lexgpt_2023,
	title = {{LexGPT} 0.1: pre-trained {GPT}-{J} models with {Pile} of {Law}},
	shorttitle = {{LexGPT} 0.1},
	url = {http://arxiv.org/abs/2306.05431},
	abstract = {This research aims to build generative language models specialized for the legal domain. The manuscript presents the development of LexGPT models based on GPT-J models and pre-trained with Pile of Law. The foundation model built in this manuscript is the initial step for the development of future applications in the legal domain, such as further training with reinforcement learning from human feedback. Another objective of this manuscript is to assist legal professionals in utilizing language models through the “No Code” approach. By fine-tuning models with specialized data and without modifying any source code, legal professionals can create custom language models for downstream tasks with minimum effort and technical knowledge. The downstream task in this manuscript is to turn a LexGPT model into a classifier, although the performance is notably lower than the state-of-the-art result. How to enhance downstream task performance without modifying the model or its source code is a research topic for future exploration.},
	language = {en},
	urldate = {2024-09-28},
	publisher = {arXiv},
	author = {Lee, Jieh-Sheng},
	month = jun,
	year = {2023},
	note = {arXiv:2306.05431 [cs]},
	keywords = {Computer Science - Computation and Language, OS, Legal Language Model - LexGPT Example},
	annote = {Comment: 10 pages and 2 figures. To be published in the Proceedings of the Seventeenth International Workshop on Juris-informatics (JURISIN 2023), hosted by JSAI International Symposia on AI 2023},
	file = {Lee - 2023 - LexGPT 0.1 pre-trained GPT-J models with Pile of .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\YNT4M9YT\\Lee - 2023 - LexGPT 0.1 pre-trained GPT-J models with Pile of .pdf:application/pdf},
}

@inproceedings{kwak_information_2023,
	address = {Singapore},
	title = {Information {Extraction} from {Legal} {Wills}: {How} {Well} {Does} {GPT}-4 {Do}?},
	shorttitle = {Information {Extraction} from {Legal} {Wills}},
	url = {https://aclanthology.org/2023.findings-emnlp.287},
	doi = {10.18653/v1/2023.findings-emnlp.287},
	abstract = {This work presents a manually annotated dataset for Information Extraction (IE) from legal wills, and relevant in-context learning experiments on the dataset. The dataset consists of entities, binary relations between the entities (e.g., relations between testator and beneficiary), and n-ary events (e.g., bequest) extracted from 45 legal wills from two US states. This dataset can serve as a foundation for downstream tasks in the legal domain. Another use case of this dataset is evaluating the performance of large language models (LLMs) on this IE task. We evaluated GPT-4 with our dataset to investigate its ability to extract information from legal wills. Our evaluation result demonstrates that the model is capable of handling the task reasonably well. When given instructions and examples as a prompt, GPT-4 shows decent performance for both entity extraction and relation extraction tasks. Nevertheless, the evaluation result also reveals that the model is not perfect. We observed inconsistent outputs (given a prompt) as well as prompt over-generalization.},
	language = {en},
	urldate = {2024-09-09},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Kwak, Alice and Jeong, Cheonkam and Forte, Gaetano and Bambauer, Derek and Morrison, Clayton and Surdeanu, Mihai},
	year = {2023},
	keywords = {OS, Information Extraction - Legal Wills Example},
	pages = {4336--4353},
	file = {Kwak et al. - 2023 - Information Extraction from Legal Wills How Well .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\3LH7F9YP\\Kwak et al. - 2023 - Information Extraction from Legal Wills How Well .pdf:application/pdf},
}

@inproceedings{krumov_su-fmi_2024,
	address = {Mexico City, Mexico},
	title = {{SU}-{FMI} at {SemEval}-2024 {Task} 5: {From} {BERT} {Fine}-{Tuning} to {LLM} {Prompt} {Engineering} - {Approaches} in {Legal} {Argument} {Reasoning}},
	shorttitle = {{SU}-{FMI} at {SemEval}-2024 {Task} 5},
	url = {https://aclanthology.org/2024.semeval-1.235},
	doi = {10.18653/v1/2024.semeval-1.235},
	abstract = {This paper presents our approach and findings for SemEval-2024 Task 5, focusing on legal argument reasoning. We explored the effectiveness of fine-tuning pre-trained BERT models and the innovative application of large language models (LLMs) through prompt engineering in the context of legal texts. Our methodology involved a combination of techniques to address the challenges posed by legal language processing, including handling long texts and optimizing natural language understanding (NLU) capabilities for the legal domain. Our contributions were validated by achieving a third-place ranking on the SemEval 2024 Task 5 Leaderboard. The results underscore the potential of LLMs and prompt engineering in enhancing legal reasoning tasks, offering insights into the evolving landscape of NLU technologies within the legal field.},
	language = {en},
	urldate = {2024-08-04},
	booktitle = {Proceedings of the 18th {International} {Workshop} on {Semantic} {Evaluation} ({SemEval}-2024)},
	publisher = {Association for Computational Linguistics},
	author = {Krumov, Kristiyan and Boytcheva, Svetla and Koytchev, Ivan},
	year = {2024},
	keywords = {OS, LLM - Approaches in Legal Argument Reasoning},
	pages = {1652--1658},
	file = {Krumov et al. - 2024 - SU-FMI at SemEval-2024 Task 5 From BERT Fine-Tuni.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\XIA3X3U7\\Krumov et al. - 2024 - SU-FMI at SemEval-2024 Task 5 From BERT Fine-Tuni.pdf:application/pdf},
}

@misc{kapoor_promises_2024,
	title = {Promises and pitfalls of artificial intelligence for legal applications},
	url = {http://arxiv.org/abs/2402.01656},
	abstract = {Is AI set to redefine the legal profession? We argue that this claim is not supported by the current evidence. We dive into AI's increasingly prevalent roles in three types of legal tasks: information processing; tasks involving creativity, reasoning, or judgment; and predictions about the future. We find that the ease of evaluating legal applications varies greatly across legal tasks, based on the ease of identifying correct answers and the observability of information relevant to the task at hand. Tasks that would lead to the most significant changes to the legal profession are also the ones most prone to overoptimism about AI capabilities, as they are harder to evaluate. We make recommendations for better evaluation and deployment of AI in legal contexts.},
	language = {en},
	urldate = {2024-09-10},
	publisher = {arXiv},
	author = {Kapoor, Sayash and Henderson, Peter and Narayanan, Arvind},
	month = jan,
	year = {2024},
	note = {arXiv:2402.01656 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Artificial Intelligence, OS, LLM - Evaluation Recommendations},
	file = {Kapoor et al. - 2024 - Promises and pitfalls of artificial intelligence f.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\FSDWSQK4\\Kapoor et al. - 2024 - Promises and pitfalls of artificial intelligence f.pdf:application/pdf},
}

@book{junger_computational_2023,
	address = {Wiesbaden},
	title = {Computational {Methods} für die {Sozial}- und {Geisteswissenschaften}},
	copyright = {https://creativecommons.org/licenses/by/4.0},
	isbn = {978-3-658-37746-5 978-3-658-37747-2},
	url = {https://link.springer.com/10.1007/978-3-658-37747-2},
	language = {de},
	urldate = {2024-07-27},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Jünger, Jakob and Gärtner, Chantal},
	year = {2023},
	doi = {10.1007/978-3-658-37747-2},
	keywords = {OS, Computational Methods for Social Sciences},
	file = {Jünger und Gärtner - 2023 - Computational Methods für die Sozial- und Geistesw.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\YLK87CLF\\Jünger und Gärtner - 2023 - Computational Methods für die Sozial- und Geistesw.pdf:application/pdf},
}

@article{homoki_large_2024,
	title = {Large language models and their possible uses in law},
	volume = {64},
	issn = {2498-5473, 2560-1067},
	url = {https://akjournals.com/view/journals/2052/64/3/article-p435.xml},
	doi = {10.1556/2052.2023.00475},
	abstract = {The paper explores the potential applications of Large Language Models (LLMs) like ChatGPT in the legal field, focusing on how they can enhance access to law. We begin by elucidating the fundamental workings of LLMs and their current and future general applications. The core of our study predicts the utilization of LLMs in various legal domains, especially where tasks like text retrieval, generation, labeling, and classification are prevalent. We argue that tools like ChatGPT could play a pivotal role in these areas. Additionally, we discuss the limitations and customization requirements of LLMs, particularly for legal uses. An experiment conducted by one of the authors, involving a tailored version of GPT for small law firms, serves as a practical example, but building on this, the paper also proposes ways in which LLM-based applications could democratize access to justice, making legal assistance more accessible and efficient for the broader public. This study contributes to the understanding of the intersection between AI technology and legal services, highlighting both the opportunities and challenges in this field.},
	language = {en},
	number = {3},
	urldate = {2024-08-04},
	journal = {Hungarian Journal of Legal Studies},
	author = {Homoki, Péter and Ződi, Zsolt},
	month = jun,
	year = {2024},
	keywords = {OS, LLM - Use in Law},
	pages = {435--455},
	file = {Homoki und Ződi - 2024 - Large language models and their possible uses in l.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\5L24NYBC\\Homoki und Ződi - 2024 - Large language models and their possible uses in l.pdf:application/pdf;s10506-022-09319-6.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\I7H4DVRM\\s10506-022-09319-6.pdf:application/pdf},
}

@book{heinlein_kunstliche_2024,
	address = {Wiesbaden},
	title = {Künstliche {Intelligenz}, {Mensch} und {Gesellschaft}: {Soziale} {Dynamiken} und gesellschaftliche {Folgen} einer technologischen {Innovation}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-658-43520-2 978-3-658-43521-9},
	shorttitle = {Künstliche {Intelligenz}, {Mensch} und {Gesellschaft}},
	url = {https://link.springer.com/10.1007/978-3-658-43521-9},
	language = {de},
	urldate = {2024-09-08},
	publisher = {Springer Fachmedien Wiesbaden},
	editor = {Heinlein, Michael and Huchler, Norbert},
	year = {2024},
	doi = {10.1007/978-3-658-43521-9},
	keywords = {OS, Book - Künstliche Intelligenz, Mensch und Gesellschaft},
	file = {Heinlein und Huchler - 2024 - Künstliche Intelligenz, Mensch und Gesellschaft S.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\W22K6JTX\\Heinlein und Huchler - 2024 - Künstliche Intelligenz, Mensch und Gesellschaft S.pdf:application/pdf},
}

@book{hartmann_ki_2020,
	address = {Berlin, Heidelberg},
	series = {{IT} kompakt},
	title = {{KI} \& {Recht} kompakt},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-662-61699-4 978-3-662-61700-7},
	url = {http://link.springer.com/10.1007/978-3-662-61700-7},
	language = {de},
	urldate = {2024-07-13},
	publisher = {Springer Berlin Heidelberg},
	editor = {Hartmann, Matthias},
	year = {2020},
	doi = {10.1007/978-3-662-61700-7},
	keywords = {OS, Book - KI und Recht},
	file = {Hartmann - 2020 - KI & Recht kompakt.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\G3FHRUVF\\Hartmann - 2020 - KI & Recht kompakt.pdf:application/pdf},
}

@book{haba_data_2023,
	address = {England},
	edition = {1st edition},
	title = {{DATA} {AUGMENTATION} {WITH} {PYTHON} enhance deep learning accuracy with data augmentation methods for image, text, audio, and tabular data},
	isbn = {978-1-80323-591-2},
	abstract = {Boost your AI and generative AI accuracy using real-world datasets with over 150 functional object-oriented methods and open source libraries Purchase of the print or Kindle book includes a free PDF eBook Key Features Explore beautiful, customized charts and infographics in full color Work with fully functional OO code using open source libraries in the Python Notebook for each chapter Unleash the potential of real-world datasets with practical data augmentation techniques Book Description Data is paramount in AI projects, especially for deep learning and generative AI, as forecasting accuracy relies on input datasets being robust. Acquiring additional data through traditional methods can be challenging, expensive, and impractical, and data augmentation offers an economical option to extend the dataset. The book teaches you over 20 geometric, photometric, and random erasing augmentation methods using seven real-world datasets for image classification and segmentation. You'll also review eight image augmentation open source libraries, write object-oriented programming (OOP) wrapper functions in Python Notebooks, view color image augmentation effects, analyze safe levels and biases, as well as explore fun facts and take on fun challenges. As you advance, you'll discover over 20 character and word techniques for text augmentation using two real-world datasets and excerpts from four classic books. The chapter on advanced text augmentation uses machine learning to extend the text dataset, such as Transformer, Word2vec, BERT, GPT-2, and others. While chapters on audio and tabular data have real-world data, open source libraries, amazing custom plots, and Python Notebook, along with fun facts and challenges. By the end of this book, you will be proficient in image, text, audio, and tabular data augmentation techniques. What you will learn Write OOP Python code for image, text, audio, and tabular data Access over 150,000 real-world datasets from the Kaggle website Analyze biases and safe parameters for each augmentation method Visualize data using standard and exotic plots in color Discover 32 advanced open source augmentation libraries Explore machine learning models, such as BERT and Transformer Meet Pluto, an imaginary digital coding companion Extend your learning with fun facts and fun challenges Who this book is for This book is for data scientists and students interested in the AI discipline. Advanced AI or deep learning skills are not required; however, knowledge of Python programming and familiarity with Jupyter Notebooks are essential to understanding the topics covered in this book},
	language = {en},
	publisher = {PACKT PUBLISHING LIMITED},
	author = {Haba, Duc},
	year = {2023},
	note = {OCLC: 1378301601},
	keywords = {OS, DL - Data Augmentation},
	file = {Haba - 2023 - DATA AUGMENTATION WITH PYTHON enhance deep learnin.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\T27HYLNX\\Haba - 2023 - DATA AUGMENTATION WITH PYTHON enhance deep learnin.pdf:application/pdf},
}

@misc{gupta_leveraging_2024,
	title = {Leveraging open-source models for legal language modeling and analysis: a case study on the {Indian} constitution},
	shorttitle = {Leveraging open-source models for legal language modeling and analysis},
	url = {http://arxiv.org/abs/2404.06751},
	abstract = {In recent years, the use of open-source models has gained immense popularity in various fields, including legal language modelling and analysis. These models have proven to be highly effective in tasks such as summarizing legal documents, extracting key information, and even predicting case outcomes. This has revolutionized the legal industry, enabling lawyers, researchers, and policymakers to quickly access and analyse vast amounts of legal text, saving time and resources. This paper presents a novel approach to legal language modeling (LLM) and analysis using open-source models from Hugging Face. We leverage Hugging Face embeddings via LangChain and Sentence Transformers to develop an LLM tailored for legal texts. We then demonstrate the application of this model by extracting insights from the official Constitution of India. Our methodology involves preprocessing the data, splitting it into chunks using ChromaDB and LangChainVectorStores, and employing the Google/Flan-T5-XXL model for analysis. The trained model is tested on the Indian Constitution, which is available in PDF format. Our findings suggest that our approach holds promise for efficient legal language processing and analysis.},
	language = {en},
	urldate = {2024-08-04},
	publisher = {arXiv},
	author = {Gupta, Vikhyath and P, Srinivasa Rao},
	month = apr,
	year = {2024},
	note = {arXiv:2404.06751 [cs]},
	keywords = {Computer Science - Computers and Society, OS, LLM - Open Source Models},
	annote = {Comment: 10 Pages , 3 figures},
	file = {Gupta und P - 2024 - Leveraging open-source models for legal language m.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\EDYVJTA3\\Gupta und P - 2024 - Leveraging open-source models for legal language m.pdf:application/pdf},
}

@misc{guo_evaluating_2023,
	title = {Evaluating {Large} {Language} {Models}: {A} {Comprehensive} {Survey}},
	shorttitle = {Evaluating {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2310.19736},
	abstract = {Large language models (LLMs) have demonstrated remarkable capabilities across a broad spectrum of tasks. They have attracted significant attention and been deployed in numerous downstream applications. Nevertheless, akin to a double-edged sword, LLMs also present potential risks. They could suffer from private data leaks or yield inappropriate, harmful, or misleading content. Additionally, the rapid progress of LLMs raises concerns about the potential emergence of superintelligent systems without adequate safeguards. To effectively capitalize on LLM capacities as well as ensure their safe and beneficial development, it is critical to conduct a rigorous and comprehensive evaluation of LLMs.},
	language = {en},
	urldate = {2024-09-19},
	publisher = {arXiv},
	author = {Guo, Zishan and Jin, Renren and Liu, Chuang and Huang, Yufei and Shi, Dan and Supryadi and Yu, Linhao and Liu, Yan and Li, Jiaxuan and Xiong, Bojian and Xiong, Deyi},
	month = nov,
	year = {2023},
	note = {arXiv:2310.19736 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, OS, LLM - Evaluation - Knowledge and Capability Evaluation},
	annote = {Comment: 111 pages},
	file = {Guo et al. - 2023 - Evaluating Large Language Models A Comprehensive .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\NPFQKMAX\\Guo et al. - 2023 - Evaluating Large Language Models A Comprehensive .pdf:application/pdf},
}

@article{guha_legalbench_2023,
	title = {Legalbench: {A} {Collaboratively} {Built} {Benchmark} for {Measuring} {Legal} {Reasoning} in {Large} {Language} {Models}},
	issn = {1556-5068},
	shorttitle = {Legalbench},
	url = {https://www.ssrn.com/abstract=4583531},
	doi = {10.2139/ssrn.4583531},
	abstract = {The advent of large language models (LLMs) and their adoption by the legal community has given rise to the question: what types of legal reasoning can LLMs perform? To enable greater study of this question, we present LEGALBENCH: a collaboratively constructed legal reasoning benchmark consisting of 162 tasks covering six different types of legal reasoning. LEGALBENCH was built through an interdisciplinary process, in which we collected tasks designed and hand-crafted by legal professionals. Because these subject matter experts took a leading role in construction, tasks either measure legal reasoning capabilities that are practically useful, or measure reasoning skills that lawyers find interesting. To enable cross-disciplinary conversations about LLMs in the law, we additionally show how popular legal frameworks for describing legal reasoning—which distinguish between its many forms—correspond to LEGALBENCH tasks, thus giving lawyers and LLM developers a common vocabulary. This paper describes LEGALBENCH, presents an empirical evaluation of 20 open-source and commercial LLMs, and illustrates the types of research explorations LEGALBENCH enables.},
	language = {en},
	urldate = {2024-09-10},
	journal = {SSRN Electronic Journal},
	author = {Guha, Neel and Nyarko, Julian and Ho, Daniel E. and Ré, Christopher and Chilton, Adam and Narayana, Aditya and Chohlas-Wood, Alex and Peters, Austin and Waldon, Brandon and Rockmore, Daniel and Zambrano, Diego and Talisman, Dmitry and Hoque, Enam and Surani, Faiz and Fagan, Frank and Sarfaty, Galit and Dickinson, Gregory M. and Porat, Haggai and Hegland, Jason and Wu, Jessica and Nudell, Joe and Niklaus, Joel and Nay, John and Choi, Jonathan H. and Tobia, Kevin and Hagan, Margaret and Ma, Megan and Livermore, Michael A. and Rasumov-Rahe, Nikon and Holzenberger, Nils and Kolt, Noam and Henderson, Peter and Rehaag, Sean and Goel, Sharad and Gao, Shang and Williams, Spencer and Gandhi, Sunny and Zur, Tom and Iyer, Varun and Li, Zehua},
	year = {2023},
	keywords = {OS, LLM - Benchmarking for Legal Reasoning},
	file = {Guha et al. - 2023 - Legalbench A Collaboratively Built Benchmark for .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\63VMHJCM\\Guha et al. - 2023 - Legalbench A Collaboratively Built Benchmark for .pdf:application/pdf},
}

@article{greco_bringing_2023,
	title = {Bringing order into the realm of {Transformer}-based language models for artificial intelligence and law},
	issn = {0924-8463, 1572-8382},
	url = {https://link.springer.com/10.1007/s10506-023-09374-7},
	doi = {10.1007/s10506-023-09374-7},
	abstract = {Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the stateof-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitations and opportunities for further research development.},
	language = {en},
	urldate = {2024-09-28},
	journal = {Artificial Intelligence and Law},
	author = {Greco, Candida M. and Tagarelli, Andrea},
	month = nov,
	year = {2023},
	keywords = {OS, LLM - Overview of Transformers},
	file = {Greco und Tagarelli - 2023 - Bringing order into the realm of Transformer-based.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\Y5WPTLG9\\Greco und Tagarelli - 2023 - Bringing order into the realm of Transformer-based.pdf:application/pdf},
}

@misc{gorur_can_2024,
	title = {Can {Large} {Language} {Models} perform {Relation}-based {Argument} {Mining}?},
	url = {http://arxiv.org/abs/2402.11243},
	abstract = {Argument mining (AM) is the process of automatically extracting arguments, their components and/or relations amongst arguments and components from text. As the number of platforms supporting online debate increases, the need for AM becomes ever more urgent, especially in support of downstream tasks. Relation-based AM (RbAM) is a form of AM focusing on identifying agreement (support) and disagreement (attack) relations amongst arguments. RbAM is a challenging classification task, with existing methods failing to perform satisfactorily. In this paper, we show that general-purpose Large Language Models (LLMs), appropriately primed and prompted, can significantly outperform the best performing (RoBERTabased) baseline. Specifically, we experiment with two open-source LLMs (Llama-2 and Mistral) with ten datasets.},
	language = {en},
	urldate = {2024-09-11},
	publisher = {arXiv},
	author = {Gorur, Deniz and Rago, Antonio and Toni, Francesca},
	month = feb,
	year = {2024},
	note = {arXiv:2402.11243 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, OS, Relation-based Argument Mining - LLMs},
	annote = {Comment: 10 pages, 9 figures, submitted to ACL 2024},
	file = {Gorur et al. - 2024 - Can Large Language Models perform Relation-based A.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\QZPMKWUF\\Gorur et al. - 2024 - Can Large Language Models perform Relation-based A.pdf:application/pdf},
}

@article{goli_frontiers_2024,
	title = {Frontiers: {Can} {Large} {Language} {Models} {Capture} {Human} {Preferences}?},
	volume = {43},
	issn = {0732-2399, 1526-548X},
	shorttitle = {Frontiers},
	url = {https://pubsonline.informs.org/doi/10.1287/mksc.2023.0306},
	doi = {10.1287/mksc.2023.0306},
	abstract = {We explore the viability of large language models (LLMs), specifically OpenAI’s GPT-3.5 and GPT-4, in emulating human survey respondents and eliciting preferences, with a focus on intertemporal choices. Leveraging the extensive literature on intertemporal discounting for benchmarking, we examine responses from LLMs across various lan­ guages and compare them with human responses, exploring preferences between smaller, sooner and larger, later rewards. Our findings reveal that both generative pretrained trans­ former (GPT) models demonstrate less patience than humans, with GPT-3.5 exhibiting a lexicographic preference for earlier rewards unlike human decision makers. Although GPT-4 does not display lexicographic preferences, its measured discount rates are still con­ siderably larger than those found in humans. Interestingly, GPT models show greater patience in languages with weak future tense references, such as German and Mandarin, aligning with the existing literature that suggests a correlation between language structure and intertemporal preferences. We demonstrate how prompting GPT to explain its deci­ sions, a procedure we term “chain-of-thought conjoint,” can mitigate, but does not elimi­ nate, discrepancies between LLM and human responses. Although directly eliciting preferences using LLMs may yield misleading results, combining chain-of-thought con­ joint with topic modeling aids in hypothesis generation, enabling researchers to explore the underpinnings of preferences. Chain-of-thought conjoint provides a structured frame­ work for marketers to use LLMs to identify potential attributes or factors that can explain preference heterogeneity across different customers and contexts.},
	language = {en},
	number = {4},
	urldate = {2024-09-11},
	journal = {Marketing Science},
	author = {Goli, Ali and Singh, Amandeep},
	month = jul,
	year = {2024},
	keywords = {OS, LLM - Human Preferences},
	pages = {709--722},
	file = {Goli und Singh - 2024 - Frontiers Can Large Language Models Capture Human.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\SX47XJ3K\\Goli und Singh - 2024 - Frontiers Can Large Language Models Capture Human.pdf:application/pdf},
}

@article{goebel_overview_2024,
	title = {Overview and {Discussion} of the {Competition} on {Legal} {Information}, {Extraction}/{Entailment} ({COLIEE}) 2023},
	volume = {18},
	issn = {2523-3173, 1867-3236},
	url = {https://link.springer.com/10.1007/s12626-023-00152-0},
	doi = {10.1007/s12626-023-00152-0},
	abstract = {We summarize the 10th Competition on Legal Information Extraction and Entailment. In this tenth edition, the competition included four tasks on case law and statute law. The case law component includes an information retrieval task (Task 1), and the confirmation of an entailment relation between an existing case and a selected unseen case (Task 2). The statute law component includes an information retrieval task (Task 3), and an entailment/question-answering task based on retrieved civil code statutes (Task 4). Participation was open to any group based on any approach. Ten different teams participated in the case law competition tasks, most of them in more than one task. We received results from 8 teams for Task 1 (22 runs) and seven teams for Task 2 (18 runs). On the statute law task, there were 9 different teams participating, most in more than one task. 6 teams submitted a total of 16 runs for Task 3, and 9 teams submitted a total of 26 runs for Task 4. We describe the variety of approaches, our official evaluation, and analysis of our data and submission results.},
	language = {en},
	number = {1},
	urldate = {2024-08-06},
	journal = {The Review of Socionetwork Strategies},
	author = {Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Rabelo, Juliano and Satoh, Ken and Yoshioka, Masaharu},
	month = apr,
	year = {2024},
	keywords = {OS, Information Extraction - Competition Discussion},
	pages = {27--47},
	file = {Goebel et al. - 2024 - Overview and Discussion of the Competition on Lega.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ZGN3S8GM\\Goebel et al. - 2024 - Overview and Discussion of the Competition on Lega.pdf:application/pdf},
}

@misc{ghosh_human_2024,
	title = {Human {Centered} {AI} for {Indian} {Legal} {Text} {Analytics}},
	url = {http://arxiv.org/abs/2403.10944},
	abstract = {Legal research is a crucial task in the practice of law. It requires intense human effort and intellectual prudence to research a legal case and prepare arguments. Recent boom in generative AI has not translated to proportionate rise in impactful legal applications, because of low trustworthiness and and the scarcity of specialized datasets for training Large Language Models (LLMs). This position paper explores the potential of LLMs within Legal Text Analytics (LTA), highlighting specific areas where the integration of human expertise can significantly enhance their performance to match that of experts. We introduce a novel dataset and describe a human centered, compound AI system that principally incorporates human inputs for performing LTA tasks with LLMs.},
	language = {en},
	urldate = {2024-08-06},
	publisher = {arXiv},
	author = {Ghosh, Sudipto and Verma, Devanshu and Ganesan, Balaji and Bindal, Purnima and Kumar, Vikas and Bhatnagar, Vasudha},
	month = mar,
	year = {2024},
	note = {arXiv:2403.10944 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, OS, LTA - Legal Text Analytics},
	annote = {Comment: 7 pages, 7 figures},
	file = {Ghosh et al. - 2024 - Human Centered AI for Indian Legal Text Analytics.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\83XAVUKD\\Ghosh et al. - 2024 - Human Centered AI for Indian Legal Text Analytics.pdf:application/pdf},
}

@misc{gastaldi_foundations_2024,
	title = {The {Foundations} of {Tokenization}: {Statistical} and {Computational} {Concerns}},
	shorttitle = {The {Foundations} of {Tokenization}},
	url = {http://arxiv.org/abs/2407.11606},
	abstract = {Tokenization—the practice of converting strings of characters over an alphabet into sequences of tokens over a vocabulary—is a critical yet under-theorized step in the NLP pipeline. Notably, it remains the only major step not fully integrated into widely used end-to-end neural models. This paper aims to address this theoretical gap by laying the foundations of tokenization from a formal perspective. By articulating and extending basic properties about the category of stochastic maps, we propose a uniﬁed framework for representing and analyzing tokenizer models. This framework allows us to establish general conditions for the use of tokenizers. In particular, we formally establish the necessary and sufﬁcient conditions for a tokenizer model to preserve the consistency of statistical estimators. Additionally, we discuss statistical and computational concerns crucial for the design and implementation of tokenizer models. The framework and results advanced in this paper represent a step toward a robust theoretical foundation for neural language modeling.},
	language = {en},
	urldate = {2024-10-07},
	publisher = {arXiv},
	author = {Gastaldi, Juan Luis and Terilla, John and Malagutti, Luca and DuSell, Brian and Vieira, Tim and Cotterell, Ryan},
	month = aug,
	year = {2024},
	note = {arXiv:2407.11606 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, OS, LLM - Tokenization},
	file = {Gastaldi et al. - 2024 - The Foundations of Tokenization Statistical and C.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\6XMEY29N\\Gastaldi et al. - 2024 - The Foundations of Tokenization Statistical and C.pdf:application/pdf},
}

@misc{fei_internlm-law_2024,
	title = {{InternLM}-{Law}: {An} {Open} {Source} {Chinese} {Legal} {Large} {Language} {Model}},
	shorttitle = {{InternLM}-{Law}},
	url = {http://arxiv.org/abs/2406.14887},
	abstract = {While large language models (LLMs) have showcased impressive capabilities, they struggle with addressing legal queries due to the intricate complexities and specialized expertise required in the legal field. In this paper, we introduce InternLM-Law, a specialized LLM tailored for addressing diverse legal queries related to Chinese laws, spanning from responding to standard legal questions (e.g., legal exercises in textbooks) to analyzing complex real-world legal situations. We meticulously construct a dataset in the Chinese legal domain, encompassing over 1 million queries, and implement a data filtering and processing pipeline to ensure its diversity and quality. Our training approach involves a novel two-stage process: initially fine-tuning LLMs on both legal-specific and general-purpose content to equip the models with broad knowledge, followed by exclusive fine-tuning on high-quality legal data to enhance structured output generation. InternLM-Law achieves the highest average performance on LawBench, outperforming state-of-the-art models, including GPT-4, on 13 out of 20 subtasks. We make InternLM-Law and our dataset publicly available to facilitate future research in applying LLMs within the legal domain.},
	language = {en},
	urldate = {2024-08-04},
	publisher = {arXiv},
	author = {Fei, Zhiwei and Zhang, Songyang and Shen, Xiaoyu and Zhu, Dawei and Wang, Xiao and Cao, Maosong and Zhou, Fengzhe and Li, Yining and Zhang, Wenwei and Lin, Dahua and Chen, Kai and Ge, Jidong},
	month = jun,
	year = {2024},
	note = {arXiv:2406.14887 [cs]},
	keywords = {Computer Science - Computation and Language, Legal Language Model - InternLM-Law},
	annote = {Comment: Our dataset, code and models will be released at https://github.com/InternLM/InternLM-Law},
	file = {Fei et al. - 2024 - InternLM-Law An Open Source Chinese Legal Large L.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\6S3BEC5L\\Fei et al. - 2024 - InternLM-Law An Open Source Chinese Legal Large L.pdf:application/pdf},
}

@misc{faysse_croissantllm_2024,
	title = {{CroissantLLM}: {A} {Truly} {Bilingual} {French}-{English} {Language} {Model}},
	shorttitle = {{CroissantLLM}},
	url = {http://arxiv.org/abs/2402.00786},
	abstract = {We introduce CroissantLLM, a 1.3B language model pre-trained on a set of 3T English and French tokens, to bring to the research and industrial community a high-performance, fully open-sourced bilingual model that runs swiftly on consumer-grade local hardware. To that end, we pioneer the approach of training an intrinsically bilingual model with a 1:1 English-toFrench pretraining data ratio, a custom tokenizer, and bilingual finetuning datasets. We release the training dataset, notably containing a French split with manually curated, high-quality, and varied data sources. To assess performance outside of English, we craft a novel benchmark, FrenchBench, consisting of an array of classification and generation tasks, covering various orthogonal aspects of model performance in the French Language. Additionally, rooted in transparency and to foster further Large Language Model research, we release codebases, and dozens of checkpoints across various model sizes, training data distributions, and training steps, as well as fine-tuned Chat models, and strong translation models. We evaluate our model through the FMTI framework (Bommasani et al., 2023) and validate 81 \% of the transparency criteria, far beyond the scores of even most open initiatives. This work enriches the NLP landscape, breaking away from previous English-centric work to strengthen our understanding of multilingualism in language models.},
	language = {en},
	urldate = {2024-08-06},
	publisher = {arXiv},
	author = {Faysse, Manuel and Fernandes, Patrick and Guerreiro, Nuno M. and Loison, António and Alves, Duarte M. and Corro, Caio and Boizard, Nicolas and Alves, João and Rei, Ricardo and Martins, Pedro H. and Casademunt, Antoni Bigata and Yvon, François and Martins, André F. T. and Viaud, Gautier and Hudelot, Céline and Colombo, Pierre},
	month = mar,
	year = {2024},
	note = {arXiv:2402.00786 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, OS, LLM - "Truly Billingual"},
	file = {Faysse et al. - 2024 - CroissantLLM A Truly Bilingual French-English Lan.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\WZX5IWHS\\Faysse et al. - 2024 - CroissantLLM A Truly Bilingual French-English Lan.pdf:application/pdf},
}

@article{fagan_view_2024,
	title = {A {View} of {How} {Language} {Models} {Will} {Transform} {Law}},
	abstract = {This Article considers the influence of Large Language Models (LLMs) on legal practice and the legal services industry. In the near term, LLMs will spur new legal work. Lawyers will be called upon to help litigate new questions over property rights in data, language model output, and lawyer-engineered prompts. Lawyers will additionally help judges decide what to do about new forms of torts, including legal malpractice, enabled by the casual and lightly supervised use of large language models. As legal rules governing the use of generative A.I. begin to clarify and settle, and as the technology fully matures, future lawyers faced with routine work will engage language models to save time and costs. Consequently, legal tasks will take less time to complete, and language models will enhance lawyer productivity.},
	language = {en},
	author = {Fagan, Frank},
	year = {2024},
	keywords = {OS, LLM - Law Transformation},
	file = {Fagan - A View of How Language Models Will Transform Law.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\TSIUHXGG\\Fagan - A View of How Language Models Will Transform Law.pdf:application/pdf},
}

@book{esposito_programming_2024,
	address = {Hoboken},
	edition = {1},
	title = {Programming large language models with azure open ai: conversational programming and prompt engineering with llms},
	isbn = {978-0-13-828037-6},
	shorttitle = {Programming large language models with azure open ai},
	language = {en},
	publisher = {Microsoft Press},
	author = {Esposito, Francesco},
	year = {2024},
	keywords = {OS, LLM - Programming with Azure Open AI},
	file = {Esposito - 2024 - Programming large language models with azure open .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\7DS3ZW8Y\\Esposito - 2024 - Programming large language models with azure open .pdf:application/pdf},
}

@article{engel_asking_2024,
	title = {Asking {GPT} for the {Ordinary} {Meaning} of {Statutory} {Terms}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4718347},
	doi = {10.2139/ssrn.4718347},
	abstract = {We report on our test of the Large Language Model (LLM) ChatGPT (GPT) as a tool for generating evidence of the ordinary meaning of statutory terms. We explain why the most useful evidence for interpretation involves a distribution of replies rather than only what GPT regards as the single “best” reply. That motivates our decision to use Chat 3.5 Turbo instead of Chat 4 and to run each prompt we use 100 times. Asking GPT whether the statutory term “vehicle” includes a list of candidate objects (e.g., bus, bicycle, skateboard) allows us to test it against a benchmark, the results of a high-quality experimental survey (Tobia 2000) that asked over 2,800 English speakers the same questions. After learning what prompts fail and which one works best (a belief prompt combined with a Likert scale reply), we use the successful prompt to test the effects of “informing” GPT that the term appears in a particular rule (one of five possible) or that the legal rule using the term has a particular purpose (one of six possible). Finally, we explore GPT’s sensitivity to meaning at a particular moment in the past (the 1950s) and its ability to distinguish extensional from intensional meaning. To our knowledge, these are the first tests of GPT as a tool for generating empirical data on the ordinary meaning of statutory terms. Legal actors have good reason to be cautious, but LLMs have the potential to radically facilitate and improve legal tasks, including the interpretation of statutes.},
	language = {en},
	urldate = {2024-09-10},
	journal = {SSRN Electronic Journal},
	author = {Engel, Christoph and McAdams, Richard H.},
	year = {2024},
	keywords = {OS, GPT Experiments - Framework},
	file = {Engel und McAdams - 2024 - Asking GPT for the Ordinary Meaning of Statutory T.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\QDVKCS5E\\Engel und McAdams - 2024 - Asking GPT for the Ordinary Meaning of Statutory T.pdf:application/pdf},
}

@article{eckert_digitale_2017,
	title = {Digitale {Kommunkation}},
	language = {de},
	author = {Eckert, C and Trick, U and Weber, F and Sun, K},
	year = {2017},
	keywords = {OS, Digitale Kommunikation - Grundlagen},
	file = {Eckert et al. - Weitere empfehlenswerte Titel.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\U7NSUJ6I\\Eckert et al. - Weitere empfehlenswerte Titel.pdf:application/pdf},
}

@misc{dong_survey_2023,
	title = {A {Survey} on {Long} {Text} {Modeling} with {Transformers}},
	url = {http://arxiv.org/abs/2302.14502},
	abstract = {Modeling long texts has been an essential technique in the ﬁeld of natural language processing (NLP). With the ever-growing number of long documents, it is important to develop effective modeling methods that can process and analyze such texts. However, long texts pose important research challenges for existing text models, with more complex semantics and special characteristics. In this paper, we provide an overview of the recent advances on long texts modeling based on Transformer models. Firstly, we introduce the formal deﬁnition of long text modeling. Then, as the core content, we discuss how to process long input to satisfy the length limitation and design improved Transformer architectures to effectively extend the maximum context length. Following this, we discuss how to adapt Transformer models to capture the special characteristics of long texts. Finally, we describe four typical applications involving long text modeling and conclude this paper with a discussion of future directions. Our survey intends to provide researchers with a synthesis and pointer to related work on long text modeling.},
	language = {en},
	urldate = {2024-08-10},
	publisher = {arXiv},
	author = {Dong, Zican and Tang, Tianyi and Li, Lunyi and Zhao, Wayne Xin},
	month = feb,
	year = {2023},
	note = {arXiv:2302.14502 [cs]},
	keywords = {Computer Science - Computation and Language, OS, NLP - Long Text Modelling},
	file = {Dong et al. - 2023 - A Survey on Long Text Modeling with Transformers.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\VBSF2FV7\\Dong et al. - 2023 - A Survey on Long Text Modeling with Transformers.pdf:application/pdf},
}

@misc{dong_survey_2024,
	title = {A {Survey} on {In}-context {Learning}},
	url = {http://arxiv.org/abs/2301.00234},
	abstract = {With the increasing capabilities of large language models (LLMs), in-context learning (ICL) has emerged as a new paradigm for natural language processing (NLP), where LLMs make predictions based on contexts augmented with a few examples. It has been a significant trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL. We first present a formal definition of ICL and clarify its correlation to related studies. Then, we organize and discuss advanced techniques, including training strategies, prompt designing strategies, and related analysis. Additionally, we explore various ICL application scenarios, such as data engineering and knowledge updating. Finally, we address the challenges of ICL and suggest potential directions for further research. We hope that our work can encourage more research on uncovering how ICL works and improving ICL.},
	language = {en},
	urldate = {2024-08-04},
	publisher = {arXiv},
	author = {Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Li, Lei and Sui, Zhifang},
	month = jun,
	year = {2024},
	note = {arXiv:2301.00234 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, OS, LLM - In-Context Learning},
	annote = {Comment: Papers collected until 2024/06/01},
	file = {Dong et al. - 2024 - A Survey on In-context Learning.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\H4TTZTYH\\Dong et al. - 2024 - A Survey on In-context Learning.pdf:application/pdf},
}

@article{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be ﬁnetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeciﬁc architecture modiﬁcations.},
	language = {en},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year = {2019},
	keywords = {OS, NLU - BERT},
	file = {Devlin et al. - BERT Pre-training of Deep Bidirectional Transform.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\CL2SQEEI\\Devlin et al. - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf},
}

@article{deroy_applicability_2024,
	title = {Applicability of large language models and generative models for legal case judgement summarization},
	issn = {0924-8463, 1572-8382},
	url = {https://link.springer.com/10.1007/s10506-024-09411-z},
	doi = {10.1007/s10506-024-09411-z},
	abstract = {Automatic summarization of legal case judgements, which are known to be long and complex, has traditionally been tried via extractive summarization models. In recent years, generative models including abstractive summarization models and Large language models (LLMs) have gained huge popularity. In this paper, we explore the applicability of such models for legal case judgement summarization. We applied various domain-specific abstractive summarization models and general-domain LLMs as well as extractive summarization models over two sets of legal case judgements – from the United Kingdom (UK) Supreme Court and the Indian Supreme Court – and evaluated the quality of the generated summaries. We also perform experiments on a third dataset of legal documents of a different type – Government reports from the United States. Results show that abstractive summarization models and LLMs generally perform better than the extractive methods as per traditional metrics for evaluating summary quality. However, detailed investigation shows the presence of inconsistencies and hallucinations in the outputs of the generative models, and we explore ways to reduce the hallucinations and inconsistencies in the summaries. Overall, the investigation suggests that further improvements are needed to enhance the reliability of abstractive models and LLMs for legal case judgement summarization. At present, a human-in-the-loop technique is more suitable for performing manual checks to identify inconsistencies in the generated summaries.},
	language = {en},
	urldate = {2024-09-11},
	journal = {Artificial Intelligence and Law},
	author = {Deroy, Aniket and Ghosh, Kripabandhu and Ghosh, Saptarshi},
	month = jul,
	year = {2024},
	keywords = {OS, LLM - Judgment Summarization (Chunking)},
	file = {Deroy et al. - 2024 - Applicability of large language models and generat.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\E62FJLCX\\Deroy et al. - 2024 - Applicability of large language models and generat.pdf:application/pdf},
}

@article{dale_law_2019,
	title = {Law and {Word} {Order}: {NLP} in {Legal} {Tech}},
	volume = {25},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1351-3249, 1469-8110},
	shorttitle = {Law and {Word} {Order}},
	url = {https://www.cambridge.org/core/product/identifier/S1351324918000475/type/journal_article},
	doi = {10.1017/S1351324918000475},
	abstract = {The law has language at its heart, so it’s not surprising that software that operates on natural language has played a role in some areas of the legal profession for a long time. But the last few years have seen an increased interest in applying modern techniques to a wider range of problems, so I look here at how natural language processing is being used in the legal sector today.},
	language = {en},
	number = {1},
	urldate = {2024-08-03},
	journal = {Natural Language Engineering},
	author = {Dale, Robert},
	month = jan,
	year = {2019},
	keywords = {OS, NLP - Legal Field},
	pages = {211--217},
	file = {Dale - 2019 - Law and Word Order NLP in Legal Tech.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LKPM562H\\Dale - 2019 - Law and Word Order NLP in Legal Tech.pdf:application/pdf},
}

@article{dahl_large_2024,
	title = {Large {Legal} {Fictions}: {Profiling} {Legal} {Hallucinations} in {Large} {Language} {Models}},
	volume = {16},
	issn = {2161-7201, 1946-5319},
	shorttitle = {Large {Legal} {Fictions}},
	url = {http://arxiv.org/abs/2401.01301},
	doi = {10.1093/jla/laae003},
	abstract = {Do large language models (LLMs) know the law? These models are increasingly being used to augment legal practice, education, and research, yet their revolutionary potential is threatened by the presence of hallucinations -- textual output that is not consistent with legal facts. We present the first systematic evidence of these hallucinations, documenting LLMs' varying performance across jurisdictions, courts, time periods, and cases. Our work makes four key contributions. First, we develop a typology of legal hallucinations, providing a conceptual framework for future research in this area. Second, we find that legal hallucinations are alarmingly prevalent, occurring between 58\% of the time with ChatGPT 4 and 88\% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases. Third, we illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup. Fourth, we provide evidence that LLMs cannot always predict, or do not always know, when they are producing legal hallucinations. Taken together, our findings caution against the rapid and unsupervised integration of popular LLMs into legal tasks. Even experienced lawyers must remain wary of legal hallucinations, and the risks are highest for those who stand to benefit from LLMs the most -- pro se litigants or those without access to traditional legal resources.},
	language = {en},
	number = {1},
	urldate = {2024-09-07},
	journal = {Journal of Legal Analysis},
	author = {Dahl, Matthew and Magesh, Varun and Suzgun, Mirac and Ho, Daniel E.},
	month = jan,
	year = {2024},
	note = {arXiv:2401.01301 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Artificial Intelligence, OS, LLM - Halluzinations},
	pages = {64--93},
	file = {Dahl et al. - 2024 - Large Legal Fictions Profiling Legal Hallucinatio.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\W4M3JBIR\\Dahl et al. - 2024 - Large Legal Fictions Profiling Legal Hallucinatio.pdf:application/pdf},
}

@book{dahl_natural_2023,
	address = {Birmingham Mumbai},
	title = {Natural language understanding with {Python}: combine natural language technology, deep learning, and large language models to create human-like language comprehension in computer systems},
	isbn = {978-1-80461-342-9},
	shorttitle = {Natural language understanding with {Python}},
	language = {en},
	publisher = {Packt Publishing},
	author = {Dahl, Deborah A.},
	year = {2023},
	keywords = {OS, NLU - Python},
	file = {Dahl - 2023 - Natural language understanding with Python combin.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\268A9B9F\\Dahl - 2023 - Natural language understanding with Python combin.pdf:application/pdf},
}

@misc{cui_chatlaw_2024,
	title = {Chatlaw: {A} {Multi}-{Agent} {Collaborative} {Legal} {Assistant} with {Knowledge} {Graph} {Enhanced} {Mixture}-of-{Experts} {Large} {Language} {Model}},
	shorttitle = {Chatlaw},
	url = {http://arxiv.org/abs/2306.16092},
	abstract = {AI legal assistants based on Large Language Models (LLMs) can provide accessible legal consulting services, but the hallucination problem poses potential legal risks. This paper presents Chatlaw, an innovative legal assistant utilizing a Mixture-of-Experts (MoE) model and a multi-agent system to enhance the reliability and accuracy of AI-driven legal services. By integrating knowledge graphs with artificial screening, we construct a high-quality legal dataset to train the MoE model. This model utilizes different experts to address various legal issues, optimizing the accuracy of legal responses. Additionally, Standardized Operating Procedures (SOP), modeled after real law firm workflows, significantly reduce errors and hallucinations in legal services. Our MoE model outperforms GPT-4 in the Lawbench and Unified Qualification Exam for Legal Professionals by 7.73\% in accuracy and 11 points, respectively, and also surpasses other models in multiple dimensions during real-case consultations, demonstrating our robust capability for legal consultation.},
	language = {en},
	urldate = {2024-09-12},
	publisher = {arXiv},
	author = {Cui, Jiaxi and Ning, Munan and Li, Zongjian and Chen, Bohua and Yan, Yang and Li, Hao and Ling, Bin and Tian, Yonghong and Yuan, Li},
	month = may,
	year = {2024},
	note = {arXiv:2306.16092 [cs]},
	keywords = {Computer Science - Computation and Language, OS, Legal Language Model - multi-agent virtual legal assistant based on multi-expert large language model},
	file = {Cui et al. - 2024 - Chatlaw A Multi-Agent Collaborative Legal Assista.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\3MF7IVI9\\Cui et al. - 2024 - Chatlaw A Multi-Agent Collaborative Legal Assista.pdf:application/pdf},
}

@book{corrales_compagnucci_legal_2020,
	address = {Singapore},
	series = {Perspectives in {Law}, {Business} and {Innovation}},
	title = {Legal {Tech} and the {New} {Sharing} {Economy}},
	copyright = {http://www.springer.com/tdm},
	isbn = {9789811513497 9789811513503},
	url = {http://link.springer.com/10.1007/978-981-15-1350-3},
	language = {en},
	urldate = {2024-07-13},
	publisher = {Springer Singapore},
	editor = {Corrales Compagnucci, Marcelo and Forgó, Nikolaus and Kono, Toshiyuki and Teramoto, Shinto and Vermeulen, Erik P. M.},
	year = {2020},
	doi = {10.1007/978-981-15-1350-3},
	keywords = {OS, Legal Tech and Decentralization},
	file = {Corrales Compagnucci et al. - 2020 - Legal Tech and the New Sharing Economy.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\7MP37DVY\\Corrales Compagnucci et al. - 2020 - Legal Tech and the New Sharing Economy.pdf:application/pdf},
}

@inproceedings{cooper_non-determinism_2022,
	title = {Non-{Determinism} and the {Lawlessness} of {Machine} {Learning} {Code}},
	url = {http://arxiv.org/abs/2206.11834},
	doi = {10.1145/3511265.3550446},
	abstract = {Legal literature on machine learning (ML) tends to focus on harms, and thus tends to reason about individual model outcomes and summary error rates. This focus has masked important aspects of ML that are rooted in its reliance on randomness — namely, stochasticity and non-determinism. While some recent work has begun to reason about the relationship between stochasticity and arbitrariness in legal contexts, the role of non-determinism more broadly remains unexamined. In this paper, we clarify the overlap and differences between these two concepts, and show that the effects of non-determinism, and consequently its implications for the law, become clearer from the perspective of reasoning about ML outputs as distributions over possible outcomes. This distributional viewpoint accounts for randomness by emphasizing the possible outcomes of ML. Importantly, this type of reasoning is not exclusive with current legal reasoning; it complements (and in fact can strengthen) analyses concerning individual, concrete outcomes for specific automated decisions. By illuminating the important role of non-determinism, we demonstrate that ML code falls outside of the cyberlaw frame of treating “code as law,” as this frame assumes that code is deterministic. We conclude with a brief discussion of what work ML can do to constrain the potentially harm-inducing effects of non-determinism, and we indicate where the law must do work to bridge the gap between its current individual-outcome focus and the distributional approach that we recommend.},
	language = {en},
	urldate = {2024-09-08},
	booktitle = {Proceedings of the 2022 {Symposium} on {Computer} {Science} and {Law}},
	author = {Cooper, A. Feder and Frankle, Jonathan and De Sa, Christopher},
	month = nov,
	year = {2022},
	note = {arXiv:2206.11834 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, OS, ML - Non-Determinism},
	pages = {1--8},
	annote = {Comment: Proceedings of the 2022 Symposium on Computer Science and Law (CSLAW '22)},
	file = {Cooper et al. - 2022 - Non-Determinism and the Lawlessness of Machine Lea.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\7TQ6AVVH\\Cooper et al. - 2022 - Non-Determinism and the Lawlessness of Machine Lea.pdf:application/pdf},
}

@misc{colombo_saullm-7b_2024,
	title = {{SaulLM}-{7B}: {A} pioneering {Large} {Language} {Model} for {Law}},
	shorttitle = {{SaulLM}-{7B}},
	url = {http://arxiv.org/abs/2403.03883},
	abstract = {In this paper, we introduce SaulLM-7B, a large language model (LLM) tailored for the legal domain. With 7 billion parameters, SaulLM-7B is the first LLM designed explicitly for legal text comprehension and generation. Leveraging the Mistral 7B architecture as its foundation, SaulLM-7B is trained on an English legal corpus of over 30 billion tokens. SaulLM-7B exhibits state-of-the-art proficiency in understanding and processing legal documents. Additionally, we present a novel instructional finetuning method that leverages legal datasets to further enhance SaulLM-7B’s performance in legal tasks. SaulLM-7B is released under the MIT License.},
	language = {en},
	urldate = {2024-08-06},
	publisher = {arXiv},
	author = {Colombo, Pierre and Pires, Telmo Pessoa and Boudiaf, Malik and Culver, Dominic and Melo, Rui and Corro, Caio and Martins, Andre F. T. and Esposito, Fabrizio and Raposo, Vera Lúcia and Morgado, Sofia and Desa, Michael},
	month = mar,
	year = {2024},
	note = {arXiv:2403.03883 [cs]},
	keywords = {Computer Science - Computation and Language, OS, Legal Language Model - SaulLM-7B},
	file = {Colombo et al. - 2024 - SaulLM-7B A pioneering Large Language Model for L.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\R9KQ8LI5\\Colombo et al. - 2024 - SaulLM-7B A pioneering Large Language Model for L.pdf:application/pdf},
}

@inproceedings{coelho_information_2024,
	address = {Angers, France},
	title = {Information {Extraction} in the {Legal} {Domain}: {Traditional} {Supervised} {Learning} vs. {ChatGPT}:},
	isbn = {978-989-758-692-7},
	shorttitle = {Information {Extraction} in the {Legal} {Domain}},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0012499800003690},
	doi = {10.5220/0012499800003690},
	language = {en},
	urldate = {2024-08-04},
	booktitle = {Proceedings of the 26th {International} {Conference} on {Enterprise} {Information} {Systems}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Coelho, Gustavo and Celecia, Alimed and De Sousa, Jefferson and Lemos, Melissa and Lima, Maria and Mangeth, Ana and Frajhof, Isabella and Casanova, Marco},
	year = {2024},
	keywords = {OS, Information Extraction - Confusion Matrix},
	pages = {579--586},
	file = {Coelho et al. - 2024 - Information Extraction in the Legal Domain Tradit.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\9GVFJSRB\\Coelho et al. - 2024 - Information Extraction in the Legal Domain Tradit.pdf:application/pdf},
}

@article{choi_how_2024,
	title = {How to {Use} {Large} {Language} {Models} for {Empirical} {Legal} {Research}},
	volume = {180},
	issn = {0932-4569},
	url = {https://www.mohrsiebeck.com/10.1628/jite-2024-0020},
	doi = {10.1628/jite-2024-0020},
	abstract = {Legal scholars have long annotated cases by hand to summarize and learn about developments in jurisprudence. Dramatic recent improvements in the performance of large language models (LLMs) now provide a potential alternative. This article demonstrates how to use LLMs to analyze legal documents. It evaluates best practices and suggests both the uses and potential limitations of LLMs in empirical legal research. In a simple classiﬁcation task involving Supreme Court opinions, it ﬁnds that GPT-4 performs approximately as well as human coders and signiﬁcantly better than a variety of prior-generation natural language processing (NLP) classiﬁers, with no improvement from supervised training, ﬁnetuning, or specialized prompting.},
	language = {en},
	number = {2},
	urldate = {2024-09-10},
	journal = {Journal of Institutional and Theoretical Economics},
	author = {Choi, Jonathan H.},
	year = {2024},
	keywords = {OS, LLM for Legal Research},
	pages = {1},
	file = {2024 - Contents.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\UX95GLCY\\2024 - Contents.pdf:application/pdf},
}

@article{choi_measuring_2024,
	title = {Measuring {Clarity} in {Legal} {Text}},
	language = {en},
	journal = {The University of Chicago Law Review},
	author = {Choi, Jonathan H},
	year = {2024},
	keywords = {OS, Word Embeddings and Cosine Similarity},
	file = {Choi - Measuring Clarity in Legal Text.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\WSBVV5Y6\\Choi - Measuring Clarity in Legal Text.pdf:application/pdf},
}

@misc{chiang_chatbot_2024,
	title = {Chatbot {Arena}: {An} {Open} {Platform} for {Evaluating} {LLMs} by {Human} {Preference}},
	shorttitle = {Chatbot {Arena}},
	url = {http://arxiv.org/abs/2403.04132},
	abstract = {Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowdsourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. Our demo is publicly available at https://chat.lmsys.org.},
	language = {en},
	urldate = {2024-09-19},
	publisher = {arXiv},
	author = {Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhang, Hao and Zhu, Banghua and Jordan, Michael and Gonzalez, Joseph E. and Stoica, Ion},
	month = mar,
	year = {2024},
	note = {arXiv:2403.04132 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, OS, Chatbot Arena - Evaluating LLMs by Human Preference},
	file = {Chiang et al. - 2024 - Chatbot Arena An Open Platform for Evaluating LLM.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\DA44UTAS\\Chiang et al. - 2024 - Chatbot Arena An Open Platform for Evaluating LLM.pdf:application/pdf},
}

@inproceedings{cheong_i_2024,
	address = {Rio de Janeiro Brazil},
	title = {({A}){I} {Am} {Not} a {Lawyer}, {But}...: {Engaging} {Legal} {Experts} towards {Responsible} {LLM} {Policies} for {Legal} {Advice}},
	isbn = {9798400704505},
	shorttitle = {({A}){I} {Am} {Not} a {Lawyer}, {But}...},
	url = {https://dl.acm.org/doi/10.1145/3630106.3659048},
	doi = {10.1145/3630106.3659048},
	abstract = {Large language models (LLMs) are increasingly capable of providing users with advice in a wide range of professional domains, including legal advice. However, relying on LLMs for legal queries raises concerns due to the significant expertise required and the potential real-world consequences of the advice. To explore when and why LLMs should or should not provide advice to users, we conducted workshops with 20 legal experts using methods inspired by casebased reasoning. The provided realistic queries (“cases”) allowed experts to examine granular, situation-specific concerns and overarching technical and legal constraints, producing a concrete set of contextual considerations for LLM developers. By synthesizing the factors that impacted LLM response appropriateness, we present a 4dimension framework: (1) User attributes and behaviors, (2) Nature of queries, (3) AI capabilities, and (4) Social impacts. We share experts’ recommendations for LLM response strategies, which center around helping users identify ‘right questions to ask’ and relevant information rather than providing definitive legal judgments. Our findings reveal novel legal considerations, such as unauthorized practice of law, confidentiality, and liability for inaccurate advice, that have been overlooked in the literature. The case-based deliberation method enabled us to elicit fine-grained, practice-informed insights that surpass those from de-contextualized surveys or speculative principles. These findings underscore the applicability of our method for translating domain-specific professional knowledge and practices into policies that can guide LLM behavior in a more responsible direction.},
	language = {en},
	urldate = {2024-09-10},
	booktitle = {The 2024 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Cheong, Inyoung and Xia, King and Feng, K. J. Kevin and Chen, Quan Ze and Zhang, Amy X.},
	month = jun,
	year = {2024},
	keywords = {OS, Query Dimensions - LLM},
	pages = {2454--2469},
	file = {Cheong et al. - 2024 - (A)I Am Not a Lawyer, But... Engaging Legal Exper.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\3A4BXM7A\\Cheong et al. - 2024 - (A)I Am Not a Lawyer, But... Engaging Legal Exper.pdf:application/pdf},
}

@misc{chen_survey_2024,
	title = {A {Survey} on {Large} {Language} {Models} for {Critical} {Societal} {Domains}: {Finance}, {Healthcare}, and {Law}},
	shorttitle = {A {Survey} on {Large} {Language} {Models} for {Critical} {Societal} {Domains}},
	url = {http://arxiv.org/abs/2405.01769},
	abstract = {In the fast-evolving domain of artificial intelligence, large language models (LLMs) such as GPT-3 and GPT-4 are revolutionizing the landscapes of finance, healthcare, and law: domains characterized by their reliance on professional expertise, challenging data acquisition, high-stakes, and stringent regulatory compliance. This survey offers a detailed exploration of the methodologies, applications, challenges, and forward-looking opportunities of LLMs within these high-stakes sectors. We highlight the instrumental role of LLMs in enhancing diagnostic and treatment methodologies in healthcare, innovating financial analytics, and refining legal interpretation and compliance strategies. Moreover, we critically examine the ethics for LLM applications in these fields, pointing out the existing ethical concerns and the need for transparent, fair, and robust AI systems that respect regulatory norms. By presenting a thorough review of current literature and practical applications, we showcase the transformative impact of LLMs, and outline the imperative for interdisciplinary cooperation, methodological advancements, and ethical vigilance. Through this lens, we aim to spark dialogue and inspire future research dedicated to maximizing the benefits of LLMs while mitigating their risks in these precision-dependent sectors. To facilitate future research on LLMs in these critical societal domains, we also initiate a reading list that tracks the latest advancements under this topic, which will be continually updated: {\textbackslash}url\{https://github.com/czyssrs/LLM\_X\_papers\}.},
	language = {en},
	urldate = {2024-08-04},
	publisher = {arXiv},
	author = {Chen, Zhiyu Zoey and Ma, Jing and Zhang, Xinlu and Hao, Nan and Yan, An and Nourbakhsh, Armineh and Yang, Xianjun and McAuley, Julian and Petzold, Linda and Wang, William Yang},
	month = may,
	year = {2024},
	note = {arXiv:2405.01769 [cs]},
	keywords = {Computer Science - Computation and Language, OS, Survey on LLM for Critical Societal Domains},
	annote = {Comment: 35 pages, 6 figures},
	file = {Chen et al. - 2024 - A Survey on Large Language Models for Critical Soc.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ZZELIYF6\\Chen et al. - 2024 - A Survey on Large Language Models for Critical Soc.pdf:application/pdf},
}

@book{campesato_python_2024,
	address = {Duxbury},
	title = {Python 3 and machine learning using {ChatGPT}/{GPT}-4},
	isbn = {978-1-5015-2295-6},
	abstract = {"This book is designed to provide the reader with basic Python 3 programming and ChatGPT concepts related to machine learning. The first chapter provides a fast-paced introduction to Python, Pandas and JSON. The next two chapters introduce the fundamental concepts of machine learning. The fourth chapter transitions to the realm of Generative AI, discussing its distinction from Conversational AI. Popular platforms and models, including ChatGPT, GPT-4, and their competitors, are presented to give readers an understanding of the current AI landscape. Chapters five through eight cover uses of GPT-4 in machine learning including linear regression, classifiers, clustering and data visualization including DALL-E"--},
	language = {en},
	publisher = {Mercury Learning and Information},
	author = {Campesato, Oswald},
	year = {2024},
	keywords = {OS, Book - Python 3 and machine learning using GPT-4},
	file = {Campesato - 2024 - Python 3 and machine learning using ChatGPTGPT-4.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\4XVMK37V\\Campesato - 2024 - Python 3 and machine learning using ChatGPTGPT-4.pdf:application/pdf},
}

@book{campesato_transformer_2023,
	address = {Duxbury},
	title = {Transformer, {BERT}, and {GPTx}},
	isbn = {978-1-68392-898-0},
	abstract = {"This book begins with foundational concepts such as the attention mechanism, delves deep into tokenization techniques, explores the nuances of Transformer and BERT architectures, and culminates in advanced topics related to the latest in the GPT series, including ChatGPT. Key chapters provide insights into the evolution and significance of attention in deep learning, the intricacies of the Transformer architecture, a two-part exploration of the BERT family, and hands-on guidance on working with GPT-3. The concluding chap-ters present an overview of ChatGPT, GPT-4, and the captivating world of visualization using generative AI. In addition to the primary topics, the document also sheds light on influential AI organizations such as DeepMind, OpenAI, Cohere, HuggingFace, and more. Through this guide, readers will gain a comprehensive understanding of the current landscape of NLP models, their underlying architectures, and practical applications. Whether you're a seasoned AI researcher or a curious enthusiast, this detailed ta-ble of contents serves as a roadmap to the world of Transformers, BERT, and GPT, guid-ing you through their inception, evolution, and future potential"--},
	language = {en},
	publisher = {Mercury Learning and Information},
	author = {Campesato, Oswald},
	year = {2023},
	keywords = {OS, Book - Transformer, BERT, GPT},
	file = {Campesato - 2023 - Transformer, BERT, and GPTx.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\9GE4XMS6\\Campesato - 2023 - Transformer, BERT, and GPTx.pdf:application/pdf},
}

@misc{bubeck_sparks_2023,
	title = {Sparks of {Artificial} {General} {Intelligence}: {Early} experiments with {GPT}-4},
	shorttitle = {Sparks of {Artificial} {General} {Intelligence}},
	url = {http://arxiv.org/abs/2303.12712},
	abstract = {Artiﬁcial intelligence (AI) researchers have been developing and reﬁning large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4 [Ope23], was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT4 is part of a new cohort of LLMs (along with ChatGPT and Google’s PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and diﬃcult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4’s performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4’s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artiﬁcial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reﬂections on societal inﬂuences of the recent technological leap and future research directions.},
	language = {en},
	urldate = {2024-09-28},
	publisher = {arXiv},
	author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
	month = apr,
	year = {2023},
	note = {arXiv:2303.12712 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, OS, GPT-4 Intelligence - Experiments},
	file = {Bubeck et al. - 2023 - Sparks of Artificial General Intelligence Early e.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\L6E2PVCV\\Bubeck et al. - 2023 - Sparks of Artificial General Intelligence Early e.pdf:application/pdf},
}

@article{briva-iglesias_large_2024,
	title = {Large language models "ad referendum": {How} good are they at machine translation in the legal domain?},
	copyright = {https://creativecommons.org/licenses/by/4.0},
	issn = {1989-9335, 1889-4178},
	shorttitle = {Large language models "ad referendum"},
	url = {https://www.e-revistes.uji.es/index.php/monti/article/view/7514},
	doi = {10.6035/MonTI.2024.16.02},
	abstract = {This study evaluates the machine translation (MT) quality of two state-of-the-art large language models (LLMs) against a traditional neural machine translation (NMT) system across four language pairs in the legal domain. It combines automatic evaluation metrics (AEMs) and human evaluation (HE) by professional translators to assess translation ranking, fluency and adequacy. The results indicate that while Google Translate generally outperforms LLMs in AEMs, human evaluators rate LLMs, especially GPT-4, comparably or slightly better in terms of producing contextually adequate and fluent translations. This discrepancy suggests LLMs' potential in handling specialized legal terminology and context, highlighting the importance of human evaluation methods in assessing MT quality. The study underscores the evolving capabilities of LLMs in specialized domains and calls for reevaluation of traditional AEMs to better capture the nuances of LLM-generated translations.
          , 
            Este estudio evalúa la calidad de la traducción automática (TA) de dos grandes modelos de lengua de última generación frente a un sistema tradicional de traducción automática neural (TAN) en cuatro pares de idiomas en el ámbito jurídico. Combinamos métricas de evaluación automática con una evaluación humana de traductores profesionales mediante el análisis de la clasificación, la fluidez y la adecuación de las traducciones. Los resultados indican que, mientras que Google Translate suele superar a los grandes modelos de lengua en las métricas automáticas, los evaluadores humanos valoran a los grandes modelos de lengua, especialmente a GPT-4, de forma comparable o ligeramente mejor en cuanto a fluidez y adecuación. Esta discrepancia sugiere el potencial de los grandes modelos de lengua para trabajar terminología jurídica especializada y contextualizada, lo que pone de relieve la importancia de los métodos de evaluación humana a la hora de evaluar la calidad de la TA. El estudio subraya la evolución de las capacidades de los grandes modelos de lengua en dominios especializados y aboga por una reevaluación de las métricas automáticas tradicionales para captar mejor los matices de las traducciones generadas por grandes modelos de lengua.},
	language = {en},
	number = {16},
	urldate = {2024-09-10},
	journal = {MonTI. Monografías de Traducción e Interpretación},
	author = {Briva-Iglesias, Vicent and Dogru, Gokhan and Cavalheiro Camargo, João Lucas},
	month = may,
	year = {2024},
	keywords = {OS, Maschine Translation Quality},
	pages = {75--107},
	file = {Briva-Iglesias et al. - 2024 - Large language models ad referendum How good ar.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\6IUX8JKI\\Briva-Iglesias et al. - 2024 - Large language models ad referendum How good ar.pdf:application/pdf},
}

@article{braun_i_2024,
	title = {I beg to differ: how disagreement is handled in the annotation of legal machine learning data sets},
	volume = {32},
	issn = {0924-8463, 1572-8382},
	shorttitle = {I beg to differ},
	url = {https://link.springer.com/10.1007/s10506-023-09369-4},
	doi = {10.1007/s10506-023-09369-4},
	abstract = {Legal documents, like contracts or laws, are subject to interpretation. Different people can have different interpretations of the very same document. Large parts of judicial branches all over the world are concerned with settling disagreements that arise, in part, from these different interpretations. In this context, it only seems natural that during the annotation of legal machine learning data sets, disagreement, how to report it, and how to handle it should play an important role. This article presents an analysis of the current state-of-the-art in the annotation of legal machine learning data sets. The results of the analysis show that all of the analysed data sets remove all traces of disagreement, instead of trying to utilise the information that might be contained in conflicting annotations. Additionally, the publications introducing the data sets often do provide little information about the process that derives the “gold standard” from the initial annotations, often making it difficult to judge the reliability of the annotation process. Based on the state-of-the-art, the article provides easily implementable suggestions on how to improve the handling and reporting of disagreement in the annotation of legal machine learning data sets.},
	language = {en},
	number = {3},
	urldate = {2024-09-21},
	journal = {Artificial Intelligence and Law},
	author = {Braun, Daniel},
	month = sep,
	year = {2024},
	keywords = {OS, Annotators Agreement - Building Data Sets},
	pages = {839--862},
	file = {Braun - 2024 - I beg to differ how disagreement is handled in th.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\5YFY9WJT\\Braun - 2024 - I beg to differ how disagreement is handled in th.pdf:application/pdf},
}

@book{botsch_maschinelles_2023,
	address = {Berlin, Heidelberg},
	title = {Maschinelles {Lernen} - {Grundlagen} und {Anwendungen}: {Mit} {Beispielen} in {Python}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-662-67276-1 978-3-662-67277-8},
	shorttitle = {Maschinelles {Lernen} - {Grundlagen} und {Anwendungen}},
	url = {https://link.springer.com/10.1007/978-3-662-67277-8},
	language = {de},
	urldate = {2024-09-08},
	publisher = {Springer Berlin Heidelberg},
	author = {Botsch, Benny},
	year = {2023},
	doi = {10.1007/978-3-662-67277-8},
	keywords = {OS, Book - ML - Grundlagen und Anwendungen, Python},
	file = {Botsch - 2023 - Maschinelles Lernen - Grundlagen und Anwendungen .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\UNKL86LN\\Botsch - 2023 - Maschinelles Lernen - Grundlagen und Anwendungen .pdf:application/pdf},
}

@misc{bhambhoria_evaluating_2024,
	title = {Evaluating {AI} for {Law}: {Bridging} the {Gap} with {Open}-{Source} {Solutions}},
	shorttitle = {Evaluating {AI} for {Law}},
	url = {http://arxiv.org/abs/2404.12349},
	abstract = {This study evaluates the performance of general-purpose AI, like ChatGPT, in legal question-answering tasks, highlighting significant risks to legal professionals and clients. It suggests leveraging foundational models enhanced by domain-specific knowledge to overcome these issues. The paper advocates for creating open-source legal AI systems to improve accuracy, transparency, and narrative diversity, addressing general AI’s shortcomings in legal contexts.},
	language = {en},
	urldate = {2024-09-10},
	publisher = {arXiv},
	author = {Bhambhoria, Rohan and Dahan, Samuel and Li, Jonathan and Zhu, Xiaodan},
	year = {2024},
	note = {arXiv:2404.12349 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, OS, Open Justice Model},
	file = {Bhambhoria et al. - 2024 - Evaluating AI for Law Bridging the Gap with Open-.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\GIB4HZYD\\Bhambhoria et al. - 2024 - Evaluating AI for Law Bridging the Gap with Open-.pdf:application/pdf},
}

@incollection{curini_text_2020,
	address = {1 Oliver's Yard, 55 City Road London EC1Y 1SP},
	title = {Text as {Data}: {An} {Overview}},
	isbn = {978-1-5264-5993-0 978-1-5264-8638-7},
	shorttitle = {Text as {Data}},
	url = {https://sk.sagepub.com/reference/the-sage-handbook-of-research-methods-in-political-science-and-ir/i4365.xml},
	language = {en},
	urldate = {2024-08-03},
	booktitle = {The {SAGE} {Handbook} of {Research} {Methods} in {Political} {Science} and {International} {Relations}},
	publisher = {SAGE Publications Ltd},
	author = {Benoit, Ken},
	collaborator = {Curini, Luigi and Franzese, Robert},
	year = {2020},
	doi = {10.4135/9781526486387.n29},
	keywords = {OS, Basics - Text as Data},
	pages = {461--497},
	file = {Benoit - 2020 - Text as Data An Overview.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LTU6MXRR\\Benoit - 2020 - Text as Data An Overview.pdf:application/pdf},
}

@misc{aynetdinov_semscore_2024,
	title = {{SemScore}: {Automated} {Evaluation} of {Instruction}-{Tuned} {LLMs} based on {Semantic} {Textual} {Similarity}},
	shorttitle = {{SemScore}},
	url = {http://arxiv.org/abs/2401.17072},
	abstract = {Instruction-tuned Large Language Models (LLMs) have recently showcased remarkable advancements in their ability to generate fitting responses to natural language instructions. However, many current works rely on manual evaluation to judge the quality of generated responses. Since such manual evaluation is time-consuming, it does not easily scale to the evaluation of multiple models and model variants. In this short paper, we propose a straightforward but remarkably effective evaluation metric called SEMSCORE, in which we directly compare model outputs to gold target responses using semantic textual similarity (STS). We conduct a comparative evaluation of the model outputs of 12 prominent instructiontuned LLMs using 8 widely-used evaluation metrics for text generation. We find that our proposed SEMSCORE metric outperforms all other, in many cases more complex, evaluation metrics in terms of correlation to human evaluation. These findings indicate the utility of our proposed metric for the evaluation of instruction-tuned LLMs.},
	language = {en},
	urldate = {2024-07-29},
	publisher = {arXiv},
	author = {Aynetdinov, Ansar and Akbik, Alan},
	month = feb,
	year = {2024},
	note = {arXiv:2401.17072 [cs]},
	keywords = {Computer Science - Computation and Language, OS, Baseline Evaluation Metrics - LLM},
	file = {Aynetdinov und Akbik - 2024 - SemScore Automated Evaluation of Instruction-Tune.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\C4H5BDQY\\Aynetdinov und Akbik - 2024 - SemScore Automated Evaluation of Instruction-Tune.pdf:application/pdf},
}

@incollection{engstrom_litigation_2023,
	edition = {1},
	title = {Litigation {Outcome} {Prediction}, {Access} to {Justice}, and {Legal} {Endogeneity}},
	isbn = {978-1-00-925530-1 978-1-00-925535-6 978-1-00-925534-9},
	url = {https://www.cambridge.org/core/product/identifier/9781009255301%23CN-bp-7/type/book_part},
	language = {en},
	urldate = {2024-08-08},
	booktitle = {Legal {Tech} and the {Future} of {Civil} {Justice}},
	publisher = {Cambridge University Press},
	author = {Alexander, Charlotte S.},
	editor = {Engstrom, David Freeman},
	month = feb,
	year = {2023},
	doi = {10.1017/9781009255301.010},
	keywords = {OS, Computational Law - Consequences of computationally driven litigation outcome prediction tools for the civil justice system},
	pages = {155--172},
	file = {Alexander - 2023 - Litigation Outcome Prediction, Access to Justice, .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\AQHL9LT2\\Alexander - 2023 - Litigation Outcome Prediction, Access to Justice, .pdf:application/pdf},
}

@book{alex_yu_data_2022,
	address = {New York},
	edition = {1},
	title = {Data {Mining} and {Exploration}: {From} {Traditional} {Statistics} to {Modern} {Data} {Science}},
	isbn = {978-1-00-315365-8},
	shorttitle = {Data {Mining} and {Exploration}},
	url = {https://www.taylorfrancis.com/books/9781003153658},
	language = {en},
	urldate = {2024-07-29},
	publisher = {CRC Press},
	author = {Alex Yu, Chong Ho},
	month = jul,
	year = {2022},
	doi = {10.1201/9781003153658},
	keywords = {OS, Book - Modern Data Science},
	file = {Alex Yu - 2022 - Data Mining and Exploration From Traditional Stat.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\BJYXX462\\Alex Yu - 2022 - Data Mining and Exploration From Traditional Stat.pdf:application/pdf},
}

@article{alaswad_using_2023,
	title = {Using {ChatGPT} and other {LLMs} in {Professional} {Environments}},
	volume = {12},
	issn = {20909551, 2090956X},
	url = {https://digitalcommons.aaru.edu.jo/isl/vol12/iss9/17/},
	doi = {10.18576/isl/120916},
	abstract = {Large language models like ChatGPT, Google’s Bard, and Microsoft’s new Bing, to name a few, are developing rapidly in recent years, becoming very popular in different environments, and supporting a wide range of tasks. A deep look into their outcomes reveals several limitations and challenges that can be further improved. The main challenge of these models is the possibility of generating biased or inaccurate results, since these models rely on large amounts of data with no access to unpublic information. Moreover, these language models need to be properly monitored and trained to prevent generating inappropriate or offensive content and to ensure that they are used ethically and safely. This study investigates the use of ChatGPT and other large language models such as Blender, and BERT in professional environments. It has been found that none of the large language models, including ChatGPT, have been used in unstructured dialogues. Moreover, involving the models in professional environments requires extensive training and monitoring by domain professionals or fine-tuning through API.},
	language = {en},
	number = {9},
	urldate = {2024-09-10},
	journal = {Information Sciences Letters},
	author = {Alaswad and {Kalganova} and {Awad}},
	month = sep,
	year = {2023},
	keywords = {OS, General Information - LLM},
	pages = {2097--2108},
	file = {2023 - Using ChatGPT and other LLMs in Professional Envir.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\BKFYUPW3\\2023 - Using ChatGPT and other LLMs in Professional Envir.pdf:application/pdf},
}

@article{al_zubaer_performance_2023,
	title = {Performance analysis of large language models in the domain of legal argument mining},
	volume = {6},
	issn = {2624-8212},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2023.1278796/full},
	doi = {10.3389/frai.2023.1278796},
	abstract = {Generative pre-trained transformers (GPT) have recently demonstrated excellent performance in various natural language tasks. The development of ChatGPT and the recently released GPT-4 model has shown competence in solving complex and higher-order reasoning tasks without further training or fine-tuning. However, the applicability and strength of these models in classifying legal texts in the context of argument mining are yet to be realized and have not been tested thoroughly. In this study, we investigate the effectiveness of GPT-like models, specifically GPT-3.5 and GPT-4, for argument mining via prompting. We closely study the model's performance considering diverse prompt formulation and example selection in the prompt via semantic search using state-of-the-art embedding models from OpenAI and sentence transformers. We primarily concentrate on the argument component classification task on the legal corpus from the European Court of Human Rights. To address these models' inherent non-deterministic nature and make our result statistically sound, we conducted 5-fold cross-validation on the test set. Our experiments demonstrate, quite surprisingly, that relatively small domain-specific models outperform GPT 3.5 and GPT-4 in the F1-score for premise and conclusion classes, with 1.9\% and 12\% improvements, respectively. We hypothesize that the performance drop indirectly reflects the complexity of the structure in the dataset, which we verify through prompt and data analysis. Nevertheless, our results demonstrate a noteworthy variation in the performance of GPT models based on prompt formulation. We observe comparable performance between the two embedding models, with a slight improvement in the local model's ability for prompt selection. This suggests that local models are as semantically rich as the embeddings from the OpenAI model. Our results indicate that the structure of prompts significantly impacts the performance of GPT models and should be considered when designing them.},
	language = {en},
	urldate = {2024-09-10},
	journal = {Frontiers in Artificial Intelligence},
	author = {Al Zubaer, Abdullah and Granitzer, Michael and Mitrović, Jelena},
	month = nov,
	year = {2023},
	keywords = {OS, Legal Argument Mining - LLM},
	pages = {1278796},
	file = {Al Zubaer et al. - 2023 - Performance analysis of large language models in t.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\QDDBYWUW\\Al Zubaer et al. - 2023 - Performance analysis of large language models in t.pdf:application/pdf},
}

@article{agarwala_detecting_2021,
	title = {Detecting {Semantic} {Similarity} {Of} {Documents} {Using} {Natural} {Language} {Processing}},
	volume = {189},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050921011716},
	doi = {10.1016/j.procs.2021.05.076},
	language = {en},
	urldate = {2024-08-18},
	journal = {Procedia Computer Science},
	author = {Agarwala, Saurabh and Anagawadi, Aniketh and Reddy Guddeti, Ram Mohana},
	year = {2021},
	keywords = {OS, NLP - Semantic Similarity of Documents},
	pages = {128--135},
	file = {Agarwala et al. - 2021 - Detecting Semantic Similarity Of Documents Using N.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\BKSLKH49\\Agarwala et al. - 2021 - Detecting Semantic Similarity Of Documents Using N.pdf:application/pdf},
}

@book{aggarwal_machine_2022,
	address = {Cham},
	title = {Machine {Learning} for {Text}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-030-96622-5 978-3-030-96623-2},
	url = {https://link.springer.com/10.1007/978-3-030-96623-2},
	language = {en},
	urldate = {2024-08-03},
	publisher = {Springer International Publishing},
	author = {Aggarwal, Charu C.},
	year = {2022},
	doi = {10.1007/978-3-030-96623-2},
	keywords = {OS, Book - Machine Learning for Text},
	file = {Aggarwal - 2022 - Machine Learning for Text.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\XG62Q8CZ\\Aggarwal - 2022 - Machine Learning for Text.pdf:application/pdf},
}

@article{ray_chatgpt_2023,
	title = {{ChatGPT}: {A} comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope},
	volume = {3},
	issn = {26673452},
	shorttitle = {{ChatGPT}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S266734522300024X},
	doi = {10.1016/j.iotcps.2023.04.003},
	abstract = {In recent years, artiﬁcial intelligence (AI) and machine learning have been transforming the landscape of scientiﬁc research. Out of which, the chatbot technology has experienced tremendous advancements in recent years, especially with ChatGPT emerging as a notable AI language model. This comprehensive review delves into the background, applications, key challenges, and future directions of ChatGPT. We begin by exploring its origins, development, and underlying technology, before examining its wide-ranging applications across industries such as customer service, healthcare, and education. We also highlight the critical challenges that ChatGPT faces, including ethical concerns, data biases, and safety issues, while discussing potential mitigation strategies. Finally, we envision the future of ChatGPT by exploring areas of further research and development, focusing on its integration with other technologies, improved human-AI interaction, and addressing the digital divide. This review offers valuable insights for researchers, developers, and stakeholders interested in the ever-evolving landscape of AI-driven conversational agents. This study explores the various ways ChatGPT has been revolutionizing scientiﬁc research, spanning from data processing and hypothesis generation to collaboration and public outreach. Furthermore, the paper examines the potential challenges and ethical concerns surrounding the use of ChatGPT in research, while highlighting the importance of striking a balance between AI-assisted innovation and human expertise. The paper presents several ethical issues in existing computing domain and how ChatGPT can invoke challenges to such notion. This work also includes some biases and limitations of ChatGPT. It is worth to note that despite of several controversies and ethical concerns, ChatGPT has attracted remarkable attentions from academia, research, and industries in a very short span of time.},
	language = {en},
	urldate = {2024-09-10},
	journal = {Internet of Things and Cyber-Physical Systems},
	author = {Ray, Partha Pratim},
	year = {2023},
	keywords = {OS, LLM - ChatGPT Overview},
	pages = {121--154},
	file = {Ray - 2023 - ChatGPT A comprehensive review on background, app.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\22KYE73V\\Ray - 2023 - ChatGPT A comprehensive review on background, app.pdf:application/pdf},
}

@article{rasiah_one_2024,
	title = {{ONE} {LAW}, {MANY} {LANGUAGES}: {BENCHMARKING} {MULTILINGUAL} {LEGAL} {REASONING} {FOR} {JUDICIAL} {SUPPORT}},
	abstract = {Recent strides in Large Language Models (LLMs) have saturated many NLP benchmarks (even professional domain-specific ones), emphasizing the need for more challenging ones to properly assess LLM capabilities. Domain-specific and multilingual benchmarks are rare, since they require high expertise to develop. Still, most public models are trained predominantly on English corpora, while other languages remain understudied, particularly for practical domain-specific NLP tasks. In this work, we introduce a novel NLP benchmark that poses challenges to current LLMs across four key dimensions: processing long documents (up to 50K tokens), using domain-specific knowledge (embodied in legal texts), multilingual understanding (covering five languages), and multitasking (comprising legal document-to-document Information Retrieval, Court View Generation, Leading Decision Summarization, Citation Extraction, and eight challenging Text Classification tasks). Our benchmark contains diverse datasets from the Swiss legal system, allowing for a comprehensive study of the underlying non-English, inherently multilingual, federal legal system. Despite the large size of our datasets (tens to hundreds of thousands of examples), existing publicly available multilingual models struggle with most tasks, even after extensive in-domain pre-training and fine-tuning. We publish all resources (benchmark suite, pre-trained models, code) under fully permissive open CC BY-SA licenses.},
	language = {en},
	author = {Rasiah, Vishvaksenan and Stern, Ronja and Stürmer, Matthias and Chalkidis, Ilias and Niklaus, Joel and Matoshi, Veton and Ho, Daniel E},
	year = {2024},
	keywords = {OS, LLM - Benchmarking Multilingual Legal Reasoning},
	file = {Rasiah et al. - 2024 - ONE LAW, MANY LANGUAGES BENCHMARKING MULTILINGUAL.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\B9WN6FHT\\Rasiah et al. - 2024 - ONE LAW, MANY LANGUAGES BENCHMARKING MULTILINGUAL.pdf:application/pdf},
}

@article{qiu_are_nodate,
	title = {Are {Large} {Language} {Models} {Temporally} {Grounded}?},
	language = {en},
	author = {Qiu, Yifu and Zhao, Zheng and Ziser, Yftah and Korhonen, Anna and Ponti, Edoardo M and Cohen, Shay B},
	keywords = {OS, LLM - Temporary Reasoning},
	file = {Qiu et al. - Are Large Language Models Temporally Grounded.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\BLXLNUMQ\\Qiu et al. - Are Large Language Models Temporally Grounded.pdf:application/pdf},
}

@misc{qin_exploring_2024,
	title = {Exploring the {Nexus} of {Large} {Language} {Models} and {Legal} {Systems}: {A} {Short} {Survey}},
	shorttitle = {Exploring the {Nexus} of {Large} {Language} {Models} and {Legal} {Systems}},
	url = {http://arxiv.org/abs/2404.00990},
	abstract = {With the advancement of Artificial Intelligence (AI) and Large Language Models (LLMs), there is a profound transformation occurring in the realm of natural language processing tasks within the legal domain. The capabilities of LLMs are increasingly demonstrating unique roles in the legal sector, bringing both distinctive benefits and various challenges. This survey delves into the synergy between LLMs and the legal system, such as their applications in tasks like legal text comprehension, case retrieval, and analysis. Furthermore, this survey highlights key challenges faced by LLMs in the legal domain, including bias, interpretability, and ethical considerations, as well as how researchers are addressing these issues. The survey showcases the latest advancements in fine-tuned legal LLMs tailored for various legal systems, along with legal datasets available for fine-tuning LLMs in various languages. Additionally, it proposes directions for future research and development.},
	language = {en},
	urldate = {2024-08-04},
	publisher = {arXiv},
	author = {Qin, Weicong and Sun, Zhongxiang},
	month = apr,
	year = {2024},
	note = {arXiv:2404.00990 [cs]},
	keywords = {Computer Science - Computation and Language, Applied Computing - Law, Nexus of LLMs and Legal Systems},
	file = {Qin und Sun - 2024 - Exploring the Nexus of Large Language Models and L.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\GB5XQHME\\Qin und Sun - 2024 - Exploring the Nexus of Large Language Models and L.pdf:application/pdf},
}

@article{soh_tsin_howe_discovering_2024,
	title = {Discovering significant topics from legal decisions with selective inference},
	volume = {382},
	issn = {1364-503X, 1471-2962},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2023.0147},
	doi = {10.1098/rsta.2023.0147},
	abstract = {We propose and evaluate an automated pipeline for discovering significant topics from legal decision texts by passing features synthesized with topic models through penalized regressions and post-selection significance tests. The method identifies case topics significantly correlated with outcomes, topic-word distributions which can be manually interpreted to gain insights about significant topics, and case-topic weights which can be used to identify representative cases for each topic. We demonstrate the method on a new dataset of domain name disputes and a canonical dataset of European Court of Human Rights violation cases. Topic models based on latent semantic analysis as well as language model embeddings are evaluated. We show that topics derived by the pipeline are consistent with legal doctrines in both areas and can be useful in other related legal analysis tasks.
            This article is part of the theme issue ‘A complexity science approach to law and governance’.},
	language = {en},
	number = {2270},
	urldate = {2024-08-06},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Soh Tsin Howe, Jerrold},
	month = apr,
	year = {2024},
	keywords = {OS, Legal Language Processing - Text as Data},
	pages = {20230147},
	file = {Soh Tsin Howe - 2024 - Discovering significant topics from legal decision.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\QDK8IGMU\\Soh Tsin Howe - 2024 - Discovering significant topics from legal decision.pdf:application/pdf},
}

@misc{shankar_who_2024,
	title = {Who {Validates} the {Validators}? {Aligning} {LLM}-{Assisted} {Evaluation} of {LLM} {Outputs} with {Human} {Preferences}},
	shorttitle = {Who {Validates} the {Validators}?},
	url = {http://arxiv.org/abs/2404.12272},
	abstract = {Due to the cumbersome nature of human evaluation and limitations of code-based evaluation, Large Language Models (LLMs) are increasingly being used to assist humans in evaluating LLM outputs. Yet LLM-generated evaluators simply inherit all the problems of the LLMs they evaluate, requiring further human validation. We present a mixed-initiative approach to “validate the validators”—aligning LLM-generated evaluation functions (be it prompts or code) with human requirements. Our interface, EvalGen, provides automated assistance to users in generating evaluation criteria and implementing assertions. While generating candidate implementations (Python functions, LLM grader prompts), EvalGen asks humans to grade a subset of LLM outputs; this feedback is used to select implementations that better align with user grades. A qualitative study finds overall support for EvalGen but underscores the subjectivity and iterative process of alignment. In particular, we identify a phenomenon we dub criteria drift: users need criteria to grade outputs, but grading outputs helps users define criteria. What is more, some criteria appears dependent on the specific LLM outputs observed (rather than independent criteria that can be defined a priori), raising serious questions for approaches that assume the independence of evaluation from observation of model outputs. We present our interface and implementation details, a comparison of our algorithm with a baseline approach, and implications for the design of future LLM evaluation assistants.},
	language = {en},
	urldate = {2024-09-19},
	publisher = {arXiv},
	author = {Shankar, Shreya and Zamfirescu-Pereira, J. D. and Hartmann, Björn and Parameswaran, Aditya G. and Arawjo, Ian},
	month = apr,
	year = {2024},
	note = {arXiv:2404.12272 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, OS, LLM - Evaluation - LLM-Assisted Evaluation of LLM Outputs with Human Preferences},
	annote = {Comment: 16 pages, 4 figures, 2 tables},
	file = {Shankar et al. - 2024 - Who Validates the Validators Aligning LLM-Assiste.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\4MSIHTUT\\Shankar et al. - 2024 - Who Validates the Validators Aligning LLM-Assiste.pdf:application/pdf},
}

@book{selvaraj_mastering_2024,
	address = {Berkeley, CA},
	title = {Mastering {REST} {APIs}: {Boosting} {Your} {Web} {Development} {Journey} with {Advanced} {API} {Techniques}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {9798868803086 9798868803093},
	shorttitle = {Mastering {REST} {APIs}},
	url = {https://link.springer.com/10.1007/979-8-8688-0309-3},
	language = {en},
	urldate = {2024-07-30},
	publisher = {Apress},
	author = {Selvaraj, Sivaraj},
	year = {2024},
	doi = {10.1007/979-8-8688-0309-3},
	keywords = {Book - REST APIs},
	file = {Selvaraj - 2024 - Mastering REST APIs Boosting Your Web Development.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\NA55FJRC\\Selvaraj - 2024 - Mastering REST APIs Boosting Your Web Development.pdf:application/pdf},
}

@misc{kalweit_warum_2024,
	title = {Warum wir neu lernen müssen, mit {Maschinen} zu sprechen – eine {Momentaufnahme} der {Generativen} {KI} im {Januar} 2024},
	url = {https://ordnungderwissenschaft.de/wp-content/uploads/2024/03/Kalweit-Druckfahne-V4.pdf},
	language = {de},
	urldate = {2024-09-07},
	author = {Kalweit, Maria and Kalweit, Gabriel},
	year = {2024},
	keywords = {OS, Neurorobotics - Momentaufnahme einer Generativen KI},
	annote = {Other
ICLR 2024 Camera Ready version. With respect to the original submission, we added text generation experiments, plots of entire accuracy distributions for each task + stdev computations, and prompt length correlation with spread analysis},
	file = {Sclar et al. - 2023 - Quantifying Language Models' Sensitivity to Spurio.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\3DZCQ7JM\\Sclar et al. - 2023 - Quantifying Language Models' Sensitivity to Spurio.pdf:application/pdf},
}

@article{sciannameo_information_2024,
	title = {Information extraction from medical case reports using {OpenAI} {InstructGPT}},
	volume = {255},
	issn = {01692607},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169260724003195},
	doi = {10.1016/j.cmpb.2024.108326},
	abstract = {Background and objective: Researchers commonly use automated solutions such as Natural Language Processing (NLP) systems to extract clinical information from large volumes of unstructured data. However, clinical text’s poor semantic structure and domain-specific vocabulary can make it challenging to develop a one-size-fits-all solution. Large Language Models (LLMs), such as OpenAI’s Generative Pre-Trained Transformer 3 (GPT-3), offer a promising solution for capturing and standardizing unstructured clinical information. This study evaluated the performance of InstructGPT, a family of models derived from LLM GPT-3, to extract relevant patient information from medical case reports and discussed the advantages and disadvantages of LLMs versus dedicated NLP methods.
Methods: In this paper, 208 articles related to case reports of foreign body injuries in children were identified by searching PubMed, Scopus, and Web of Science. A reviewer manually extracted information on sex, age, the object that caused the injury, and the injured body part for each patient to build a gold standard to compare the performance of InstructGPT.
Results: InstructGPT achieved high accuracy in classifying the sex, age, object and body part involved in the injury, with 94\%, 82\%, 94\% and 89\%, respectively. When excluding articles for which InstructGPT could not retrieve any information, the accuracy for determining the child’s sex and age improved to 97\%, and the accuracy for identifying the injured body part improved to 93\%. InstructGPT was also able to extract information from non-English language articles.
Conclusions: The study highlights that LLMs have the potential to eliminate the necessity for task-specific training (zero-shot extraction), allowing the retrieval of clinical information from unstructured natural language text, particularly from published scientific literature like case reports, by directly utilizing the PDF file of the article without any pre-processing and without requiring any technical expertise in NLP or Machine Learning. The diverse nature of the corpus, which includes articles written in languages other than English, some of which contain a wide range of clinical details while others lack information, adds to the strength of the study.},
	language = {en},
	urldate = {2024-08-05},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Sciannameo, Veronica and Pagliari, Daniele Jahier and Urru, Sara and Grimaldi, Piercesare and Ocagli, Honoria and Ahsani-Nasab, Sara and Comoretto, Rosanna Irene and Gregori, Dario and Berchialla, Paola},
	month = oct,
	year = {2024},
	keywords = {OS, Information Extraction - Clinical Reports Example},
	pages = {108326},
	file = {Sciannameo et al. - 2024 - Information extraction from medical case reports u.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\H4FWJCBY\\Sciannameo et al. - 2024 - Information extraction from medical case reports u.pdf:application/pdf},
}

@article{schneider_foundation_2024,
	title = {Foundation {Models}: {A} {New} {Paradigm} for {Artificial} {Intelligence}},
	volume = {66},
	issn = {2363-7005, 1867-0202},
	shorttitle = {Foundation {Models}},
	url = {https://link.springer.com/10.1007/s12599-024-00851-0},
	doi = {10.1007/s12599-024-00851-0},
	language = {en},
	number = {2},
	urldate = {2024-09-07},
	journal = {Business \& Information Systems Engineering},
	author = {Schneider, Johannes and Meske, Christian and Kuss, Pauline},
	month = apr,
	year = {2024},
	keywords = {OS, Foundational Models - Potentiial},
	pages = {221--231},
	file = {Schneider et al. - 2024 - Foundation Models A New Paradigm for Artificial I.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\X6JZGRF7\\Schneider et al. - 2024 - Foundation Models A New Paradigm for Artificial I.pdf:application/pdf},
}

@inproceedings{savelka_can_2023,
	title = {Can {GPT}-4 {Support} {Analysis} of {Textual} {Data} in {Tasks} {Requiring} {Highly} {Specialized} {Domain} {Expertise}?},
	url = {http://arxiv.org/abs/2306.13906},
	doi = {10.1145/3587102.3588792},
	abstract = {We evaluated the capability of generative pre-trained transformers (GPT-4) in analysis of textual data in tasks that require highly specialized domain expertise. Specifically, we focused on the task of analyzing court opinions to interpret legal concepts. We found that GPT-4, prompted with annotation guidelines, performs on par with well-trained law student annotators. We observed that, with a relatively minor decrease in performance, GPT-4 can perform batch predictions leading to significant cost reductions. However, employing chain-of-thought prompting did not lead to noticeably improved performance on this task. Further, we demonstrated how to analyze GPT-4’s predictions to identify and mitigate deficiencies in annotation guidelines, and subsequently improve the performance of the model. Finally, we observed that the model is quite brittle, as small formatting related changes in the prompt had a high impact on the predictions. These findings can be leveraged by researchers and practitioners who engage in semantic/pragmatic annotations of texts in the context of the tasks requiring highly specialized domain expertise.},
	language = {en},
	urldate = {2024-09-10},
	booktitle = {Proceedings of the 2023 {Conference} on {Innovation} and {Technology} in {Computer} {Science} {Education} {V}. 1},
	author = {Savelka, Jaromir and Ashley, Kevin D. and Gray, Morgan A. and Westermann, Hannes and Xu, Huihui},
	month = jun,
	year = {2023},
	note = {arXiv:2306.13906 [cs]},
	keywords = {Computer Science - Computation and Language, OS, LLM - Legal Analysis of Texual Data},
	pages = {117--123},
	file = {Savelka et al. - 2023 - Can GPT-4 Support Analysis of Textual Data in Task.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\L8X9J6XI\\Savelka et al. - 2023 - Can GPT-4 Support Analysis of Textual Data in Task.pdf:application/pdf},
}

@article{savelka_unreasonable_2023,
	title = {The unreasonable effectiveness of large language models in zero-shot semantic annotation of legal texts},
	volume = {6},
	issn = {2624-8212},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2023.1279794/full},
	doi = {10.3389/frai.2023.1279794},
	abstract = {The emergence of ChatGPT has sensitized the general public, including the legal profession, to large language models' (LLMs) potential uses (e.g., document drafting, question answering, and summarization). Although recent studies have shown how well the technology performs in diverse semantic annotation tasks focused on legal texts, an influx of newer, more capable (GPT-4) or cost-effective (GPT-3.5-turbo) models requires another analysis. This paper addresses recent developments in the ability of LLMs to semantically annotate legal texts in zero-shot learning settings. Given the transition to mature generative AI systems, we examine the performance of GPT-4 and GPT-3.5-turbo(-16k), comparing it to the previous generation of GPT models, on three legal text annotation tasks involving diverse documents such as adjudicatory opinions, contractual clauses, or statutory provisions. We also compare the models' performance and cost to better understand the trade-offs. We found that the GPT-4 model clearly outperforms the GPT-3.5 models on two of the three tasks. The cost-effective GPT-3.5-turbo matches the performance of the 20× more expensive text-davinci-003 model. While one can annotate multiple data points within a single prompt, the performance degrades as the size of the batch increases. This work provides valuable information relevant for many practical applications (e.g., in contract review) and research projects (e.g., in empirical legal studies). Legal scholars and practicing lawyers alike can leverage these findings to guide their decisions in integrating LLMs in a wide range of workflows involving semantic annotation of legal texts.},
	language = {en},
	urldate = {2024-09-10},
	journal = {Frontiers in Artificial Intelligence},
	author = {Savelka, Jaromir and Ashley, Kevin D.},
	month = nov,
	year = {2023},
	keywords = {OS, Semantic Annotation - GPT for Legal Texts},
	pages = {1279794},
	file = {Savelka und Ashley - 2023 - The unreasonable effectiveness of large language m.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\TM7D86VW\\Savelka und Ashley - 2023 - The unreasonable effectiveness of large language m.pdf:application/pdf},
}

@inproceedings{savelka_unlocking_2023,
	address = {Braga Portugal},
	title = {Unlocking {Practical} {Applications} in {Legal} {Domain}: {Evaluation} of {GPT} for {Zero}-{Shot} {Semantic} {Annotation} of {Legal} {Texts}},
	isbn = {9798400701979},
	shorttitle = {Unlocking {Practical} {Applications} in {Legal} {Domain}},
	url = {https://dl.acm.org/doi/10.1145/3594536.3595161},
	doi = {10.1145/3594536.3595161},
	abstract = {We evaluated the capability of a state-of-the-art generative pretrained transformer (GPT) model to perform semantic annotation of short text snippets (one to few sentences) coming from legal documents of various types. Discussions of potential uses (e.g., document drafting, summarization) of this emerging technology in legal domain have intensified, but to date there has not been a rigorous analysis of these large language models’ (LLM) capacity in sentence-level semantic annotation of legal texts in zero-shot learning settings. Yet, this particular type of use could unlock many practical applications (e.g., in contract review) and research opportunities (e.g., in empirical legal studies). We fill the gap with this study. We examined if and how successfully the model can semantically annotate small batches of short text snippets (10–50) based exclusively on concise definitions of the semantic types. We found that the GPT model performs surprisingly well in zero-shot settings on diverse types of documents (F1 = .73 on a task involving court opinions, .86 for contracts, and .54 for statutes and regulations). These findings can be leveraged by legal scholars and practicing lawyers alike to guide their decisions in integrating LLMs in wide range of workflows involving semantic annotation of legal texts.},
	language = {en},
	urldate = {2024-09-10},
	booktitle = {Proceedings of the {Nineteenth} {International} {Conference} on {Artificial} {Intelligence} and {Law}},
	publisher = {ACM},
	author = {Savelka, Jaromir},
	month = jun,
	year = {2023},
	keywords = {OS, Semantic Annotation - GPT for Legal Texts},
	pages = {447--451},
	file = {Savelka - 2023 - Unlocking Practical Applications in Legal Domain .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\A2AXL35J\\Savelka - 2023 - Unlocking Practical Applications in Legal Domain .pdf:application/pdf},
}

@book{rothman_transformers_2022,
	address = {Birmingham Mumbai},
	edition = {Second edition},
	series = {Expert {Insight}},
	title = {Transformers for natural language processing: build, train, and fine-tune deep neural network architectures for {NLP} with {Python}, {Hugging} {Face}, and {OpenAI}´s {GPT3}, {ChatGPT}, and {GPT}-4},
	isbn = {978-1-80324-733-5},
	shorttitle = {Transformers for natural language processing},
	language = {en},
	publisher = {Packt},
	author = {Rothman, Denis},
	year = {2022},
	keywords = {OS, Book - Transformers for NLP},
	file = {Rothman - 2022 - Transformers for natural language processing buil.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\XIW2SN8U\\Rothman - 2022 - Transformers for natural language processing buil.pdf:application/pdf},
}

@article{romein_exploring_2024,
	title = {Exploring {Data} {Provenance} in {Handwritten} {Text} {Recognition} {Infrastructure}: {Sharing} and {Reusing} {Ground} {Truth} {Data}, {Referencing} {Models}, and {Acknowledging} {Contributions}. {Starting} the {Conversation} on {How} {We} {Could} {Get} {It} {Done}},
	volume = {Historical Documents and...},
	issn = {2416-5999},
	shorttitle = {Exploring {Data} {Provenance} in {Handwritten} {Text} {Recognition} {Infrastructure}},
	url = {https://jdmdh.episciences.org/10403},
	doi = {10.46298/jdmdh.10403},
	abstract = {This paper discusses best practices for sharing and reusing Ground Truth in Handwritten Text Recognition infrastructures, as well as ways to reference and acknowledge contributions to the creation and enrichment of data within these systems. We discuss how one can place Ground Truth data in a repository and, subsequently, inform others through HTR-United. Furthermore, we want to suggest appropriate citation methods for ATR data, models, and contributions made by volunteers. Moreover, when using digitised sources (digital facsimiles), it becomes increasingly important to distinguish between the physical object and the digital collection. These topics all relate to the proper acknowledgement of labour put into digitising, transcribing, and sharing Ground Truth HTR data. This also points to broader issues surrounding the use of machine learning in archival and library contexts, and how the community should begin to acknowledge and record both contributions and data provenance.},
	language = {en},
	urldate = {2024-09-16},
	journal = {Journal of Data Mining \& Digital Humanities},
	author = {Romein, C. Annemieke and Hodel, Tobias and Gordijn, Femke and Zundert, Joris J. Van and Chagué, Alix and Lange, Milan Van and Jensen, Helle Strandgaard and Stauder, Andy and Purcell, Jake and Terras, Melissa M. and Heuvel, Pauline Van Den and Keijzer, Carlijn and Rabus, Achim and Sitaram, Chantal and Bhatia, Aakriti and Depuydt, Katrien and Afolabi-Adeolu, Mary Aderonke and Anikina, Anastasiia and Bastianello, Elisa and Benzinger, Lukas Vincent and Bosse, Arno and Brown, David and Charlton, Ash and Dannevig, André Nilsson and Gelder, Klaas Van and Go, Sabine C.P.J. and Goh, Marcus J.C. and Gstrein, Silvia and Hasan, Sewa and Heide, Stefan Von Der and Hindermann, Maximilian and Huff, Dorothee and Huysman, Ineke and Idris, Ali and Keijzer, Liesbeth and Kemper, Simon and Koenders, Sanne and Kuijpers, Erika and Rønsig Larsen, Lisette and Lepa, Sven and Link, Tommy O. and Nispen, Annelies Van and Nockels, Joe and Noort, Laura M. Van and Oosterhuis, Joost Johannes and Popken, Vivien and Estrella Puertollano, María and Puusaag, Joosep J. and Sheta, Ahmed and Stoop, Lex and Strutzenbladh, Ebba and Sijs, Nicoline Van Der and Spek, Jan Paul Van Der and Trouw, Barry Benaissa and Van Synghel, Geertrui and Vučković, Vladimir and Wilbrink, Heleen and Weiss, Sonia and Wrisley, David Joseph and Zweistra, Riet},
	month = mar,
	year = {2024},
	keywords = {OS, Data Mining - Ground Truth},
	pages = {10403},
	file = {Romein et al. - 2024 - Exploring Data Provenance in Handwritten Text Reco:C\:\\Users\\WeigoldS\\Zotero\\storage\\7C8NWERJ\\Romein et al. - 2024 - Exploring Data Provenance in Handwritten Text Reco:application/pdf},
}

@article{richmond_explainable_2024,
	title = {Explainable {AI} and {Law}: {An} {Evidential} {Survey}},
	volume = {3},
	issn = {2731-4650, 2731-4669},
	shorttitle = {Explainable {AI} and {Law}},
	url = {https://link.springer.com/10.1007/s44206-023-00081-z},
	doi = {10.1007/s44206-023-00081-z},
	abstract = {Decisions made by legal adjudicators and administrative decision-makers often found upon a reservoir of stored experiences, from which is drawn a tacit body of expert knowledge. Such expertise may be implicit and opaque, even to the decisionmakers themselves, and generates obstacles when implementing AI for automated decision-making tasks within the legal field, since, to the extent that AI-powered decision-making tools must found upon a stock of domain expertise, opacities may proliferate. This raises particular issues within the legal domain, which requires a high level of accountability, thus transparency. This requires enhanced explainability, which entails that a heterogeneous body of stakeholders understand the mechanism underlying the algorithm to the extent that an explanation can be furnished. However, the “black-box” nature of some AI variants, such as deep learning, remains unresolved, and many machine decisions therefore remain poorly understood. This survey paper, based upon a unique interdisciplinary collaboration between legal and AI experts, provides a review of the explainability spectrum, as informed by a systematic survey of relevant research papers, and categorises the results. The article establishes a novel taxonomy, linking the differing forms of legal inference at play within particular legal sub-domains to specific forms of algorithmic decisionmaking. The diverse categories demonstrate different dimensions in explainable AI (XAI) research. Thus, the survey departs from the preceding monolithic approach to legal reasoning and decision-making by incorporating heterogeneity in legal logics: a feature which requires elaboration, and should be accounted for when designing AI-driven decision-making systems for the legal field. It is thereby hoped that administrative decision-makers, court adjudicators, researchers, and practitioners can gain unique insights into explainability, and utilise the survey as the basis for further research within the field.},
	language = {en},
	number = {1},
	urldate = {2024-09-10},
	journal = {Digital Society},
	author = {Richmond, Karen McGregor and Muddamsetty, Satya M. and Gammeltoft-Hansen, Thomas and Olsen, Henrik Palmer and Moeslund, Thomas B.},
	month = may,
	year = {2024},
	keywords = {OS, AI and Law - Explainable AI},
	pages = {1},
	file = {Richmond et al. - 2024 - Explainable AI and Law An Evidential Survey.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\SN3N3DWW\\Richmond et al. - 2024 - Explainable AI and Law An Evidential Survey.pdf:application/pdf},
}

@article{vladika_towards_nodate,
	title = {Towards {A} {Structured} {Overview} of {Use} {Cases} for {Natural} {Language} {Processing} in the {Legal} {Domain}: {A} {German} {Perspective}},
	abstract = {In recent years, the field of Legal Tech has risen in prevalence, as the Natural Language Processing (NLP) and legal disciplines have combined forces to digitalize legal processes. Amidst the steady flow of research solutions stemming from the NLP domain, the study of use cases has fallen behind, leading to a number of innovative technical methods without a place in practice. In this work, we aim to build a structured overview of Legal Tech use cases, grounded in NLP literature, but also supplemented by voices from legal practice in Germany. Based upon a Systematic Literature Review, we identify seven categories of NLP technologies for the legal domain, which are then studied in juxtaposition to 22 legal use cases. In the investigation of these use cases, we identify 15 ethical, legal, and social aspects (ELSA), shedding light on the potential concerns of digitally transforming the legal domain.},
	language = {en},
	author = {Vladika, Juraj and Meisenbacher, Stephen},
	keywords = {OS, NLP - Legal Use Cases},
	file = {Vladika und Meisenbacher - Towards A Structured Overview of Use Cases for Nat.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\WTQSSL4J\\Vladika und Meisenbacher - Towards A Structured Overview of Use Cases for Nat.pdf:application/pdf},
}

@article{tibshirani_valerie_nodate,
	title = {Valerie and {Patrick} {Hastie}},
	language = {en},
	author = {Tibshirani, Sami and Friedman, Harry},
	keywords = {OS, Book - Statistical Learning - Data Mining, Inference, Prediction},
	file = {Tibshirani und Friedman - Valerie and Patrick Hastie.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\DVPUA5IP\\Tibshirani und Friedman - Valerie and Patrick Hastie.pdf:application/pdf},
}

@book{thakur_artificial_2024,
	address = {Boca Raton},
	edition = {1},
	title = {Artificial {Intelligence} and {Large} {Language} {Models}: {An} {Introduction} to the {Technological} {Future}},
	isbn = {978-1-00-347417-3},
	shorttitle = {Artificial {Intelligence} and {Large} {Language} {Models}},
	url = {https://www.taylorfrancis.com/books/9781003474173},
	language = {en},
	urldate = {2024-07-13},
	publisher = {Chapman and Hall/CRC},
	author = {Thakur, Kutub and Barker, Helen G. and Khan Pathan, Al-Sakib},
	month = may,
	year = {2024},
	doi = {10.1201/9781003474173},
	keywords = {OS, Book - AI and LLM},
	file = {Thakur et al. - 2024 - Artificial Intelligence and Large Language Models.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\PTYBHP2H\\Thakur et al. - 2024 - Artificial Intelligence and Large Language Models.pdf:application/pdf},
}

@article{tan_chatgpt_2023,
	title = {{ChatGPT} as an {Artificial} {Lawyer}?},
	abstract = {Lawyers can analyze and understand specific situations of their clients to provide them with relevant legal information and advice. We qualitatively investigate to which extent ChatGPT (a large language model developed by OpenAI) may be able to carry out some of these tasks, to provide legal information to laypeople. This paper proposes a framework for evaluating the provision of legal information as a process, evaluating not only its accuracy in providing legal information, but also its ability to understand and reason about users’ needs. We perform an initial investigation of ChatGPT’s ability to provide legal information using several simulated cases. We also compare the performance to that of JusticeBot, a legal information tool based on expert systems. While ChatGPT does not always provide accurate and reliable information, it acts as a powerful and intuitive way to interact with laypeople. This research opens the door to combining the two approaches for flexible and accurate legal information tools.},
	language = {en},
	author = {Tan, Jinzhe and Westermann, Hannes and Benyekhlef, Karim},
	year = {2023},
	keywords = {OS, LLM - Qualitative Evaluation},
	file = {Tan et al. - ChatGPT as an Artificial Lawyer.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\XEQX6KQA\\Tan et al. - ChatGPT as an Artificial Lawyer.pdf:application/pdf},
}

@article{taipalus_vector_2024,
	title = {Vector database management systems: {Fundamental} concepts, use-cases, and current challenges},
	volume = {85},
	issn = {13890417},
	shorttitle = {Vector database management systems},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1389041724000093},
	doi = {10.1016/j.cogsys.2024.101216},
	abstract = {Vector database management systems have emerged as an important component in modern data management, driven by the growing importance for the need to computationally describe rich data such as texts, images and video in various domains such as recommender systems, similarity search, and chatbots. These data descriptions are captured as numerical vectors that are computationally inexpensive to store and compare. However, the unique characteristics of vectorized data, including high dimensionality and sparsity, demand specialized solutions for efficient storage, retrieval, and processing. This narrative literature review provides an accessible introduction to the fundamental concepts, use-cases, and current challenges associated with vector database management systems, offering an overview for researchers and practitioners seeking to facilitate effective vector data management.},
	language = {en},
	urldate = {2024-08-12},
	journal = {Cognitive Systems Research},
	author = {Taipalus, Toni},
	month = jun,
	year = {2024},
	keywords = {OS, Database - Vector Database Management Systems},
	pages = {101216},
	file = {Taipalus - 2024 - Vector database management systems Fundamental co.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\29V2ZHS8\\Taipalus - 2024 - Vector database management systems Fundamental co.pdf:application/pdf},
}

@book{tabatabaian_prompt_2024,
	address = {Duxbury},
	title = {Prompt engineering and {GPTs}},
	isbn = {978-1-5015-2241-3},
	abstract = {"This book is a gateway to understanding the intricate process of crafting effective prompts, with a special emphasis on ChatGPT and its advanced iterations, including GPT-4 and GPTs, the ground-breaking innovations from OpenAI (https://openai.com/). Whether you are a student fascinated by the vast potential of AI or a professional trying to harness its power for practical applications, this guide is designed to provide you with the essential knowledge and techniques for effective interaction with AI systems"--},
	language = {en},
	publisher = {Mercury Learning and Information},
	author = {Tabatabaian, Mehrzad},
	year = {2024},
	keywords = {OS, Book - Prompt Engeneering and GPT},
	file = {Tabatabaian - 2024 - Prompt engineering and GPTs.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\BGJGP9S3\\Tabatabaian - 2024 - Prompt engineering and GPTs.pdf:application/pdf},
}

@book{subhash_khandare_mastering_2024,
	address = {S.l.},
	title = {{MASTERING} {LARGE} {LANGUAGE} {MODELS} advanced techniques, applications, cutting-edge methods,... and top llms},
	isbn = {978-93-5551-762-3},
	language = {en},
	publisher = {BPB PUBLICATIONS},
	author = {SUBHASH KHANDARE, SANKET},
	year = {2024},
	note = {OCLC: 1428526309},
	keywords = {OS, Book - LLM Handbook (written by LLM?)},
	file = {SUBHASH KHANDARE - 2024 - MASTERING LARGE LANGUAGE MODELS advanced technique.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\C299R4EW\\SUBHASH KHANDARE - 2024 - MASTERING LARGE LANGUAGE MODELS advanced technique.pdf:application/pdf},
}

@book{studer_relationale_2019,
	address = {Berlin, Heidelberg},
	title = {Relationale {Datenbanken}: {Von} den theoretischen {Grundlagen} zu {Anwendungen} mit {PostgreSQL}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-662-58975-5 978-3-662-58976-2},
	shorttitle = {Relationale {Datenbanken}},
	url = {http://link.springer.com/10.1007/978-3-662-58976-2},
	language = {de},
	urldate = {2024-07-29},
	publisher = {Springer Berlin Heidelberg},
	author = {Studer, Thomas},
	year = {2019},
	doi = {10.1007/978-3-662-58976-2},
	keywords = {OS, Book - Relationale Datenbanken},
	file = {Studer - 2019 - Relationale Datenbanken Von den theoretischen Gru.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\XWGSXH2W\\Studer - 2019 - Relationale Datenbanken Von den theoretischen Gru.pdf:application/pdf},
}

@book{stubblebine_regular_2007,
	address = {Beijing Cambridge Farnham KölnSebastopol Tokyo},
	edition = {Second edition},
	title = {Regular expression pocket reference},
	isbn = {978-0-596-51427-3},
	language = {en},
	publisher = {O'Reilly},
	author = {Stubblebine, Tony},
	year = {2007},
	keywords = {OS, Book - RegEx - Pocket Reference},
	file = {Stubblebine - 2007 - Regular expression pocket reference.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\HU3EQEL6\\Stubblebine - 2007 - Regular expression pocket reference.pdf:application/pdf},
}

@article{strobel_exploring_nodate,
	title = {Exploring {Generative} {Artificial} {Intelligence}: {A} {Taxonomy} and {Types}},
	abstract = {Generative Artificial Intelligence (GAI) is a prevalent topic in recent research and business, seemingly taking the position of a disruptive technology that has the potential to significantly transform industries ranging from productivity (e.g., ChatGPT-4) to creativity (e.g., DALL-E). While the emerging scientific discussion on GAI covers a variety of fields and issues, such as privacy, accuracy, and application scenarios, this paper sheds light on the business side of GAI by investigating the morphologic nature of start-ups and incumbents leveraging GAI. Based on the structured analysis of 100 real-world instances, we report on a taxonomy of GAI applications and services that advances our practical understanding, strengthens the distinguishability, as well as adds clarity to the discourse of GAI potentials. We provide an initial framework and five types of GAI, namely Generator, Reimaginator, Synthesizer, Assistant, and Enabler, that are informed by the core characteristics of the technology paradigm.},
	language = {en},
	author = {Strobel, Gero and Möller, Frederik and Braunschweig, TU and Banh, Leonardo and Schoormann, Thorsten},
	keywords = {OS, Generative Artificial Intelligence - Taxonomie},
	file = {Strobel et al. - Exploring Generative Artificial Intelligence A Ta.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LQIMDWN7\\Strobel et al. - Exploring Generative Artificial Intelligence A Ta.pdf:application/pdf},
}

@misc{stelmakh_gold_2023,
	title = {A {Gold} {Standard} {Dataset} for the {Reviewer} {Assignment} {Problem}},
	url = {http://arxiv.org/abs/2303.16750},
	abstract = {Many peer-review venues are either using or looking to use algorithms to assign submissions to reviewers. The crux of such automated approaches is the notion of the “similarity score”—a numerical estimate of the expertise of a reviewer in reviewing a paper—and many algorithms have been proposed to compute these scores. However, these algorithms have not been subjected to a principled comparison, making it diﬃcult for stakeholders to choose the algorithm in an evidence-based manner. The key challenge in comparing existing algorithms and developing better algorithms is the lack of the publicly available gold-standard data that would be needed to perform reproducible research. We address this challenge by collecting a novel dataset of similarity scores that we release to the research community. Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously.},
	language = {en},
	urldate = {2024-09-19},
	publisher = {arXiv},
	author = {Stelmakh, Ivan and Wieting, John and Neubig, Graham and Shah, Nihar B.},
	month = mar,
	year = {2023},
	note = {arXiv:2303.16750 [cs]},
	keywords = {Computer Science - Machine Learning, OS, Computer Science - Information Retrieval, Computer Science - Digital Libraries, NLP - Cosine Similarity},
	file = {Stelmakh et al. - 2023 - A Gold Standard Dataset for the Reviewer Assignmen.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\C7SFGFM9\\Stelmakh et al. - 2023 - A Gold Standard Dataset for the Reviewer Assignmen.pdf:application/pdf},
}

@inproceedings{steck_is_2024,
	title = {Is {Cosine}-{Similarity} of {Embeddings} {Really} {About} {Similarity}?},
	url = {http://arxiv.org/abs/2403.05440},
	doi = {10.1145/3589335.3651526},
	abstract = {Cosine-similarity is the cosine of the angle between two vectors, or equivalently the dot product between their normalizations. A popular application is to quantify semantic similarity between high-dimensional objects by applying cosine-similarity to a learned low-dimensional feature embedding. This can work better but sometimes also worse than the unnormalized dot-product between embedded vectors in practice. To gain insight into this empirical observation, we study embeddings derived from regularized linear models, where closed-form solutions facilitate analytical insights. We derive analytically how cosine-similarity can yield arbitrary and therefore meaningless ‘similarities.’ For some linear models the similarities are not even unique, while for others they are implicitly controlled by the regularization. We discuss implications beyond linear models: a combination of different regularizations are employed when learning deep models; these have implicit and unintended effects when taking cosinesimilarities of the resulting embeddings, rendering results opaque and possibly arbitrary. Based on these insights, we caution against blindly using cosine-similarity and outline alternatives.},
	language = {en},
	urldate = {2024-08-12},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2024},
	author = {Steck, Harald and Ekanadham, Chaitanya and Kallus, Nathan},
	month = may,
	year = {2024},
	note = {arXiv:2403.05440 [cs]},
	keywords = {Computer Science - Machine Learning, OS, Computer Science - Information Retrieval, NLP - Cosine Similarity},
	pages = {887--890},
	annote = {Comment: 9 pages},
	file = {Steck et al. - 2024 - Is Cosine-Similarity of Embeddings Really About Si.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\TDQM75ZB\\Steck et al. - 2024 - Is Cosine-Similarity of Embeddings Really About Si.pdf:application/pdf},
}

@inproceedings{yu_exploring_2023,
	address = {Toronto, Canada},
	title = {Exploring the {Effectiveness} of {Prompt} {Engineering} for {Legal} {Reasoning} {Tasks}},
	url = {https://aclanthology.org/2023.findings-acl.858},
	doi = {10.18653/v1/2023.findings-acl.858},
	abstract = {The use of large language models (LLMs) for zero- or few-shot prompting in natural language processing has given rise to a new research area known as prompt engineering, which shows promising improvement in tasks such as arithmetic and common-sense reasoning. This paper explores the use of such approaches in legal reasoning tasks by conducting experiments on the COLIEE entailment task, which is based on the Japanese Bar exam. We further evaluate zero-shot/few-shot and fine-tuning approaches with and without explanations, alongside various prompting strategies. Our results indicate that while these techniques can improve general performance, the best results are achieved with prompts derived from specific legal reasoning techniques, such as IRAC (Issue, Rule, Application, Conclusion). In addition, we observe that few-shot learning with demonstrations derived from clustering past training data consistently yields high performance on the most recent COLIEE entailment tasks. Through our experiments, we improve the previous best result on the 2021 COLIEE task from 0.7037 to 0.8025 and surpass the best system from 2022 with an accuracy of 0.789.},
	language = {en},
	urldate = {2024-08-04},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Yu, Fangyi and Quartey, Lee and Schilder, Frank},
	year = {2023},
	keywords = {OS, Prompt Engineering - Effectiveness},
	pages = {13582--13596},
	file = {Yu et al. - 2023 - Exploring the Effectiveness of Prompt Engineering .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\Q7HUZQQ5\\Yu et al. - 2023 - Exploring the Effectiveness of Prompt Engineering .pdf:application/pdf},
}

@article{yenduri_gpt_2024,
	title = {{GPT} ({Generative} {Pre}-{Trained} {Transformer})— {A} {Comprehensive} {Review} on {Enabling} {Technologies}, {Potential} {Applications}, {Emerging} {Challenges}, and {Future} {Directions}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10500411/},
	doi = {10.1109/ACCESS.2024.3389497},
	abstract = {The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.},
	language = {en},
	urldate = {2024-09-10},
	journal = {IEEE Access},
	author = {Yenduri, Gokul and Ramalingam, M. and Selvi, G. Chemmalar and Supriya, Y. and Srivastava, Gautam and Maddikunta, Praveen Kumar Reddy and Raj, G. Deepti and Jhaveri, Rutvij H. and Prabadevi, B. and Wang, Weizheng and Vasilakos, Athanasios V. and Gadekallu, Thippa Reddy},
	year = {2024},
	keywords = {OS, GPT - Comprehensive Review},
	pages = {54608--54649},
	file = {Yenduri et al. - 2024 - GPT (Generative Pre-Trained Transformer)— A Compre.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\IC5DT87A\\Yenduri et al. - 2024 - GPT (Generative Pre-Trained Transformer)— A Compre.pdf:application/pdf},
}

@misc{xu_hallucination_2024,
	title = {Hallucination is {Inevitable}: {An} {Innate} {Limitation} of {Large} {Language} {Models}},
	shorttitle = {Hallucination is {Inevitable}},
	url = {http://arxiv.org/abs/2401.11817},
	abstract = {Hallucination has been widely recognized to be a significant drawback for large language models (LLMs). There have been many works that attempt to reduce the extent of hallucination. These efforts have mostly been empirical so far, which cannot answer the fundamental question whether it can be completely eliminated. In this paper, we formalize the problem and show that it is impossible to eliminate hallucination in LLMs. Specifically, we define a formal world where hallucination is defined as inconsistencies between a computable LLM and a computable ground truth function. By employing results from learning theory, we show that LLMs cannot learn all of the computable functions and will therefore always hallucinate. Since the formal world is a part of the real world which is much more complicated, hallucinations are also inevitable for real world LLMs. Furthermore, for real world LLMs constrained by provable time complexity, we describe the hallucination-prone tasks and empirically validate our claims. Finally, using the formal world framework, we discuss the possible mechanisms and efficacies of existing hallucination mitigators as well as the practical implications on the safe deployment of LLMs.},
	language = {en},
	urldate = {2024-10-08},
	publisher = {arXiv},
	author = {Xu, Ziwei and Jain, Sanjay and Kankanhalli, Mohan},
	month = jan,
	year = {2024},
	note = {arXiv:2401.11817 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, OS, LLM - Halluzinations},
	file = {Xu et al. - 2024 - Hallucination is Inevitable An Innate Limitation .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\XVS6Q4HK\\Xu et al. - 2024 - Hallucination is Inevitable An Innate Limitation .pdf:application/pdf},
}

@misc{xiao_introduction_2023,
	title = {Introduction to {Transformers}: an {NLP} {Perspective}},
	shorttitle = {Introduction to {Transformers}},
	url = {http://arxiv.org/abs/2311.17633},
	abstract = {Transformers have dominated empirical machine learning models of natural language processing. In this paper, we introduce basic concepts of Transformers and present key techniques that form the recent advances of these models. This includes a description of the standard Transformer architecture, a series of model refinements, and common applications. Given that Transformers and related deep learning techniques might be evolving in ways we have never seen, we cannot dive into all the model details or cover all the technical areas. Instead, we focus on just those concepts that are helpful for gaining a good understanding of Transformers and their variants. We also summarize the key ideas that impact this field, thereby yielding some insights into the strengths and limitations of these models.},
	language = {en},
	urldate = {2024-08-10},
	publisher = {arXiv},
	author = {Xiao, Tong and Zhu, Jingbo},
	month = nov,
	year = {2023},
	note = {arXiv:2311.17633 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, OS, NLP - Transformers},
	annote = {Comment: 119 pages and 21 figures},
	file = {Xiao und Zhu - 2023 - Introduction to Transformers an NLP Perspective.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\CHRAN47C\\Xiao und Zhu - 2023 - Introduction to Transformers an NLP Perspective.pdf:application/pdf},
}

@book{wagner_legal_2018,
	address = {Wiesbaden},
	series = {essentials},
	title = {Legal {Tech} und {Legal} {Robots}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-658-20056-5 978-3-658-20057-2},
	url = {http://link.springer.com/10.1007/978-3-658-20057-2},
	language = {de},
	urldate = {2024-07-13},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Wagner, Jens},
	year = {2018},
	doi = {10.1007/978-3-658-20057-2},
	keywords = {OS, Book - Legal Tech},
	file = {Wagner - 2018 - Legal Tech und Legal Robots.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\J9BQHFCM\\Wagner - 2018 - Legal Tech und Legal Robots.pdf:application/pdf},
}

@misc{yue_disc-lawllm_2023,
	title = {{DISC}-{LawLLM}: {Fine}-tuning {Large} {Language} {Models} for {Intelligent} {Legal} {Services}},
	shorttitle = {{DISC}-{LawLLM}},
	url = {http://arxiv.org/abs/2309.11325},
	abstract = {We propose DISC-LawLLM, an intelligent legal system utilizing large language models (LLMs) to provide a wide range of legal services. We adopt legal syllogism prompting strategies to construct supervised fine-tuning datasets in the Chinese Judicial domain and fine-tune LLMs with legal reasoning capability. We augment LLMs with a retrieval module to enhance models’ ability to access and utilize external legal knowledge. A comprehensive legal benchmark, DISC-Law-Eval, is presented to evaluate intelligent legal systems from both objective and subjective dimensions. Quantitative and qualitative results on DISC-Law-Eval demonstrate the effectiveness of our system in serving various users across diverse legal scenarios. The detailed resources are available at https://github. com/FudanDISC/DISC-LawLLM.},
	language = {en},
	urldate = {2024-09-20},
	publisher = {arXiv},
	author = {Yue, Shengbin and Chen, Wei and Wang, Siyuan and Li, Bingxuan and Shen, Chenchen and Liu, Shujun and Zhou, Yuxuan and Xiao, Yao and Yun, Song and Huang, Xuanjing and Wei, Zhongyu},
	month = sep,
	year = {2023},
	note = {arXiv:2309.11325 [cs]},
	keywords = {Computer Science - Computation and Language, OS, LLM - Finetuning - Legal Services},
	file = {Yue et al. - 2023 - DISC-LawLLM Fine-tuning Large Language Models for.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\4NLRAYRQ\\Yue et al. - 2023 - DISC-LawLLM Fine-tuning Large Language Models for.pdf:application/pdf},
}

@article{yue_lawllm_2023,
	title = {{LawLLM}: {Intelligent} {Legal} {System} with {Legal} {Reasoning} and {Verifiable} {Retrieval}},
	abstract = {We propose LawLLM, an LLM-powered intelligent legal system featuring on (1) Versatile Services: LawLLM provides a versatile diverse range of services through its multi-task capabilities; (2) Legal Reasoning: It is fine-tuned on supervised instruction data curated with legal syllogism prompting, enabling LawLLM to develop stronger legal reasoning capabilities based on clear judicial logics; (3) Verifiable Retrieval: with verifiable labels, LawLLM can first distinguish relevant external knowledge, then incorporate and finally validate it, enhancing the quality and actuality of model output. A comprehensive legal benchmark, Law-Eval, is further constructed to evaluate intelligent legal systems from both objective and subjective dimensions. Experiments demonstrate the effectiveness of our system in serving various users across diverse legal scenarios. The detailed resources are available at https://github.com/FudanDISC/DISC-LawLLM.},
	language = {en},
	author = {Yue, Shengbin and Liu, Shujun and Zhou, Yuxuan and Shen, Chenchen and Wang, Siyuan and Xiao, Yao and Li, Bingxuan and Song, Yun and Shen, Xiaoyu and Chen, Wei and Huang, Xuanjing and Wei, Zhongyu},
	year = {2023},
	keywords = {OS, Legal Language Model - LawLLM},
	file = {Yue et al. - LawLLM Intelligent Legal System with Legal Reason.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\X69W9866\\Yue et al. - LawLLM Intelligent Legal System with Legal Reason.pdf:application/pdf},
}

@article{zheng_feature_2018,
	title = {Feature {Engineering} for {Machine} {Learning}},
	language = {en},
	author = {Zheng, Alice and Casari, Amanda},
	year = {2018},
	keywords = {OS, Book - Feature Engineering for Machine Learning},
	file = {Zheng und Casari - Feature Engineering for Machine Learning.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\M4FZ6JS9\\Zheng und Casari - Feature Engineering for Machine Learning.pdf:application/pdf},
}

@inproceedings{zhang_are_2024,
	address = {Utrecht, Netherlands},
	title = {Are {There} {Fundamental} {Limitations} in {Supporting} {Vector} {Data} {Management} in {Relational} {Databases}? {A} {Case} {Study} of {PostgreSQL}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350317152},
	shorttitle = {Are {There} {Fundamental} {Limitations} in {Supporting} {Vector} {Data} {Management} in {Relational} {Databases}?},
	url = {https://ieeexplore.ieee.org/document/10597811/},
	doi = {10.1109/ICDE60146.2024.00280},
	abstract = {High-dimensional vector data is gaining increasing importance in data science applications. Consequently, various database systems have recently been developed to manage vector data. These systems can be broadly categorized into two types: specialized and generalized vector databases. Specialized vector databases are explicitly designed and optimized for storing and querying vector data, while generalized vector databases support vector data management within a relational database like PostgreSQL. It is expected (and conﬁrmed by our experiments) that generalized vector databases exhibit slower performance. However, it is not clear whether there are fundamental limitations (or just implementation issues) for relational databases to support vector data management.},
	language = {en},
	urldate = {2024-08-12},
	booktitle = {2024 {IEEE} 40th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Zhang, Yunan and Liu, Shige and Wang, Jianguo},
	month = may,
	year = {2024},
	keywords = {OS, Database - Case Study PostgreSQL},
	pages = {3640--3653},
	file = {Zhang et al. - 2024 - Are There Fundamental Limitations in Supporting Ve.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\WAVQZJ6J\\Zhang et al. - 2024 - Are There Fundamental Limitations in Supporting Ve.pdf:application/pdf},
}

@misc{zhou_lawgpt_2024,
	title = {{LawGPT}: {A} {Chinese} {Legal} {Knowledge}-{Enhanced} {Large} {Language} {Model}},
	shorttitle = {{LawGPT}},
	url = {http://arxiv.org/abs/2406.04614},
	abstract = {Large language models (LLMs), including both proprietary and open-source models, have showcased remarkable capabilities in addressing a wide range of downstream tasks. Nonetheless, when it comes to practical Chinese legal tasks, these models fail to meet the actual requirements. Proprietary models do not ensure data privacy for sensitive legal cases, while open-source models demonstrate unsatisfactory performance due to their lack of legal knowledge. To address this problem, we introduce LAWGPT, the ﬁrst open-source model speciﬁcally designed for Chinese legal applications. LAWGPT comprises two key components: legal-oriented pre-training and legal supervised ﬁne-tuning. Speciﬁcally, we employ large-scale Chinese legal documents for legal-oriented pre-training to incorporate legal domain knowledge. To further improve the model’s performance on downstream legal tasks, we create a knowledge-driven instruction dataset for legal supervised ﬁne-tuning. Our experimental results demonstrate that LAWGPT outperforms the open-source LLaMA 7B model. Our code and resources are publicly available at https://github.com/pengxiao-song/LaWGPT and have received 5.7K stars on GitHub.},
	language = {en},
	urldate = {2024-09-11},
	publisher = {arXiv},
	author = {Zhou, Zhi and Shi, Jiang-Xin and Song, Peng-Xiao and Yang, Xiao-Wen and Jin, Yi-Xuan and Guo, Lan-Zhe and Li, Yu-Feng},
	month = jun,
	year = {2024},
	note = {arXiv:2406.04614 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, OS, Legal Language Model - LawGPT},
	annote = {Comment: Technical Report},
	file = {Zhou et al. - 2024 - LawGPT A Chinese Legal Knowledge-Enhanced Large L.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\IUD9HUDA\\Zhou et al. - 2024 - LawGPT A Chinese Legal Knowledge-Enhanced Large L.pdf:application/pdf},
}

@book{caelen_developing_2023,
	address = {Beijing Boston Farnham Sebastopol Tokyo},
	edition = {First edition},
	title = {Developing apps with {GPT}-4 and {ChatGPT}: build intelligent chatbots, content generators, and more},
	isbn = {978-1-09-815248-2 978-1-09-815245-1},
	shorttitle = {Developing apps with {GPT}-4 and {ChatGPT}},
	abstract = {This minibook is a comprehensive guide for Python developers who want to learn how to build applications with large language models. Authors Olivier Caelen and Marie-Alice Blete cover the main features and benefits of GPT-4 and ChatGPT and explain how they work. You'll also get a step-by-step guide for developing applications using the GPT-4 and ChatGPT Python library, including text generation, Q\&A, and content summarization tools. Written in clear and concise language, Developing Apps with GPT-4 and ChatGPT includes easy-to-follow examples to help you understand and apply the concepts to your projects. Python code examples are available in a GitHub repository, and the book includes a glossary of key terms. Ready to harness the power of large language models in your applications? This book is a must. You'll learn: The fundamentals and benefits of ChatGPT and GPT-4 and how they work How to integrate these models into Python-based applications for NLP tasks How to develop applications using GPT-4 or ChatGPT APIs in Python for text generation, question answering, and content summarization, among other tasks Advanced GPT topics including prompt engineering, fine-tuning models for specific tasks, plug-ins, LangChain, and more},
	language = {eng},
	publisher = {O'Reilly},
	author = {Caelen, Oliver and Blete, Marie-Alice},
	year = {2023},
	keywords = {OS, Book - Apps with GPT-4 and ChatGPT},
	annote = {Description based on publisher supplied metadata and other sources},
	file = {Caelen und Blete - 2023 - Developing apps with GPT-4 and ChatGPT build inte.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\9YQPCWSY\\Caelen und Blete - 2023 - Developing apps with GPT-4 and ChatGPT build inte.pdf:application/pdf},
}

@book{ilyas_data_2019,
	address = {New York, NY},
	edition = {First edition},
	series = {{ACM} books},
	title = {Data {Cleaning}},
	isbn = {978-1-4503-7155-1},
	language = {eng},
	number = {28},
	publisher = {Association for Computing Machinery and Morgan \& Claypool Publishers},
	author = {Ilyas, Ihab F. and Chu, Xu},
	year = {2019},
	keywords = {OS, Book - Data Cleaning},
	annote = {Description based on publisher supplied metadata and other sources},
	annote = {This is an overview of the end-to-end data cleaning process. Data quality is one of the most important problems in data management, since dirty data often leads to inaccurate data analytics results and incorrect business decisions.Poor data across businesses and the U.S. government are reported to cost trillions of dollars a year. Multiple surveys show that dirty data is the most common barrier faced by data scientists. Not surprisingly, developing effective and efficient data cleaning solutions is challenging and is rife with deep theoretical and engineering problems. This book is about data cleaning, which is used to refer to all kinds of tasks and activities to detect and repair errors in the data. Rather than focus on a particular data cleaning task, this book describes various error detection and repair methods, and attempts to anchor these proposals with multiple taxonomies and views. Specifically, it covers four of the most common and important data cleaning tasks, namely, outlier detection, data transformation, error repair (including imputing missing values), and data deduplication. Furthermore, due to the increasing popularity and applicability of machine learning techniques, it includes a chapter that specifically explores how machine learning techniques are used for data cleaning, and how data cleaning is used to improve machine learning models Intro -- Contents -- Preface -- Figure and Table Credits -- 1. Introduction -- 2. Outlier Detection -- 3. Data Deduplication -- 4. Data Transformation -- 5. Data Quality Rule Definition and Discovery -- 6. Rule-Based Data Cleaning -- 7. Machine Learning and Probabilistic Data Cleaning -- 8. Conclusion and Future Thoughts -- References -- Index -- Author Biographies -- Blank Page},
	file = {(Association for Computing Machinery._ ACM books) Association for Computing Machinery._ Chu, Xu_ Ilyas, Ihab F - Data cleaning-Association for Computing Machinery (2019).pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\S3ZEH7WY\\(Association for Computing Machinery._ ACM books) Association for Computing Machinery._ Chu, Xu_ Ilyas, Ihab F - Data cleaning-Association for Computing Machinery (2019).pdf:application/pdf},
}

@book{albrecht_blueprints_2021,
	address = {Sebastopol},
	title = {Blueprints for {Text} {Analytics} {Using} {Python}},
	isbn = {978-1-4920-7408-3 978-1-4920-7403-8},
	language = {eng},
	publisher = {O'Reilly Media, Incorporated},
	author = {Albrecht, Jens},
	collaborator = {Ramachandran, Sidharth and Winkler, Christian},
	year = {2021},
	keywords = {OS, Book - Texts Analytics using Python},
	annote = {Description based on publisher supplied metadata and other sources},
	file = {Jens Albrecht, Sidharth Ramachandran, Christian Winkles - Blueprints for Text Analytics using Python_ Machine Learning Based Solutions for Common Real World (NLP) Applications-O′Reilly (202.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\YSDQRRPK\\Jens Albrecht, Sidharth Ramachandran, Christian Winkles - Blueprints for Text Analytics using Python_ Machine Learning Based Solutions for Common Real World (NLP) Applications-O′Reilly (202.pdf:application/pdf},
}

@book{brownlee_data_2020,
	title = {Data {Preparation} for {Machine} {Learning}  {Data} {Cleaning}, {Feature} {Selection}, and {Data} {Transforms} in {Python}},
	author = {Brownlee, Jason},
	year = {2020},
	keywords = {OS, Book - Data Preparation for Machine Learning},
	file = {Jason Brownlee - Data Preparation for Machine Learning - Data Cleaning, Feature Selection, and Data-machine learning mastery (2020).pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\VWY8QAXH\\Jason Brownlee - Data Preparation for Machine Learning - Data Cleaning, Feature Selection, and Data-machine learning mastery (2020).pdf:application/pdf},
}

@article{snake_natural_nodate,
	title = {Natural {Language} {Processing} {Practical} using {Transformers} with {Python}},
	language = {en},
	author = {Snake, Tony},
	keywords = {OS, Book - NLP - Python},
	file = {Natural Language Processing Practical using Transf.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\CZWHNT46\\Natural Language Processing Practical using Transf.pdf:application/pdf},
}

@article{polat_testing_2024,
	title = {Testing prompt engineering methods for knowledge extraction from text},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {22104968, 15700844},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-243719},
	doi = {10.3233/SW-243719},
	abstract = {The capabilities of Large Language Models (LLMs,) such as Mistral 7B, Llama 3, GPT-4, present a signiﬁcant opportunity for knowledge extraction (KE) from text. However, LLMs’ context-sensitivity can hinder obtaining precise and task-aligned outcomes, thereby requiring prompt engineering. This study explores the efﬁcacy of ﬁve prompt methods with different task demonstration strategies across 17 different prompt templates, utilizing a relation extraction dataset (RED-FM) with the aforementioned LLMs. To facilitate evaluation, we introduce a novel framework grounded in Wikidata’s ontology. The ﬁndings demonstrate that LLMs are capable of extracting a diverse array of facts from text. Notably, incorporating a simple instruction accompanied by a task demonstration – comprising three examples selected via a retrieval mechanism – signiﬁcantly enhances performance across Mistral 7B, Llama 3, and GPT-4. The effectiveness of reasoning-oriented prompting methods such as Chain-of-Thought, Reasoning and Acting, while improved with task demonstrations, does not surpass alternative methods. This suggests that framing extraction as a reasoning task may not be necessary for KE. Notably, task demonstrations leveraging examples selected via retrieval mechanisms facilitate effective knowledge extraction across all tested prompting strategies and LLMs.},
	language = {en},
	urldate = {2024-11-19},
	journal = {Semantic Web},
	author = {Polat, Fina and Tiddi, Ilaria and Groth, Paul},
	editor = {Tiwari, Sanju and Mihindukulasooriya, Nandana and Osborne, Francesco and Kontokostas, Dimitris and D’Souza, Jennifer and Kejriwal, Mayank},
	month = sep,
	year = {2024},
	keywords = {OS, Prompt Engineering - Methods},
	pages = {1--34},
	file = {PDF:C\:\\Users\\WeigoldS\\Zotero\\storage\\KB623QTE\\Polat et al. - 2024 - Testing prompt engineering methods for knowledge extraction from text.pdf:application/pdf},
}

@article{azoulay_old_nodate,
	title = {Old {Moats} for {New} {Models}: {Openness}, {Control}, and {Competition} in {Generative} {AI}},
	abstract = {Drawing insights from the field of innovation economics, we discuss the likely competitive environment shaping generative AI advances. Central to our analysis are the concepts of appropriability—whether firms in the industry are able to control the knowledge generated by their innovations—and complementary assets—whether effective entry requires access to specialized infrastructure and capabilities to which incumbent firms can ration access. While the rapid improvements in AI foundation models promise transformative impacts across broad sectors of the economy, we argue that tight control over complementary assets will likely result in a concentrated market structure, as in past episodes of technological upheaval. We suggest the likely paths through which incumbent firms may restrict entry, confining newcomers to subordinate roles and stifling broad sectoral innovation. We conclude with speculations regarding how this oligopolistic future might be averted. Policy interventions aimed at fractionalizing or facilitating shared access to complementary assets might help preserve competition and incentives for extending the generative AI frontier. Ironically, the best hopes for a vibrant open source AI ecosystem might rest on the presence of a “rogue” technology giant, who might choose openness and engagement with smaller firms as a strategic weapon wielded against other incumbents.},
	language = {en},
	author = {Azoulay, Pierre and Krieger, Joshua and Nagaraj, Abhishek},
	keywords = {OS, LLM - Openess, Control \& Competition},
	file = {PDF:C\:\\Users\\WeigoldS\\Zotero\\storage\\VM9HCMNL\\Azoulay et al. - Old Moats for New Models Openness, Control, and Competition in Generative AI.pdf:application/pdf},
}

@article{haar_stellenwert_2024,
	title = {Stellenwert von {Natural} {Language} {Processing} und chatbasierten {Generative} {Language} {Models}},
	volume = {119},
	issn = {2193-6218, 2193-6226},
	url = {https://link.springer.com/10.1007/s00063-023-01098-5},
	doi = {10.1007/s00063-023-01098-5},
	language = {de},
	number = {3},
	urldate = {2024-12-03},
	journal = {Medizinische Klinik - Intensivmedizin und Notfallmedizin},
	author = {Haar, Markus and Sonntagbauer, Michael and Kluge, Stefan},
	month = apr,
	year = {2024},
	keywords = {OS, NLP - Definition},
	pages = {181--188},
	file = {Haar et al. - 2024 - Stellenwert von Natural Language Processing und ch.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\6CKQED7C\\Haar et al. - 2024 - Stellenwert von Natural Language Processing und ch.pdf:application/pdf},
}

@misc{minaee_large_2024,
	title = {Large {Language} {Models}: {A} {Survey}},
	shorttitle = {Large {Language} {Models}},
	url = {http://arxiv.org/abs/2402.06196},
	doi = {10.48550/arXiv.2402.06196},
	abstract = {Large Language Models (LLMs) have drawn a lot of attention due to their strong performance on a wide range of natural language tasks, since the release of ChatGPT in November 2022. LLMs’ ability of general-purpose language understanding and generation is acquired by training billions of model’s parameters on massive amounts of text data, as predicted by scaling laws [1], [2]. The research area of LLMs, while very recent, is evolving rapidly in many different ways. In this paper, we review some of the most prominent LLMs, including three popular LLM families (GPT, LLaMA, PaLM), and discuss their characteristics, contributions and limitations. We also give an overview of techniques developed to build, and augment LLMs. We then survey popular datasets prepared for LLM training, fine-tuning, and evaluation, review widely used LLM evaluation metrics, and compare the performance of several popular LLMs on a set of representative benchmarks. Finally, we conclude the paper by discussing open challenges and future research directions.},
	language = {en},
	urldate = {2024-12-03},
	publisher = {arXiv},
	author = {Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng},
	month = feb,
	year = {2024},
	note = {arXiv:2402.06196 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, OS, LLM - Definition p. 1},
	annote = {Comment: arXiv admin note: substantial text overlap with arXiv:2401.14423},
	file = {Minaee et al. - 2024 - Large Language Models A Survey.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LQWDT5DH\\Minaee et al. - 2024 - Large Language Models A Survey.pdf:application/pdf},
}

@misc{naveed_comprehensive_2024,
	title = {A {Comprehensive} {Overview} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2307.06435},
	doi = {10.48550/arXiv.2307.06435},
	abstract = {Large Language Models (LLMs) have recently demonstrated remarkable capabilities in natural language processing tasks and beyond. This success of LLMs has led to a large influx of research contributions in this direction. These works encompass diverse topics such as architectural innovations, better training strategies, context length improvements, fine-tuning, multi-modal LLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid development of techniques and regular breakthroughs in LLM research, it has become considerably challenging to perceive the bigger picture of the advances in this direction. Considering the rapidly emerging plethora of literature on LLMs, it is imperative that the research community is able to benefit from a concise yet comprehensive overview of the recent developments in this field. This article provides an overview of the literature on a broad range of LLM-related concepts. Our self-contained comprehensive overview of LLMs discusses relevant background concepts along with covering the advanced topics at the frontier of research in LLMs. This review article is intended to provide not only a systematic survey but also a quick, comprehensive reference for the researchers and practitioners to draw insights from extensive, informative summaries of the existing works to advance the LLM research.},
	language = {en},
	urldate = {2024-12-17},
	publisher = {arXiv},
	author = {Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and Mian, Ajmal},
	month = oct,
	year = {2024},
	note = {arXiv:2307.06435 [cs]},
	keywords = {Computer Science - Computation and Language, SW},
	file = {Naveed et al. - 2024 - A Comprehensive Overview of Large Language Models.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\FQF8MVYK\\Naveed et al. - 2024 - A Comprehensive Overview of Large Language Models.pdf:application/pdf;Naveed et al. - 2024 - A Comprehensive Overview of Large Language Models.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\G4HXV7Z5\\Naveed et al. - 2024 - A Comprehensive Overview of Large Language Models.pdf:application/pdf},
}

@article{kumar_large_2024,
	title = {Large language models ({LLMs}): survey, technical frameworks, and future challenges},
	volume = {57},
	issn = {1573-7462},
	shorttitle = {Large language models ({LLMs})},
	url = {https://link.springer.com/10.1007/s10462-024-10888-y},
	doi = {10.1007/s10462-024-10888-y},
	abstract = {Artificial intelligence (AI) has significantly impacted various fields. Large language models (LLMs) like GPT-4, BARD, PaLM, Megatron-Turing NLG, Jurassic-1 Jumbo etc., have contributed to our understanding and application of AI in these domains, along with natural language processing (NLP) techniques. This work provides a comprehensive overview of LLMs in the context of language modeling, word embeddings, and deep learning. It examines the application of LLMs in diverse fields including text generation, vision-language models, personalized learning, biomedicine, and code generation. The paper offers a detailed introduction and background on LLMs, facilitating a clear understanding of their fundamental ideas and concepts. Key language modeling architectures are also discussed, alongside a survey of recent works employing LLM methods for various downstream tasks across different domains. Additionally, it assesses the limitations of current approaches and highlights the need for new methodologies and potential directions for significant advancements in this field.},
	language = {en},
	number = {10},
	urldate = {2024-12-17},
	journal = {Artificial Intelligence Review},
	author = {Kumar, Pranjal},
	month = aug,
	year = {2024},
	keywords = {SW},
	pages = {260},
	file = {Kumar - 2024 - Large language models (LLMs) survey, technical fr.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\SG4M45ZA\\Kumar - 2024 - Large language models (LLMs) survey, technical fr.pdf:application/pdf},
}

@article{castano_enforcing_2024,
	title = {Enforcing legal information extraction through context-aware techniques: {The} {ASKE} approach},
	volume = {52},
	issn = {02673649},
	shorttitle = {Enforcing legal information extraction through context-aware techniques},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0267364923001139},
	doi = {10.1016/j.clsr.2023.105903},
	abstract = {To cope with the growing volume, complexity, and articulation of legal documents as well as to foster digital justice and digital law, increasing effort is being devoted to legal knowledge extraction and digital transformation processes. In this paper, we present the ASKE (Automated System for Knowledge Extraction) approach to legal knowledge extraction, based on a combination of context-aware embedding models and zero-shot learning techniques into a three-phase extraction cycle, which is executed a number of times (called generations) to progressively extract concepts representative of the different meanings of terminology used in legal documents chunks. A graph-based data structure called ASKE Conceptual Graph is initially populated through a data preparation step, and it is continuously enriched at each ASKE generation with results of document chunk classification, new extracted terminology, and newly derived concepts. A quantitative evaluation of ASKE knowledge extraction and document classification is provided by considering the EurLex dataset. Furthermore, we present the results of applying ASKE to a real case-study of Italian case law decisions with qualitative feedback from legal experts in the framework of an ongoing national research project.},
	language = {en},
	urldate = {2024-09-08},
	journal = {Computer Law \& Security Review},
	author = {Castano, Silvana and Ferrara, Alfio and Furiosi, Emanuela and Montanelli, Stefano and Picascia, Sergio and Riva, Davide and Stefanetti, Carolina},
	month = apr,
	year = {2024},
	keywords = {OS, Legal Information Extraction -  Context Aware Technics},
	pages = {105903},
	file = {Castano et al. - 2024 - Enforcing legal information extraction through con.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\3IV87QQS\\Castano et al. - 2024 - Enforcing legal information extraction through con.pdf:application/pdf},
}

@misc{dominguez-olmedo_lawma_2024,
	title = {Lawma: {The} {Power} of {Specialization} for {Legal} {Tasks}},
	shorttitle = {Lawma},
	url = {http://arxiv.org/abs/2407.16615},
	doi = {10.48550/arXiv.2407.16615},
	abstract = {Annotation and classification of legal text are central components of empirical legal research. Traditionally, these tasks are often delegated to trained research assistants. Motivated by the advances in language modeling, empirical legal scholars are increasingly turning to prompting commercial models, hoping that it will alleviate the significant cost of human annotation. Despite growing use, our understanding of how to best utilize large language models for legal tasks remains limited. We conduct a comprehensive study of 260 legal text classification tasks, nearly all new to the machine learning community. Starting from GPT-4 as a baseline, we show that it has non-trivial but highly varied zero-shot accuracy, often exhibiting performance that may be insufficient for legal work. We then demonstrate that a lightly fine-tuned Llama 3 model vastly outperforms GPT-4 on almost all tasks, typically by double-digit percentage points. We find that larger models respond better to fine-tuning than smaller models. A few tens to hundreds of examples suffice to achieve high classification accuracy. Notably, we can fine-tune a single model on all 260 tasks simultaneously at a small loss in accuracy relative to having a separate model for each task. Our work points to a viable alternative to the predominant practice of prompting commercial models. For concrete legal tasks with some available labeled data, researchers are better off using a fine-tuned open-source model.},
	language = {en},
	urldate = {2024-12-27},
	publisher = {arXiv},
	author = {Dominguez-Olmedo, Ricardo and Nanda, Vedant and Abebe, Rediet and Bechtold, Stefan and Engel, Christoph and Frankenreiter, Jens and Gummadi, Krishna and Hardt, Moritz and Livermore, Michael},
	month = jul,
	year = {2024},
	note = {arXiv:2407.16615 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, OS},
	file = {Dominguez-Olmedo et al. - 2024 - Lawma The Power of Specialization for Legal Tasks.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LU44QBAN\\Dominguez-Olmedo et al. - 2024 - Lawma The Power of Specialization for Legal Tasks.pdf:application/pdf},
}

@article{university_of_belgrade_faculty_of_law_serbia_artificial_2024,
	title = {Artificial {Reason} and {Artificial} {Intelligence}: the {Legal} {Reasoning} {Capabilities} of {GPT}-4},
	volume = {72},
	issn = {00032565, 24062693},
	shorttitle = {Artificial {Reason} and {Artificial} {Intelligence}},
	url = {https://anali.rs/artificial-reason-and-artificial-intelligence-the-legal-reasoning-capabilities-of-gpt-4/?lang=en},
	doi = {10.51204/Anali_PFBU_24302A},
	abstract = {Despite the widespread adoption of generative transformer large language models and the interest of the global legal community, discussions about the models in philosophy of law mainly have been focusing on what LLMs cannot do. In making the first steps towards a philosophical analysis of the capabilities of AI models in the field of law, we follow the basic idea of Turing’s „imitation game“. Proceeding from the frequently raised characterization of legal reasoning as „artificial“, the paper identifies the undisputed minimum core of the „artificiality“ thesis and asks to what extent it can be imitated by artificial intelligence. To answer this question, we test the legal reasoning capabilities of ChatGPT, the most advanced, up-to-date LLM version of artificial intelligence. The conclusion is that in all relevant types of activities usually associated with legal reasoning – fact-finding, interpretation, qualification, and decision-making – ChatGPT can generate outcomes as if it reasons legally.},
	language = {en},
	number = {3},
	urldate = {2024-12-27},
	journal = {Anali Pravnog fakulteta u Beogradu},
	author = {{University of Belgrade Faculty of Law, Serbia} and Spaić, Bojan and Jovanović, Miodrag},
	month = sep,
	year = {2024},
	keywords = {OS},
	pages = {383--422},
	file = {University of Belgrade Faculty of Law, Serbia et al. - 2024 - Artificial Reason and Artificial Intelligence the.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\Z456C8YA\\University of Belgrade Faculty of Law, Serbia et al. - 2024 - Artificial Reason and Artificial Intelligence the.pdf:application/pdf},
}

@inproceedings{ravaut_context_2024,
	address = {Bangkok, Thailand},
	title = {On {Context} {Utilization} in {Summarization} with {Large} {Language} {Models}},
	url = {https://aclanthology.org/2024.acl-long.153},
	doi = {10.18653/v1/2024.acl-long.153},
	abstract = {Large language models (LLMs) excel in abstractive summarization tasks, delivering fluent and pertinent summaries. Recent advancements have extended their capabilities to handle long-input contexts, exceeding 100k tokens. However, in question answering, language models exhibit uneven utilization of their input context. They tend to favor the initial and final segments, resulting in a U-shaped performance pattern concerning where the answer is located within the input. This bias raises concerns, particularly in summarization where crucial content may be dispersed throughout the source document(s). Besides, in summarization, mapping facts from the source to the summary is not trivial as salient content is usually re-phrased. In this paper, we conduct the first comprehensive study on context utilization and position bias in summarization. Our analysis encompasses 6 LLMs, 10 datasets, and 5 evaluation metrics. We introduce a new evaluation benchmark called MiddleSum on the which we benchmark two alternative inference methods to alleviate position bias: hierarchical summarization and incremental summarization1.},
	language = {en},
	urldate = {2024-12-27},
	booktitle = {Proceedings of the 62nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Ravaut, Mathieu and Sun, Aixin and Chen, Nancy and Joty, Shafiq},
	year = {2024},
	pages = {2764--2781},
	file = {Ravaut et al. - 2024 - On Context Utilization in Summarization with Large.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\DZ8XLDWV\\Ravaut et al. - 2024 - On Context Utilization in Summarization with Large.pdf:application/pdf},
}

@misc{han_empirical_2024,
	title = {An {Empirical} {Study} on {Information} {Extraction} using {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2409.00369},
	doi = {10.48550/arXiv.2409.00369},
	abstract = {Human-like large language models (LLMs), especially the most powerful and popular ones in OpenAI's GPT family, have proven to be very helpful for many natural language processing (NLP) related tasks. Therefore, various attempts have been made to apply LLMs to information extraction (IE), which is a fundamental NLP task that involves extracting information from unstructured plain text. To demonstrate the latest representative progress in LLMs' information extraction ability, we assess the information extraction ability of GPT-4 (the latest version of GPT at the time of writing this paper) from four perspectives: Performance, Evaluation Criteria, Robustness, and Error Types. Our results suggest a visible performance gap between GPT-4 and state-of-the-art (SOTA) IE methods. To alleviate this problem, considering the LLMs' human-like characteristics, we propose and analyze the effects of a series of simple prompt-based methods, which can be generalized to other LLMs and NLP tasks. Rich experiments show our methods' effectiveness and some of their remaining issues in improving GPT-4's information extraction ability.},
	language = {en},
	urldate = {2024-12-27},
	publisher = {arXiv},
	author = {Han, Ridong and Yang, Chaohao and Peng, Tao and Tiwari, Prayag and Wan, Xiang and Liu, Lu and Wang, Benyou},
	month = sep,
	year = {2024},
	note = {arXiv:2409.00369 [cs]},
	keywords = {Computer Science - Computation and Language, OS},
	annote = {Comment: This submission was intended instead as the replacement of arXiv:2305.14450 , where it now appears as arXiv:2305.14450v2},
	file = {Han et al. - 2024 - An Empirical Study on Information Extraction using.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\4BPWWSYY\\Han et al. - 2024 - An Empirical Study on Information Extraction using.pdf:application/pdf},
}

@book{prince_understanding_2024,
	title = {Understanding {Deep} {Learning}},
	language = {en},
	author = {Prince, Simon J D},
	year = {2024},
	file = {Prince - Understanding Deep Learning.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LPRDDJ86\\Prince - Understanding Deep Learning.pdf:application/pdf},
}

@book{raschka_build_2024,
	title = {Build a {Large} {Language} {Model} ({From} {Scratch})},
	language = {en},
	author = {Raschka, Sebastian},
	year = {2024},
	file = {Build a Large Language Model (From Scratch).pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\AKPII4W4\\Build a Large Language Model (From Scratch).pdf:application/pdf},
}

@misc{peeperkorn_is_2024,
	title = {Is {Temperature} the {Creativity} {Parameter} of {Large} {Language} {Models}?},
	url = {http://arxiv.org/abs/2405.00492},
	doi = {10.48550/arXiv.2405.00492},
	abstract = {Large language models (LLMs) are applied to all sorts of creative tasks, and their outputs vary from beautiful, to peculiar, to pastiche, into plain plagiarism. The temperature parameter of an LLM regulates the amount of randomness, leading to more diverse outputs; therefore, it is often claimed to be the creativity parameter. Here, we investigate this claim using a narrative generation task with a predetermined fixed context, model and prompt. Specifically, we present an empirical analysis of the LLM output for different temperature values using four necessary conditions for creativity in narrative generation: novelty, typicality, cohesion, and coherence. We find that temperature is weakly correlated with novelty, and unsurprisingly, moderately correlated with incoherence, but there is no relationship with either cohesion or typicality. However, the influence of temperature on creativity is far more nuanced and weak than suggested by the “creativity parameter” claim; overall results suggest that the LLM generates slightly more novel outputs as temperatures get higher. Finally, we discuss ideas to allow more controlled LLM creativity, rather than relying on chance via changing the temperature parameter.},
	language = {en},
	urldate = {2024-12-27},
	publisher = {arXiv},
	author = {Peeperkorn, Max and Kouwenhoven, Tom and Brown, Dan and Jordanous, Anna},
	month = may,
	year = {2024},
	note = {arXiv:2405.00492 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: To be published in the Proceedings of the 15th International Conference on Computational Creativity (ICCC'24), 8 pages, 2 figures, 2 tables},
	file = {Peeperkorn et al. - 2024 - Is Temperature the Creativity Parameter of Large L.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\YS8DVN9J\\Peeperkorn et al. - 2024 - Is Temperature the Creativity Parameter of Large L.pdf:application/pdf},
}

@book{alammar_hands-large_2024,
	address = {Beijing Boston Farnham},
	edition = {1st edition},
	title = {Hands-on large language models: language understanding and generation},
	isbn = {978-1-09-815096-9 978-1-09-815093-8},
	shorttitle = {Hands-on large language models},
	abstract = {Intro -- Copyright -- Table of Contents -- Preface -- An Intuition-First Philosophy -- Prerequisites -- Book Structure -- Part I: Understanding Language Models -- Part II: Using Pretrained Language Models -- Part III: Training and Fine-Tuning Language Models -- Hardware and Software Requirements -- API Keys -- Conventions Used in This Book -- Using Code Examples -- O'Reilly Online Learning -- How to Contact Us -- Acknowledgments -- Part I. Understanding Language Models -- Chapter 1. An Introduction to Large Language Models -- What Is Language AI? -- A Recent History of Language AI -- Representing Language as a Bag-of-Words -- Better Representations with Dense Vector Embeddings -- Types of Embeddings -- Encoding and Decoding Context with Attention -- Attention Is All You Need -- Representation Models: Encoder-Only Models -- Generative Models: Decoder-Only Models -- The Year of Generative AI -- The Moving Definition of a "Large Language Model" -- The Training Paradigm of Large Language Models -- Large Language Model Applications: What Makes Them So Useful? -- Responsible LLM Development and Usage -- Limited Resources Are All You Need -- Interfacing with Large Language Models -- Proprietary, Private Models -- Open Models -- Open Source Frameworks -- Generating Your First Text -- Summary -- Chapter 2. Tokens and Embeddings -- LLM Tokenization -- How Tokenizers Prepare the Inputs to the Language Model -- Downloading and Running an LLM -- How Does the Tokenizer Break Down Text? -- Word Versus Subword Versus Character Versus Byte Tokens -- Comparing Trained LLM Tokenizers -- Tokenizer Properties -- Token Embeddings -- A Language Model Holds Embeddings for the Vocabulary of Its Tokenizer -- Creating Contextualized Word Embeddings with Language Models -- Text Embeddings (for Sentences and Whole Documents) -- Word Embeddings Beyond LLMs},
	language = {en},
	publisher = {O'Reilly},
	author = {Alammar, Jay and Grootendorst, Maarten},
	year = {2024},
	file = {Alammar und Grootendorst - 2024 - Hands-on large language models language understan.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\DR5W2J4U\\Alammar und Grootendorst - 2024 - Hands-on large language models language understan.pdf:application/pdf},
}

@book{wilson_developers_2024,
	address = {Beijing Boston Farnham Sebastopol Tokyo},
	edition = {First edition},
	title = {The developer's playbook for large {Language} model security: building secure {AI} applications},
	isbn = {978-1-09-816220-7 978-1-09-816217-7},
	shorttitle = {The developer's playbook for large {Language} model security},
	abstract = {Cover -- Copyright -- Table of Contents -- Preface -- Who Should Read This Book -- Why I Wrote This Book -- Navigating This Book -- Section 1: Laying the Foundation (Chapters 1-3) -- Section 2: Risks, Vulnerabilities, and Remediations (Chapters 4-9) -- Section 3: Building a Security Process and Preparing for the Future (Chapters 10-12) -- Conventions Used in This Book -- O'Reilly Online Learning -- How to Contact Us -- Acknowledgments -- Chapter 1. Chatbots Breaking Bad -- Let's Talk About Tay -- Tay's Rapid Decline -- Why Did Tay Break Bad? -- It's a Hard Problem -- Chapter 2. The OWASP Top 10 for LLM Applications -- About OWASP -- The Top 10 for LLM Applications Project -- Project Execution -- Reception -- Keys to Success -- This Book and the Top 10 List -- Chapter 3. Architectures and Trust Boundaries -- AI, Neural Networks, and Large Language Models: What's the Difference? -- The Transformer Revolution: Origins, Impact, and the LLM Connection -- Origins of the Transformer -- Transformer Architecture's Impact on AI -- Types of LLM-Based Applications -- LLM Application Architecture -- Trust Boundaries -- The Model -- User Interaction -- Training Data -- Access to Live External Data Sources -- Access to Internal Services -- Conclusion -- Chapter 4. Prompt Injection -- Examples of Prompt Injection Attacks -- Forceful Suggestion -- Reverse Psychology -- Misdirection -- Universal and Automated Adversarial Prompting -- The Impacts of Prompt Injection -- Direct Versus Indirect Prompt Injection -- Direct Prompt Injection -- Indirect Prompt Injection -- Key Differences -- Mitigating Prompt Injection -- Rate Limiting -- Rule-Based Input Filtering -- Filtering with a Special-Purpose LLM -- Adding Prompt Structure -- Adversarial Training -- Pessimistic Trust Boundary Definition -- Conclusion -- Chapter 5. Can Your LLM Know Too Much? -- Real-World Examples},
	language = {en},
	publisher = {O'Reilly},
	author = {Wilson, Steve},
	year = {2024},
	file = {Wilson - 2024 - The developer's playbook for large Language model .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\ZX5FHGZU\\Wilson - 2024 - The developer's playbook for large Language model .pdf:application/pdf},
}

@book{nelson_essential_2023,
	address = {Beijing},
	title = {Essential math for {AI}: next-level mathematics for efficient and successful {AI} systems},
	isbn = {978-1-09-810763-5 978-1-09-810760-4},
	shorttitle = {Essential math for {AI}},
	abstract = {Cover -- Copyright -- Table of Contents -- Preface -- Why I Wrote This Book -- Who Is This Book For? -- Who Is This Book Not For? -- How Will the Math Be Presented in This Book? -- Infographic -- What Math Background Is Expected from You to Be Able to Read This Book? -- Overview of the Chapters -- My Favorite Books on AI -- Conventions Used in This Book -- Using Code Examples -- O'Reilly Online Learning -- How to Contact Us -- Acknowledgments -- Chapter 1. Why Learn the Mathematics of AI? -- What Is AI? -- Why Is AI So Popular Now? -- What Is AI Able to Do? -- An AI Agent's Specific Tasks -- What Are AI's Limitations? -- What Happens When AI Systems Fail? -- Where Is AI Headed? -- Who Are the Current Main Contributors to the AI Field? -- What Math Is Typically Involved in AI? -- Summary and Looking Ahead -- Chapter 2. Data, Data, Data -- Data for AI -- Real Data Versus Simulated Data -- Mathematical Models: Linear Versus Nonlinear -- An Example of Real Data -- An Example of Simulated Data -- Mathematical Models: Simulations and AI -- Where Do We Get Our Data From? -- The Vocabulary of Data Distributions, Probability, and Statistics -- Random Variables -- Probability Distributions -- Marginal Probabilities -- The Uniform and the Normal Distributions -- Conditional Probabilities and Bayes' Theorem -- Conditional Probabilities and Joint Distributions -- Prior Distribution, Posterior Distribution, and Likelihood Function -- Mixtures of Distributions -- Sums and Products of Random Variables -- Using Graphs to Represent Joint Probability Distributions -- Expectation, Mean, Variance, and Uncertainty -- Covariance and Correlation -- Markov Process -- Normalizing, Scaling, and/or Standardizing a Random Variable or Data Set -- Common Examples -- Continuous Distributions Versus Discrete Distributions (Density Versus Mass)},
	language = {en},
	publisher = {O'Reilly},
	author = {Nelson, Hala},
	year = {2023},
	file = {Nelson - 2023 - Essential math for AI next-level mathematics for .pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LLFQC2QC\\Nelson - 2023 - Essential math for AI next-level mathematics for .pdf:application/pdf},
}

@book{bahree_generative_2024,
	address = {Shelter Island, NY},
	title = {Generative {AI} in action},
	isbn = {978-1-63343-694-7},
	abstract = {Generative AI in Action presents concrete examples, insights, and techniques for using LLMs and other modern AI technologies successfully},
	language = {en},
	publisher = {Manning Publications Co},
	author = {Bahree, Amit and Boyd, Eric},
	year = {2024},
	file = {Bahree und Boyd - 2024 - Generative AI in action.pdf:C\:\\Users\\WeigoldS\\Zotero\\storage\\LPCU2TFG\\Bahree und Boyd - 2024 - Generative AI in action.pdf:application/pdf},
}

@misc{liu2023gevalnlgevaluationusing,
      title={G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment}, 
      author={Yang Liu and Dan Iter and Yichong Xu and Shuohang Wang and Ruochen Xu and Chenguang Zhu},
      year={2023},
      eprint={2303.16634},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.16634}, 
}

@misc{anon_2025,
	  title={Conference presentation of the same research project with a focus on legal subjects},
	  author={Anonymous},
	  year={2025},
}